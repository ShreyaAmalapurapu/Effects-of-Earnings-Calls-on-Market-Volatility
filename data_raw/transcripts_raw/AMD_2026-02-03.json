{
  "event_id": "AMD_2026-02-03",
  "ticker": "AMD",
  "company": "Advanced Micro Devices, Inc.",
  "quarter": 4,
  "fiscal_year": 2025,
  "call_date": "2026-02-03",
  "call_start_ts": "2026-02-03 22:00:00+00:00",
  "raw_text": "\n|[pic]                     |\n\nAdvanced Micro Devices, Inc. NasdaqGS:AMD\nFQ4 2025 Earnings Call Transcripts\nTuesday, February 3, 2026 10:00 PM GMT\nS&P Global Market Intelligence Estimates\n|      |-FQ4 2025-           |-FQ1  |-FY 2025-            |-FY   |\n|      |                     |2026- |                     |2026- |\n|                              |CONSENSUS      |ACTUAL         |SURPRISE       |\n|                   |CONSENSUS          |ACTUAL             |SURPRISE           |\n|FQ1 2025           |0.93               |0.96               |[pic]3.23 %        |\n|FQ2 2025           |0.48               |0.48               |[pic]0.00 %        |\n|FQ3 2025           |1.17               |1.20               |[pic]2.56 %        |\n|FQ4 2025           |1.32               |1.53               |[pic]15.91 %       |\n\n|Table of Contents                                     |   |\n|Call Participants          |..............................................|3      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Presentation               |..............................................|4      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Question and Answer        |..............................................|10     |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|                                                                                  |\n|Call Participants                                                                 |\n|                           |                           |                           |\n|EXECUTIVES                 |                           |                           |\n|                           |Timothy Michael Arcuri     |                           |\n|                           |UBS Investment Bank,       |                           |\n|Jean X. Hu                 |Research Division          |                           |\n|Executive VP, CFO &        |                           |                           |\n|Treasurer                  |                           |                           |\n|                           |Vivek  Arya                |                           |\n|                           |BofA Securities, Research  |                           |\n|Lisa T. Su                 |Division                   |                           |\n|Chair, President & CEO     |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Matthew D. Ramsay          |                           |                           |\n|Vice President of Financial|                           |                           |\n|Strategy & Investor        |                           |                           |\n|Relations                  |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|ANALYSTS                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Aaron Christopher Rakers   |                           |                           |\n|Wells Fargo Securities,    |                           |                           |\n|LLC, Research Division     |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Benjamin Alexander Reitzes |                           |                           |\n|                           |                           |                           |\n|Melius Research LLC        |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Christopher James Muse     |                           |                           |\n|Cantor Fitzgerald & Co.,   |                           |                           |\n|Research Division          |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|James Edward Schneider     |                           |                           |\n|Goldman Sachs Group, Inc., |                           |                           |\n|Research Division          |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joseph Lawrence Moore      |                           |                           |\n|Morgan Stanley, Research   |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joshua Louis Buchalter     |                           |                           |\n|TD Cowen, Research Division|                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Ross Clark Seymore         |                           |                           |\n|Deutsche Bank AG, Research |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Stacy Aaron Rasgon         |                           |                           |\n|Bernstein Institutional    |                           |                           |\n|Services LLC, Research     |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Thomas James O'Malley      |                           |                           |\n|Barclays Bank PLC, Research|                           |                           |\n|Division                   |                           |                           |\n|                                                                                  |\n\n\nPresentation\n\n\nOperator\n\nGreetings, and welcome to the AMD Fourth Quarter and Full Year 2025\nConference Call. [Operator Instructions]. And please note that this\nconference is being recorded.\n\n\nI will now turn the conference over to Matt Ramsay, VP of Financial\nStrategy and IR. Thank you. You may begin.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nThank you, and welcome to AMD's Fourth Quarter and 2025 Full Year Financial\nResults Conference Call. By now, you should have had the opportunity to\nreview a copy of our earnings press release and accompanying slides. If you\nhave not had the opportunity to review these materials, they can be found\non the Investor Relations page of amd.com.\n\n\nToday, we will refer primarily to non-GAAP financial measures on the call.\nThe full non-GAAP to GAAP reconciliations are available in today's press\nrelease and in the slides posted on our website. Participants in today's\nconference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our\nExecutive Vice President, CFO and Treasurer. This is a live call and will\nbe replayed via webcast on our website.\n\n\nBefore we begin, I would like to note that Mark Papermaster, Executive Vice\nPresident and CTO, will present at Morgan Stanley's TMT Conference on\nTuesday, March 3. Today's discussions contain forward-looking statements\nbased on our current beliefs, assumptions and expectations, speak only as\nof today and as such, involve risks and uncertainties that could cause\nactual results to differ materially from our current expectations. Please\nrefer to the cautionary statement in our press release for more information\non factors that could cause actual results to differ materially.\n\n\nWith that, I will hand the call to Lisa.\n\n\nLisa T. Su\nChair, President & CEO\n\nThank you, Matt, and good afternoon to all those listening today. 2025 was\na defining year for AMD with record revenue, net income and free cash flow\ndriven by broad-based demand for our high-performance computing and AI\nproducts. We ended the year with significant momentum with every part of\nour business performing very well. We saw demand accelerate across the data\ncenter, PC, gaming and embedded markets, launched the broadest set of\nleadership products in our history, gained significant server and PC\nprocessor share and rapidly scaled our Data Center AI business as Instinct\nand ROCm adoption increased with cloud, enterprise and AI customers.\n\n\nLooking at our fourth quarter, fourth quarter revenue grew 34% year-over-\nyear to $10.3 billion, led by record EPYC, Ryzen and Instinct processor\nsales. Net income increased 42% to a record $2.5 billion and free cash flow\nnearly doubled year-over-year to a record $2.1 billion. For the full year,\nrevenue grew 34% to $34.6 billion, and we added more than $7.6 billion of\nData Center segment and client revenue.\n\n\nTurning to our fourth quarter segment results. Data Center segment revenue\nincreased 39% year-over-year to a record $5.4 billion, led by accelerating\nInstinct MI350 Series GPU deployments and server share gains. In server,\nadoption of fifth-gen EPYC turn CPUs accelerated in the quarter, accounting\nfor more than half of the total server revenue. Fourth-gen EPYC sales were\nalso robust as our prior generation CPUs continue to deliver superior\nperformance and TCO compared to competitive offerings across a wide range\nof workloads. As a result, we had record server CPU sales to both cloud and\nenterprise customers in the quarter and exited the year with record share.\n\n\nIn cloud, hyperscaler demand was very strong as North American customers\nexpanded deployments. EPYC-powered public cloud offerings grew\nsignificantly in the quarter with AWS, Google and others launching more\nthan 230 new AMD instances. Hyperscalers launched more than 500 AMD-based\ninstances in 2025, increasing the number of EPYC cloud instances more than\n50% year-over-year to nearly 1,600.\n\n\nIn the enterprise, we are seeing a meaningful shift in EPYC adoption,\ndriven by our leadership performance, expanded platform availability, broad\nsoftware enablement and increased go-to-market programs. The leading server\nproviders now offer more than 3,000 solutions powered by fourth and fifth-\ngen EPYC CPUs that are optimized for all major enterprise workloads. As a\nresult, the number of large businesses deploying EPYC on-prem more than\ndoubled in 2025, and we exited the year with record server sell-through.\n\n\nLooking ahead, server CPU demand remains very strong. Hyperscalers are\nexpanding their infrastructure to meet growing demand for cloud services\nand AI while enterprises are modernizing their data centers to ensure they\nhave the right compute required to enable new AI workflows. Against this\nbackdrop, EPYC has become the processor of choice for the modern data\ncenter, delivering leadership performance, efficiency and TCO. Our next-\ngeneration Venice CPU extends our leadership across each of these metrics.\nCustomer pull for Venice is very high with engagements underway to support\nlarge-scale cloud deployments and broad OEM platform availability when\nVenice launches later this year.\n\n\nTurning to our Data Center AI business. We delivered record Instinct GPU\nrevenue in the fourth quarter, led by the ramp of MI350 Series shipments.\nWe also had some revenue from MI308 sales to customers in China. Instinct\nadoption broadened in the quarter. Today, 8 of the top 10 AI companies use\nInstinct to power production workloads across a growing range of use cases.\nWith the MI350 Series, we are entering the next phase of Instinct adoption,\nexpanding our footprint with existing partners and adding new customers.\n\n\nIn the fourth quarter, hyperscalers expanded MI350 Series availability,\nleading AI companies scale their deployments to support additional\nworkloads and multiple neocloud providers launched MI350 Series offerings\nthat deliver on-demand access to Instinct infrastructure in the cloud.\n\n\nTurning to our AI software stack. We expanded the ROCm ecosystem in the\nfourth quarter, enabling customers to deploy Instinct faster and with\nhigher performance across a broader range of workloads. Millions of large\nlanguage and multimodal models run out of the box on AMD with the leading\nmodels launching with day zero support for Instinct GPUs. This capability\nhighlights our rapidly expanding open source community enablement,\nincluding new upstream integration of AMD GPUs in vLLM, one of the most\nwidely used inference engines.\n\n\nTo drive Instinct adoption with industry-specific use cases, we're also\nadding support for domain-specific models in key verticals. As one example,\nin health care, we added ROCm support for the leading medical imaging\nframework to enable developers to train and deploy highly performing deep\nlearning models on Instinct GPUs. For large businesses, we introduced our\nenterprise AI suite, a full stack software platform with enterprise-grade\ntools, inference microservices and solutions blueprints designed to\nsimplify and accelerate production deployments at scale.\n\n\nWe also announced a strategic partnership with Tata Consultancy Services to\nco-develop industry-specific AI solutions and help customers deploy AI\nacross their operations. Looking ahead, customer engagements for our next-\ngen MI400 Series and Helios platform continue expanding. In addition to our\nmulti-generation partnership with OpenAI to deploy 6 gigawatts of Instinct\nGPUs, we are in active discussions with other customers on at-scale\nmultiyear deployments starting with Helios and MI450 later this year.\n\n\nWith the MI400 series, we are also expanding our portfolio to address the\nfull range of cloud, HPC and enterprise AI workloads. This includes MI455X\nand Helios for AI superclusters, MI430X for HPC and sovereign AI and MI440X\nservers for enterprise customers requiring leadership training and\ninference performance in a compact 8-GPU solution that integrates easily\ninto existing infrastructure.\n\n\nMultiple OEMs publicly announced plans to launch Helios systems in 2026\nwith deep engineering engagements underway to support smooth production\nramps. In December, HPE announced that they will offer Helios racks with\npurpose-built HPE Juniper Ethernet switches, an optimized software for high-\nbandwidth scale-up networking. And in January, Lenovo announced plans to\noffer Helios racks. MI430X adoption also grew in the quarter with new\nexascale class supercomputers announced by GENCI in France and HLRS in\nGermany.\n\n\nLooking further ahead, development of our next-generation MI500 Series is\nwell underway. MI500 is powered by our CDNA 6 architecture built on\nadvanced 2-nanometer process technology and features high-speed HBM4E\nmemory. We are on track to launch MI500 in 2027 and expect MI500 to deliver\nanother major leap in AI performance to power the next wave of large-scale\nmultimodal models.\n\n\nIn summary, our AI business is accelerating with the launch of MI400 Series\nand Helios representing a major inflection point for the business as we\ndeliver leadership performance and TCO at the chip, compute tray and rack\nlevel. Based on the strength of our EPYC and Instinct road maps, we are\nwell positioned to grow Data Center segment revenue by more than 60%\nannually over the next 3 to 5 years and scale our AI business to tens of\nbillions in annual revenue in 2027.\n\n\nTurning to Client and Gaming. Segment revenue increased 37% year-over-year\nto $3.9 billion. In client, our PC processor business performed\nexceptionally well. Revenue increased 34% year-over-year to a record $3.1\nbillion, driven by increased demand for multiple generations of Ryzen\ndesktop and mobile CPUs. Desktop CPU sales set a record for the fourth\nconsecutive quarter. Ryzen CPUs topped the bestseller list at major global\nretailers and e-tailers throughout the holiday period with strong demand\nacross all price points in every region, driving record desktop channel\nsell-out.\n\n\nIn mobile, strong demand for AMD-powered notebooks drove record Ryzen PC\nsell-through in the quarter. That momentum extended into commercial PCs,\nwhere Ryzen adoption accelerated as we established a new long-term growth\nengine for our client business. Sell-through of Ryzen CPUs for commercial\nnotebooks and desktops grew by more than 40% year-over-year in the fourth\nquarter, and we closed large wins with major telecom, financial services,\naerospace, automotive, energy and technology customers.\n\n\nAt CES, we expanded our Ryzen portfolio with CPUs that further extend our\nperformance leadership. Our new Ryzen AI 400 mobile processors deliver\nsignificantly faster content creation and multitasking performance than the\ncompetition. Notebooks powered by Ryzen AI 400 are already available with\nthe broadest lineup of AMD-based consumer and commercial AI PCs set to\nlaunch throughout the year. We also introduced our Ryzen AI Halo platform,\nthe world's smallest AI development system, featuring our highest-end Ryzen\nAI MAX processor with 128 gigabytes of unified memory that can run models\nwith up to 200 billion parameters locally.\n\n\nIn gaming, revenue increased 50% year-over-year to $843 million. Semi-\ncustom sales increased year-over-year and declined sequentially as\nexpected. For 2026, we expect semi-custom SoC annual revenue to decline by\na significant double-digit percentage as we enter the seventh year of what\nhas been a very strong console cycle.\n\n\nFrom a product standpoint, Valve is on track to begin shipping its AMD-\npowered steam machine early this year and development of Microsoft's next-\ngen Xbox featuring an AMD semi-custom SoC is progressing well to support a\nlaunch in 2027. Gaming GPU revenue also increased year-over-year with\nhigher channel sell-out driven by demand throughout the holiday sales\nperiod for our latest generation Radeon RX 9000 series GPUs. We also\nlaunched FSR 4 Redstone in the quarter, our most advanced AI-powered\nupscaling technology, delivering higher image quality and smoother frame\nrates for gamers.\n\n\nTurning to our Embedded segment. Revenue increased 3% year-over-year to\n$950 million, led by strength with test and measurement and aerospace\ncustomers and growing adoption of our Embedded x86 CPUs. Channel sell-\nthrough accelerated in the quarter as end customer demand improved across\nseveral end markets, led by test, measurement and emulation. Design win\nmomentum remains one of the clearest indicators of long-term growth for our\nembedded business, and we delivered another record year. We closed $17\nbillion in design wins in 2025, up nearly 20% year-over-year as we've now\nwon more than $50 billion of embedded designs since acquiring Xilinx.\n\n\nWe also strengthened our Embedded portfolio in the quarter. We began\nproduction of our Versal AI Edge Gen 2 SoCs for low-latency inference\nworkloads and started shipping our highest-end Spartan UltraScale+ devices\nfor cost-optimized application. We also launched new embedded CPUs,\nincluding our EPYC 2005 series for network security and industrial edge\napplications, Ryzen P100 series for in-vehicle infotainment and industrial\nsystems and Ryzen X100 series for physical AI and autonomous platforms.\n\n\nIn summary, 2025 was an excellent year for AMD, marking the start of a new\ngrowth trajectory for the company. We are entering a multiyear demand super\ncycle for high performance and AI computing that is creating significant\ngrowth opportunities across each of our businesses. AMD is well positioned\nto capture that growth with highly differentiated products, a proven\nexecution engine, deep customer partnerships and significant operational\nscale.\n\n\nAnd as AI reshapes the compute landscape, we have the breadth of solutions\nand partnerships required for end-to-end leadership. From Helios in the\ncloud for at-scale training and inference to an expanded Instinct portfolio\nfor sovereign, supercomputing and enterprise AI deployment. At the same\ntime, demand for EPYC CPUs is surging as agentic and emerging AI workloads\nrequire high-performance CPUs to power head nodes and run parallel tasks\nalongside GPUs. And at the edge and in PCs where AI adoption is just\nbeginning, our industry-leading Ryzen and Embedded processors are powering\nreal-time on-device AI. As a result, we expect significant top line and\nbottom line growth in 2026, led by increased adoption of EPYC and Instinct,\ncontinued client share gains and a return to growth in our Embedded\nsegment.\n\n\nLooking further ahead, we see a clear path to achieve the ambitious targets\nwe laid out at our Financial Analyst Day last November, including growing\nrevenue at greater than 35% CAGR over the next 3 to 5 years, significantly\nexpanding operating margins and generating annual EPS of more than $20 in\nthe strategic time frame, driven by growth in all of our segments and the\nrapid scaling of our Data Center AI business.\n\n\nNow I'll turn the call over to Jean to provide additional color on our\nfourth quarter results and full year results. Jean?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of\nour financial results and then provide our current outlook for the first\nquarter of fiscal 2026.\n\n\nAMD executed very well in 2025, delivering record revenue of $34.6 billion,\nup 34% year-over-year, driven by 32% growth in our Data Center segment and\n51% growth in our Client and Gaming segment. Gross margin was 52%, and we\ndelivered record earnings per share of $4.17, up 26% year-over-year while\ncontinuing to invest aggressively in AI and the data center to support our\nlong-term growth.\n\n\nFor the fourth quarter of 2025, revenue was a record $10.3 billion, growing\n34% year-over-year, driven by strong growth in the Data Center and Client\nand Gaming segment, including approximately $390 million in revenue from\nMI308 sales to China, which was not included in our fourth quarter\nguidance. Revenue was up 11% sequentially, primarily driven by continued\nstrong growth in data center from both server and Data Center AI business\nas well as a return to year-over-year growth in the Embedded segment.\n\n\nGross margin was 57%, up 290 basis points year-over-year. We benefited from\nthe release of $360 million in previously writing down MI308 inventory\nreserves. Excluding the inventory reserve release and MI308 revenue from\nChina, gross margin would have been approximately 55%, up 80 basis points\nyear-over-year, driven by favorable product mix.\n\n\nOperating expenses were $3 billion, an increase of 42% year-over-year as we\ncontinue to invest in R&D go-to-market activities to support our AI road\nmap and long-term growth opportunities as well as higher employee\nperformance-based incentives. Operating income was a record $2.9 billion,\nrepresenting a 28% operating margin. Tax, interest and other resulted in a\nnet expense of approximately $335 million.\n\n\nFor the fourth quarter, diluted earnings per share was a record $1.53, an\nincrease of 40% year-over-year, reflecting strong execution and operating\nleverage in our business model.\n\n\nNow turning to our reportable segment. Starting with the Data Center\nsegment. Revenue was a record $5.4 billion, up 39% year-over-year and 24%\nsequentially, driven by strong demand for EPYC processors and the continued\nramp of MI350 products. Data Center segment operating income was $1.8\nbillion or 33% of revenue compared to $1.2 billion or 30% a year ago,\nreflecting higher revenue and inventory reserve release, partially offset\nby continued investment to support our AI hardware and software road maps.\n\n\nClient and Gaming segment revenue was $3.9 billion, up 37% year-over-year,\ndriven primarily by strong demand for our leadership AMD Ryzen processors.\nOn a sequential basis, revenue was down 3% due to lower semi customer\nrevenue. The client business revenue was a record $3.1 billion, up 34% year-\nover-year and 13% sequentially, led by strong demand from both the channel\nand the PC OEMs and continued market share gains.\n\n\nThe gaming business revenue was $843 million, up 50% year-over-year,\nprimarily driven by higher semi customer revenue and strong demand for AMD\nRadeon GPUs. Sequentially, gaming revenue was down 35% due to lower semi\ncustomer sales. Client and Gaming segment operating income was $725 million\nor 18% of revenue compared to $496 million or 17% a year ago.\n\n\nEmbedded segment revenue was $950 million, up 3% year-over-year and 11%\nsequentially as demand strengthened across several end markets. Embedded\nsegment operating income was $357 million or 38% of revenue compared to\n$362 million or 39% a year ago.\n\n\nBefore I review the balance sheet and cash flow, as a reminder, we closed\nthe sale of ZT Systems manufacturing business to Sanmina in late October.\nThe fourth quarter financial results of the ZT manufacturing business are\nreported separately in our financial statement as discontinued operations\nand are excluded from our non-GAAP financials.\n\n\nTurning to the balance sheet and cash flow. During the quarter, we\ngenerated a record $2.3 billion in cash from continuing operations and a\nrecord of $2.1 billion in free cash flow. Inventory increased sequentially\nby approximately $607 million to $7.9 billion to support strong data center\ndemand. At the end of the quarter, cash, cash equivalents and short-term\ninvestments were $10.6 billion.\n\n\nFor the year, we repurchased 12.4 million shares and returned $1.3 billion\nto shareholders. We ended the year with $9.4 billion authorization\nremaining under our share repurchase program.\n\n\nNow turning to our first quarter 2026 outlook. We expect revenue to be\napproximately $9.8 billion, plus or minus $300 million, including\napproximately $100 million of MI308 sales to China. At the midpoint of our\nguidance, revenue is expected to be up 32% year-over-year, driven by strong\ngrowth in our Data Center and Client and Gaming segments and modest growth\nin our Embedded segment.\n\n\nSequentially, we expect revenue to be down approximately 5%, driven by\nseasonal decline in our Client and Gaming and Embedded segment, partially\noffset by growth in our Data Center segment. In addition, we expect fourth\nquarter non-GAAP gross margin to be approximately 55%. Non-GAAP operating\nexpense to be approximately $3.05 billion. Non-GAAP other net income to be\napproximately $35 million. Non-GAAP effective tax rate to be 13% and\ndiluted share count is expected to be approximately 1.65 billion shares.\n\n\nIn closing, 2025 was an outstanding year for AMD, reflecting disciplined\nexecution across the business to deliver strong revenue growth, increased\nprofitability and cash generation while investing aggressively in AI and\ninnovation to support our long-term growth strategy. Looking ahead, we are\nvery well positioned for continued strong top line revenue growth and\nearnings expansion in 2026 with a focus on driving data center AI growth,\noperating leverage and delivering long-term value to shareholders.\n\n\nWith that, I'll turn it back to Matt for the Q&A session.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor RelationsYes. Thank you\nvery much, Jean. Operator, please go ahead and open the Q&A session. Thank\nyou.\n\n\nQuestion and Answer\n\n\nOperator\n\n[Operator Instructions] And the first question comes from the line of Aaron\nRakers with Wells Fargo.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nLisa, at your Analyst Day back in November, you seem to kind of endorse the\nhigh $20 billion AI revenue expectation that was out there on the Street\nfor 2027. I know today, you're reaffirming the path to strong double-digit\ngrowth. So I guess my question is, can you talk a little bit about what\nyou've seen as far as customer engagements, how those might have expanded?\nI think you've alluded to in the past, multiple multi-gigawatt\nopportunities. Just any -- just double-click on what you've seen for the\nMI455 and Helios platform from a demand shaping perspective as we look into\nthe back half of the year?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Aaron. Thanks for the question. So first of all, I think the\nMI450 Series development is going extremely well. So we're very happy with\nthe progress that we have. We're right on track for a second half launch\nand beginning of production. And as it relates to sort of the shape of the\nramp and the customer engagements, I would say the customer engagements\ncontinue to proceed very well. We have obviously a very strong relationship\nwith OpenAI, and we're planning that ramp starting in the second half of\nthe year going into 2027. That is on track.\n\n\nWe're also working closely with a number of other customers who are very\ninterested in ramping MI450 quickly, just given the strength of the\nproduct, and we see that across both inference and training. And that is\nthe opportunity that we see in front of us. So we feel very good about sort\nof the data center growth overall for us in 2026 and then certainly going\ninto 2027, we've talked about tens of billions of dollars of data center AI\nrevenue, and we feel very good about that.\n\n\nOperator\n\nThe next question comes from the line of Tim Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nJean, I'm wondering if you can maybe give us a little bit of detail under\nthe hood for the March guidance. I know you basically told us that -- you\ntold us about, what, Embedded is going to be up a bit year-over-year.\nClient sounds like it's down seasonally, which I take to be maybe down 10%.\nSo can you give us a sense maybe of the other pieces?\n\n\nAnd then also, can you give us a sense of how Data Center GPU is going to\nramp through the year? I know it's a back half loaded year, but I think\npeople are thinking at least somewhere in the $14 billion range this year.\nThat's what investors are thinking. I don't -- I'm not asking you to\nendorse that. But if you can give us a little flavor for sort of how the\nramp will look for the year, that would be great.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nTim, thanks for your question. We're guiding one quarter at a time, but I\ncan give you some color about our Q1 guide. First is right, sequentially,\nwe guided a decline around 5%, but Data Center is actually going to be up.\nAnd when you think about it, right, our CPU business seasonal actually in a\nregular seasonal pattern, it's going to be down high single digit. And in\nour current guide, we actually guide CPU revenue up sequentially very\nnicely.\n\n\nAlso with the Data Center GPU side, we also feel really good about GPU\nrevenue, including China, will be also up. So very nice guide for the Data\nCenter overall. On the Client side, we do see seasonality sequentially\ndecline. Embedded and Gaming, they also have a seasonal decline.\n\n\nLisa T. Su\nChair, President & CEO\n\nAnd maybe, Tim, if I just give you a little bit on the full year\ncommentary. I think the important thing, as we look at the full year, we're\nvery bullish on the year. We're not -- if you look at the key themes, we're\nseeing very strong growth in the Data Center, and that's across 2 growth\nvectors. We see server CPU growth actually very strong. I mean we've talked\nabout the fact that CPUs are very important as AI continues to ramp. And\nwe've seen the CPU order book continue to strengthen as we go through the\nlast few quarters and especially over the last 60 days.\n\n\nSo we see that as a strong growth driver for us. As Jean said, we see\nserver CPU growing from Q4 into Q1 in what normally is seasonally down, and\nthat continues throughout the year. And then on the Data Center AI side,\nit's a very important year for us. It's really an inflection point. MI355\nhas done well, and we were pleased with the performance in Q4, and we\ncontinue to ramp that in the first half of the year. But as we get into the\nsecond half of the year, the MI450 is really an inflection point for us. So\nthat revenue will start in the third quarter, but it will ramp significant\nvolume in the fourth quarter as we get into 2027. So that gives you a\nlittle bit of sort of what the data center ramp looks like throughout the\nyear.\n\n\nOperator\n\nAnd the next question comes from the line of Vivek Arya with Bank of\nAmerica.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nFirst, just a clarification on what you're assuming for your China MI308\nsales beyond Q1. And then Lisa, specific to 2026, can your Data Center\nrevenues grow at your target 60% plus growth rate? I realize that that's a\nmultiyear target, but do you think that there are enough drivers, whether\nit's on the server CPU side or GPU side for you to grow at that target base\neven in 2026?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Vivek. So let me talk a little bit about China first because\nthat's, I think, important for us to make sure that's clear. Look, we were\npleased to have some MI308 sales in the fourth quarter. They were actually\na license that was approved through work with the administration. And those\norders were actually from very early in 2025. And so we saw some revenue in\nQ4, and we're forecasting for about $100 million of revenue in Q1. We are\nnot forecasting any additional revenue from China just because it's a very\ndynamic situation.\n\n\nSo given that it's a dynamic situation, we're still waiting for -- we've\nsubmitted licenses for the MI325, and we're continuing to work with\ncustomers and understanding sort of their customer demand. We thought it\nprudent not to forecast any additional revenue other than the $100 million\nthat we called out in the Q1 guide.\n\n\nNow as it relates to overall Data Center, as I mentioned in the question to\nTim, like we're very bullish about data center. I think the combination of\ndrivers that we have across our CPU franchise, I mean, the EPYC product\nline, both Turin and Genoa continue to ramp well. And in the second half of\nthe year, we will be launching Venice, which we believe actually extends\nour leadership and the MI450 ramp, which is also very significant in the\nsecond half of 2026. We're not obviously guiding specifically by segment,\nbut the long-term target of, let's call it, greater than 60% is certainly\npossible in 2026.\n\n\nOperator\n\n[Operator Instructions] The next question comes from the line of C.J. Muse\nwith Cantor.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI'm curious on the server CPU side of the house and given the dramatic\ntightness, curious your ability to source incremental capacity from TSMC\nand elsewhere. And I guess, how long will it take for that to see wafers\nout? And how should we think about the implications for kind of the growth\ntrajectory throughout all of calendar '26? And I guess as part of that, if\nyou could speak to how we should be thinking about inflection in pricing as\nwell, that would be very helpful.\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, C.J. So a couple of points about the server CPU market. First of all,\nwe think the overall server CPU TAM is going to grow, let's call it, strong\ndouble digits in 2026, just given the -- as we said, the relationship\nbetween CPU demand and overall AI ramp. So I think that's a positive.\n\n\nRelative to our ability to support that, we've been seeing this trend for\nthe last couple of quarters. So we have increased our supply capacity\ncapability for server CPUs. And that's one of the reasons we're able to\nincrease our Q1 guide as it relates to the server business, and we see the\nability to continue to grow that throughout the year. There's no question\nthat demand continues to be strong. And so we're working with our supply\nchain partners to increase supply as well. But from what we see today, I\nthink the overall server situation is strong, and we are increasing supply\nto address that.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nC.J., do you have a follow-up question?\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI do maybe for Jean, if you could kind of touch on gross margins through\nthe year and as you balance kind of strengthening server CPU with perhaps\ngreater GPU accelerating in the second half. Is there kind of a framework\nthat we should be working off of?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes. Thank you for the question. We are very pleased with our gross margin\nQ4 performance and the Q1 guide at 55%, which actually is 130 basis points\nup year-over-year, while we continue to ramp our MI355 year-over-year very\nsignificantly. I think we are benefiting from a very favorable product mix\nacross all our business. If you think about in Data Center, we're ramping\nour new product, new generation product, Turin and MI355, which helps the\ngross margin. In Client, we continue to move up the stack and also gaining\nmomentum in our commercial business.\n\n\nOur Client business gross margin has been improving nicely. In addition,\ncertainly, we see the recovery of our Embedded business, which is also\nmargin accretive. So all those tailwinds we are seeing, we continue to see\nin the next few quarters. And when MI450 ramp, of course, in Q4, our gross\nmargin will be driven largely by mix. And I think we'll give you more color\nwhen we get there. But overall, we feel really good about our gross margin\nprogression this year.\n\n\nOperator\n\nThe next question comes from the line of Joe Moore with Morgan Stanley.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOn the MI455 ramp, will 100% of the business be racks? Will there be kind\nof an 8-way server business around that architecture? And then is the\nrevenue recognition when you ship to the rack vendor? Or is there something\nto understand about that?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Joe. So we do have multiple variants of the MI450 series, including an\n8-way GPU form factor. But for 2026, I would say the vast majority of it is\ngoing to be Rack Scale solutions. And yes, we will take revenue when we\nship to the rack builder.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOkay. Great. And then can you talk to any risks that you may have in terms\nof once you get silicon out, turning that into racks, any potential issues\nas you ramp that? I know your competitor had some last year, and you said\nyou learned from that. Is there anything you've done with kind of\nprebuilding racks to sort of ensure you won't have those issues? Just any\nrisk that we need to understand around that?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean, I think, Joe, the main thing is the development is going\nreally well. It is -- we're right on track with the MI450 series as well as\nthe Helios rack development. We've done a lot of testing already both at\nthe Rack Scale level as well as at the silicon level. So far, so good. We\nare getting, let's call it, a lot of input from our customers on things to\ntest so that we can do a lot of testing in parallel. And our expectation is\nthat we will be on track for our second half launch.\n\n\nOperator\n\nOur next question comes from the line of Stacy Rasgon with Research.\n\n\nStacy Aaron Rasgon\nBernstein Institutional Services LLC, Research Division\n\nFirst, Lisa, I just wanted to ask about OpEx. Like every quarter, you guys\nare guiding it up and then it's coming in even higher and then you're\nguiding it up again. And I understand, given the growth trajectory that you\nneed to invest. But how should we think about the ramp of that OpEx and\nthat spending number, especially as the GPU revenue starts to inflect? Do\nwe get leverage on that? Or should we be expecting the OpEx to be growing\neven more materially as the AI revenue starts to ramp?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Stacy. Thanks for the question. Look, I think in terms of OpEx,\nwe're at a point where we have very high conviction in the road map that we\nhave. And so in 2025, as the revenue increased. We did lean in on OpEx, and\nI think it was for all the right reasons. As we get into 2026 and as we see\nsome of the significant growth that we're expecting, we should absolutely\nsee leverage. And the way to think about it is we've always said in our\nlong-term model that OpEx should grow slower than revenue, and we would\nexpect that in 2026 as well, especially as we get into the second half of\nthe year and we see inflection in the revenue. But at this point, I think\nthe -- if you look at our free cash flow generation and the overall revenue\ngrowth, I think the investment in OpEx is absolutely the right thing to do.\n\n\n\nStacy Aaron Rasgon\nBernstein Institutional Services LLC, Research Division\n\nFor my follow-up, I actually have 2 sort of one-line answers I'm looking\nfor. Just first, the $100 million in China revenue in Q1, does that also\ndrop through a 0 cost basis like we had in Q4? And is that a margin\nheadwind? And number two, I know you don't give us the AI number, but could\nyou just give us the annual like 2025 Instinct number now that we're\nthrough the year? Like how big was it?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nSo Stacy, let me answer your first question on the $100 million revenue in\nQ1. Actually, the inventory reserve reversed in Q4, which was $360 million,\nnot only associated with the Q4 revenue, China revenue, but also covers the\n$100 million revenue we expect to ship in Q1 to China with our MI308. So\nthe Q1 gross margin guide is a very clean guide.\n\n\nLisa T. Su\nChair, President & CEO\n\nAnd Stacy, for your second question, as you know, we don't guide at the\nbusiness level, but to help you with your models, I think you can -- if you\nlook at the Q4 data center AI number, even if you were to back out the\nChina number, which was, let's call it, not a recurring number, you would\nstill see growth -- you'll see growth from Q3 to Q4. So that should help\nyou a little bit with your modeling.\n\n\nOperator\n\nAnd the next question comes from the line of Joshua Buchalter with TD\nCowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nI want to ask about clients. So the segment beat pretty handily in the\nfourth quarter, and I recognize you guys have been gaining share with\nRyzen. But I think given what we've been seeing in the memory market,\nthere's a lot of concern about inflationary costs and the potential for\npull-ins. Were there any changes in your order patterns during the quarter?\nAnd maybe bigger picture, how are you thinking about client growth and the\nhealth of that market into 2026?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Thanks for the question, Josh. The client market has performed\nextremely well for us throughout 2025, very strong growth for us, both in\nterms of ASP mixing up the stack as well as just unit growth. Going into\n2026, we are certainly watching the development of the business. I think\nthe PC market is an important market. Based on everything that we see\ntoday, we're probably seeing the PC TAM down a bit just given some of the\ninflationary pressures of the commodities pricing, including memory.\n\n\nThe way we are modeling the year is, let's call it, second half a bit\nsubseasonal to first half, just given everything that we see. Even in that\nenvironment with the PC market down, we believe we can grow the -- our PC\nbusiness. And our focus areas are enterprise. That's a place where we're\nmaking a very nice progress in 2025, and we expect that into 2026 and just\ncontinuing to grow sort of at the premium higher end of the market.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nAnd then I want to ask about the Instinct family. So we've seen your big\nGPU competitor make a deal with an SRAM-based spatial architecture provider\nand then OpenAI has reportedly been linked to one as well. Could you speak\nto the competitive implications of that? You've done well in inferencing, I\nthink, partly because of your leadership in HBM content. So I was wondering\nif you could maybe address the pull seemingly motivated by lower latency\ninference and how Instinct is positioned to service this if you're indeed\nseeing it as well.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I think, Josh, it's really, I think, the evolution that you might\nexpect as the AI market matures. What we're seeing is as inference ramps,\nthe -- really the tokens per dollar or the efficiency of the inference\nstack becomes more and more important. As you know, with our chiplet\narchitecture, we have a lot of ability to optimize across inference\ntraining and even across sort of the different stages of inference as well.\n\n\n\nSo I think I view this as very much as you go into the future, you'll see\nmore workload optimized products. And you can do that with GPUs as well as\nwith other more ASIC-like architectures. I think we have the full compute\nstack to do all of those things. And from that standpoint, we're going to\ncontinue to lean into inference as we view that as a significant\nopportunity for us in addition to ramping our training capabilities.\n\n\nOperator\n\nAnd the next question comes from the line of Ben Reitzes with Melius\nResearch.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nLisa, I wanted to ask you about OpenAI. I'm sure a lot of the volatility\nout there is not lost on you. Is everything on track for the second half\nfor starting the 6 gigawatts and the 3.5-year time line as far as you know?\nAnd is there any other color that you'd just like to give on that\nrelationship? And then I have a follow-up.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean I think, Ben, what I would say is we're very much working in\npartnership with OpenAI as well as our CSP partners to deliver on MI450\nseries and deliver on the ramp. The ramp is on schedule to start in the\nsecond half of the year. MI450 is doing great. Helios is doing well. We are\nin, let's call it, deep co-development across all of those parties. And as\nwe look forward, I think we are optimistic about the MI450 ramp for OpenAI.\nBut I also want to remind everyone that we have a broad set of customers\nthat are very excited about MI450 series. And so in addition to the work\nthat we're doing with OpenAI, there are a number of customers that we're\nworking to ramp in that time frame as well.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nAll right. I appreciate that. And I wanted to shift to the server CPU and\njust talk about x86 versus ARM. There's some view out there that x86 has a\nparticular edge in agents, big picture, do you agree with that? And what\nare you seeing from customers? And in particular, obviously, your big\ncompetitor is going to be selling an ARM CPU separately now in the second\nhalf. So if there's just anything on that competitive dynamic versus ARM\nand what NVIDIA is doing and your views on that, that'd be great to hear.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Ben, what I would say about the CPU market is there is a great need\nfor high-performance CPUs right now. And that goes towards agentic\nworkloads where when you have these AI processes or AI agents that are\nspinning off a lot of work, in an enterprise, they're actually going to a\nlot of traditional CPU tasks and the vast majority of them are on x86\ntoday. I think the beauty of EPYC is that we've optimized. We've done\nworkload optimization. So we have the best cloud processor out there. We\nhave the best enterprise processor. We also have some lower-cost variants\nfor storage and other elements. And I think all of that comes into play as\nwe think about the entirety of the AI infrastructure that needs to be put\nin place.\n\n\nI think the CPUs are going to continue to be as important as a piece of the\nAI infrastructure ramp. And that's one of the things that we mentioned at\nour Analyst Day back in November, is really this multiyear CPU cycle, and\nwe continue to see that. I think we've optimized EPYC to satisfy all of\nthose workloads, and we're going to continue to work with our customers to\nexpand our EPYC footprint.\n\n\nOperator\n\nAnd the next question comes from the line of Tom O'Malley with Barclays.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nLisa, I just wanted to ask, you mentioned on memory earlier as a sticking\npoint in terms of inflationary cost. Different customers do this in\ndifferent ways, different suppliers do this in different ways. But can you\nmaybe talk about your procurement of memory, when that takes place,\nparticularly on the HBM side? Is that something that gets done a year in\nadvance, 6 months in advance? Different accelerator guys have talked about\ndifferent time lines. I would be curious to kind of hear when you do the\nprocurement.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean, given the lead times for things like HBM and wafers and these\nparts of the supply chain, I mean, we're working closely with our suppliers\nover a multiyear time frame in terms of what we see in demand, how we ramp,\nhow we ensure that our development is very closely tied together. So I feel\nvery good about our supply chain capabilities. We have been planning for\nthis ramp. So independent of the current market conditions, we've been\nplanning for a significant ramp in our -- both CPU as well as our GPU\nbusiness over the past couple of years. And so from that standpoint, I\nthink we're well positioned to grow substantially in 2026. And now we are\nalso doing multiyear agreements that extend beyond that given the tightness\nof the supply chain.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nAnd just as a follow-up, you've seen a variety of different things in the\nindustry in terms of system accelerators, so KV cache offload, more\ndiscrete ASIC style compute, CPX. If you look at what your competitors are\ndoing and you look at your first generation of system architecture coming\nout, maybe spend some time on -- do you see yourself following in the\nfootsteps of some of these different type of architectural changes? Do you\nthink that you'll go in a different direction? Anything just on the\nevolution of your system-based architecture and then the adjoining products\nand/or silicon within?\n\n\nLisa T. Su\nChair, President & CEO\n\nI think, Tom, what we have is the ability with a very flexible\narchitecture, with our chiplet architecture, and then we also have a\nflexible platform architecture that allows us to really have different\nsystem solutions for the different requirements. I think we're very\ncognizant that there will be different solutions. So there's no -- I've\noften said there's no one size fits all, and I'll say that again, there's\nno one size fits all.\n\n\nBut that being the case, it's clear that the Rack Scale architecture is\nvery, very good for the highest end applications when you're talking about\ninference -- distributed inference and training. But we also see an\nopportunity with enterprise AI to use some of these other form factors. And\nso we're investing across that spectrum.\n\n\nOperator\n\nAnd the next question comes from the line of Ross Seymore with Deutsche\nBank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nA couple of I guess my first question is back on the gross margin side of\nthings. As you go from the MI300 to the 400 to the 500 eventually, do you\nsee any changes in the gross margin throughout that period? In the past,\nyou've talked about optimizing dollars more so than percentages. But just\non the percentage side, does it go up, down? Or is there volatility as you\ngo from one to the next for any reason? Just wondered on the trajectory\nthere.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nRoss, thank you for the question. At a very high level, each generation, we\nactually provide much more capabilities, more memory, help our customers\nmore. So in general, the gross margin should progress each generation when\nyou offer more capabilities to your customers. But typically, when you\nfirst ramp -- at the beginning of ramp of generation, it tends to be lower\nwhen you get to the scale, get to the yield improvement, the testing\nimprovement and also overall performance improvement, you will see gross\nmargin improving within each generation. So it's kind of a dynamic gross\nmargin. But in the longer term, you should expect each generation should\nhave a higher gross margin.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nAnd then one on a small segment of your business, but it seems quite\nvolatile and you talked a little bit about further off than you usually do\nis the gaming side of things. What is the magnitude down you're talking\nabout this year? Because in 2025, you thought it was going to be flat and\nit ended up growing 50%, which was a nice positive surprise. But now that\nyou're talking about this year being down, but then the next-gen Xbox\nramping in 2027, I just hope to get some color on what you see as kind of\nthe annual trajectory there.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes. So Lisa can add more. So 2026, actually, it's the seventh year of\ncurrent product cycle. Typically, when you're at this stage of the cycle,\nrevenue tend to come down. We do expect the revenue on the semi customer\nrevenue side to come down significantly double digit for 2026, as Lisa\nmentioned in her prepared remarks. For the next generation?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I think we'll -- I mean we'll certainly talk about that going forward.\nBut as we ramp the new generation, you would expect a reversal of that.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nOperator, I think we have time for one more caller on the call, please.\n\n\nOperator\n\nAnd our final question comes from the line of Jim Schneider with Goldman\nSachs.\n\n\nJames Edward Schneider\nGoldman Sachs Group, Inc., Research Division\n\nRelative to the ramp of your recallable systems, would you expect any kind\nof bottleneck in terms of supply constraints in terms of the ramp as you\nramp the second half of the year to potentially impact or limit the revenue\ngrowth? In other words, maybe talk about whether you expect supply to\nreally kind of mute the growth in Q4 sequentially relative to -- sorry, Q3\nrelative to Q4?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Jim, we are planning this at the -- every component level. So I think\nrelative to our data center AI ramp, I do not believe that we will be\nsupply limited in terms of the ramp that we put in place. I think we have\nan aggressive ramp. I think it's a very doable ramp. And as we think about\nthe size and scale of AMD, clearly, our priority is ensuring that the data\ncenter ramps go very well, and that's both on the data center AI, the GPU\nside as well as on the CPU side.\n\n\nJames Edward Schneider\nGoldman Sachs Group, Inc., Research Division\n\nAnd then maybe as a follow-up to the earlier question on OpEx. Could you\nmaybe address what are some of the largest investment areas you made in\n2025? And then what are the largest incremental OpEx investment areas for\n'26?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes, Jim, on the 2025 investment, the priority and the investment --\nlargest investment in Data Center AI. Our hardware road map, we accelerated\nthat road map. We expand our software capabilities. We also acquired ZT\nSystems, which added significant system-level solutions and capabilities.\nThose are the primary investment in 2025.\n\n\nWe also invest heavily in go-to-market to really expand our go-to-market\ncapabilities to support the revenue growth and also expand our commercial\nbusiness and enterprise business for our CPU franchise. In 2026, you should\nexpect us to continue to invest aggressively. But as Lisa mentioned\nearlier, we do expect revenue to expand faster than operating expense\nincrease to drive the earnings per share expansion.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nAll right. Thank you, everybody, for participating on the call. Operator, I\nthink we can go ahead and close the call now. Thank you. Good evening.\n\n\nOperatorThank you. And ladies and gentlemen, that does conclude the\nquestion-and-answer session, and that also concludes today's\nteleconference. You may disconnect your lines at this time, and have a\ngreat rest of the day.\nCopyright  2026 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2026 S&P Global Market Intelligence.\n\n",
  "presentation_text": "Operator\n\nGreetings, and welcome to the AMD Fourth Quarter and Full Year 2025\nConference Call. [Operator Instructions]. And please note that this\nconference is being recorded.\n\n\nI will now turn the conference over to Matt Ramsay, VP of Financial\nStrategy and IR. Thank you. You may begin.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nThank you, and welcome to AMD's Fourth Quarter and 2025 Full Year Financial\nResults Conference Call. By now, you should have had the opportunity to\nreview a copy of our earnings press release and accompanying slides. If you\nhave not had the opportunity to review these materials, they can be found\non the Investor Relations page of amd.com.\n\n\nToday, we will refer primarily to non-GAAP financial measures on the call.\nThe full non-GAAP to GAAP reconciliations are available in today's press\nrelease and in the slides posted on our website. Participants in today's\nconference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our\nExecutive Vice President, CFO and Treasurer. This is a live call and will\nbe replayed via webcast on our website.\n\n\nBefore we begin, I would like to note that Mark Papermaster, Executive Vice\nPresident and CTO, will present at Morgan Stanley's TMT Conference on\nTuesday, March 3. Today's discussions contain forward-looking statements\nbased on our current beliefs, assumptions and expectations, speak only as\nof today and as such, involve risks and uncertainties that could cause\nactual results to differ materially from our current expectations. Please\nrefer to the cautionary statement in our press release for more information\non factors that could cause actual results to differ materially.\n\n\nWith that, I will hand the call to Lisa.\n\n\nLisa T. Su\nChair, President & CEO\n\nThank you, Matt, and good afternoon to all those listening today. 2025 was\na defining year for AMD with record revenue, net income and free cash flow\ndriven by broad-based demand for our high-performance computing and AI\nproducts. We ended the year with significant momentum with every part of\nour business performing very well. We saw demand accelerate across the data\ncenter, PC, gaming and embedded markets, launched the broadest set of\nleadership products in our history, gained significant server and PC\nprocessor share and rapidly scaled our Data Center AI business as Instinct\nand ROCm adoption increased with cloud, enterprise and AI customers.\n\n\nLooking at our fourth quarter, fourth quarter revenue grew 34% year-over-\nyear to $10.3 billion, led by record EPYC, Ryzen and Instinct processor\nsales. Net income increased 42% to a record $2.5 billion and free cash flow\nnearly doubled year-over-year to a record $2.1 billion. For the full year,\nrevenue grew 34% to $34.6 billion, and we added more than $7.6 billion of\nData Center segment and client revenue.\n\n\nTurning to our fourth quarter segment results. Data Center segment revenue\nincreased 39% year-over-year to a record $5.4 billion, led by accelerating\nInstinct MI350 Series GPU deployments and server share gains. In server,\nadoption of fifth-gen EPYC turn CPUs accelerated in the quarter, accounting\nfor more than half of the total server revenue. Fourth-gen EPYC sales were\nalso robust as our prior generation CPUs continue to deliver superior\nperformance and TCO compared to competitive offerings across a wide range\nof workloads. As a result, we had record server CPU sales to both cloud and\nenterprise customers in the quarter and exited the year with record share.\n\n\nIn cloud, hyperscaler demand was very strong as North American customers\nexpanded deployments. EPYC-powered public cloud offerings grew\nsignificantly in the quarter with AWS, Google and others launching more\nthan 230 new AMD instances. Hyperscalers launched more than 500 AMD-based\ninstances in 2025, increasing the number of EPYC cloud instances more than\n50% year-over-year to nearly 1,600.\n\n\nIn the enterprise, we are seeing a meaningful shift in EPYC adoption,\ndriven by our leadership performance, expanded platform availability, broad\nsoftware enablement and increased go-to-market programs. The leading server\nproviders now offer more than 3,000 solutions powered by fourth and fifth-\ngen EPYC CPUs that are optimized for all major enterprise workloads. As a\nresult, the number of large businesses deploying EPYC on-prem more than\ndoubled in 2025, and we exited the year with record server sell-through.\n\n\nLooking ahead, server CPU demand remains very strong. Hyperscalers are\nexpanding their infrastructure to meet growing demand for cloud services\nand AI while enterprises are modernizing their data centers to ensure they\nhave the right compute required to enable new AI workflows. Against this\nbackdrop, EPYC has become the processor of choice for the modern data\ncenter, delivering leadership performance, efficiency and TCO. Our next-\ngeneration Venice CPU extends our leadership across each of these metrics.\nCustomer pull for Venice is very high with engagements underway to support\nlarge-scale cloud deployments and broad OEM platform availability when\nVenice launches later this year.\n\n\nTurning to our Data Center AI business. We delivered record Instinct GPU\nrevenue in the fourth quarter, led by the ramp of MI350 Series shipments.\nWe also had some revenue from MI308 sales to customers in China. Instinct\nadoption broadened in the quarter. Today, 8 of the top 10 AI companies use\nInstinct to power production workloads across a growing range of use cases.\nWith the MI350 Series, we are entering the next phase of Instinct adoption,\nexpanding our footprint with existing partners and adding new customers.\n\n\nIn the fourth quarter, hyperscalers expanded MI350 Series availability,\nleading AI companies scale their deployments to support additional\nworkloads and multiple neocloud providers launched MI350 Series offerings\nthat deliver on-demand access to Instinct infrastructure in the cloud.\n\n\nTurning to our AI software stack. We expanded the ROCm ecosystem in the\nfourth quarter, enabling customers to deploy Instinct faster and with\nhigher performance across a broader range of workloads. Millions of large\nlanguage and multimodal models run out of the box on AMD with the leading\nmodels launching with day zero support for Instinct GPUs. This capability\nhighlights our rapidly expanding open source community enablement,\nincluding new upstream integration of AMD GPUs in vLLM, one of the most\nwidely used inference engines.\n\n\nTo drive Instinct adoption with industry-specific use cases, we're also\nadding support for domain-specific models in key verticals. As one example,\nin health care, we added ROCm support for the leading medical imaging\nframework to enable developers to train and deploy highly performing deep\nlearning models on Instinct GPUs. For large businesses, we introduced our\nenterprise AI suite, a full stack software platform with enterprise-grade\ntools, inference microservices and solutions blueprints designed to\nsimplify and accelerate production deployments at scale.\n\n\nWe also announced a strategic partnership with Tata Consultancy Services to\nco-develop industry-specific AI solutions and help customers deploy AI\nacross their operations. Looking ahead, customer engagements for our next-\ngen MI400 Series and Helios platform continue expanding. In addition to our\nmulti-generation partnership with OpenAI to deploy 6 gigawatts of Instinct\nGPUs, we are in active discussions with other customers on at-scale\nmultiyear deployments starting with Helios and MI450 later this year.\n\n\nWith the MI400 series, we are also expanding our portfolio to address the\nfull range of cloud, HPC and enterprise AI workloads. This includes MI455X\nand Helios for AI superclusters, MI430X for HPC and sovereign AI and MI440X\nservers for enterprise customers requiring leadership training and\ninference performance in a compact 8-GPU solution that integrates easily\ninto existing infrastructure.\n\n\nMultiple OEMs publicly announced plans to launch Helios systems in 2026\nwith deep engineering engagements underway to support smooth production\nramps. In December, HPE announced that they will offer Helios racks with\npurpose-built HPE Juniper Ethernet switches, an optimized software for high-\nbandwidth scale-up networking. And in January, Lenovo announced plans to\noffer Helios racks. MI430X adoption also grew in the quarter with new\nexascale class supercomputers announced by GENCI in France and HLRS in\nGermany.\n\n\nLooking further ahead, development of our next-generation MI500 Series is\nwell underway. MI500 is powered by our CDNA 6 architecture built on\nadvanced 2-nanometer process technology and features high-speed HBM4E\nmemory. We are on track to launch MI500 in 2027 and expect MI500 to deliver\nanother major leap in AI performance to power the next wave of large-scale\nmultimodal models.\n\n\nIn summary, our AI business is accelerating with the launch of MI400 Series\nand Helios representing a major inflection point for the business as we\ndeliver leadership performance and TCO at the chip, compute tray and rack\nlevel. Based on the strength of our EPYC and Instinct road maps, we are\nwell positioned to grow Data Center segment revenue by more than 60%\nannually over the next 3 to 5 years and scale our AI business to tens of\nbillions in annual revenue in 2027.\n\n\nTurning to Client and Gaming. Segment revenue increased 37% year-over-year\nto $3.9 billion. In client, our PC processor business performed\nexceptionally well. Revenue increased 34% year-over-year to a record $3.1\nbillion, driven by increased demand for multiple generations of Ryzen\ndesktop and mobile CPUs. Desktop CPU sales set a record for the fourth\nconsecutive quarter. Ryzen CPUs topped the bestseller list at major global\nretailers and e-tailers throughout the holiday period with strong demand\nacross all price points in every region, driving record desktop channel\nsell-out.\n\n\nIn mobile, strong demand for AMD-powered notebooks drove record Ryzen PC\nsell-through in the quarter. That momentum extended into commercial PCs,\nwhere Ryzen adoption accelerated as we established a new long-term growth\nengine for our client business. Sell-through of Ryzen CPUs for commercial\nnotebooks and desktops grew by more than 40% year-over-year in the fourth\nquarter, and we closed large wins with major telecom, financial services,\naerospace, automotive, energy and technology customers.\n\n\nAt CES, we expanded our Ryzen portfolio with CPUs that further extend our\nperformance leadership. Our new Ryzen AI 400 mobile processors deliver\nsignificantly faster content creation and multitasking performance than the\ncompetition. Notebooks powered by Ryzen AI 400 are already available with\nthe broadest lineup of AMD-based consumer and commercial AI PCs set to\nlaunch throughout the year. We also introduced our Ryzen AI Halo platform,\nthe world's smallest AI development system, featuring our highest-end Ryzen\nAI MAX processor with 128 gigabytes of unified memory that can run models\nwith up to 200 billion parameters locally.\n\n\nIn gaming, revenue increased 50% year-over-year to $843 million. Semi-\ncustom sales increased year-over-year and declined sequentially as\nexpected. For 2026, we expect semi-custom SoC annual revenue to decline by\na significant double-digit percentage as we enter the seventh year of what\nhas been a very strong console cycle.\n\n\nFrom a product standpoint, Valve is on track to begin shipping its AMD-\npowered steam machine early this year and development of Microsoft's next-\ngen Xbox featuring an AMD semi-custom SoC is progressing well to support a\nlaunch in 2027. Gaming GPU revenue also increased year-over-year with\nhigher channel sell-out driven by demand throughout the holiday sales\nperiod for our latest generation Radeon RX 9000 series GPUs. We also\nlaunched FSR 4 Redstone in the quarter, our most advanced AI-powered\nupscaling technology, delivering higher image quality and smoother frame\nrates for gamers.\n\n\nTurning to our Embedded segment. Revenue increased 3% year-over-year to\n$950 million, led by strength with test and measurement and aerospace\ncustomers and growing adoption of our Embedded x86 CPUs. Channel sell-\nthrough accelerated in the quarter as end customer demand improved across\nseveral end markets, led by test, measurement and emulation. Design win\nmomentum remains one of the clearest indicators of long-term growth for our\nembedded business, and we delivered another record year. We closed $17\nbillion in design wins in 2025, up nearly 20% year-over-year as we've now\nwon more than $50 billion of embedded designs since acquiring Xilinx.\n\n\nWe also strengthened our Embedded portfolio in the quarter. We began\nproduction of our Versal AI Edge Gen 2 SoCs for low-latency inference\nworkloads and started shipping our highest-end Spartan UltraScale+ devices\nfor cost-optimized application. We also launched new embedded CPUs,\nincluding our EPYC 2005 series for network security and industrial edge\napplications, Ryzen P100 series for in-vehicle infotainment and industrial\nsystems and Ryzen X100 series for physical AI and autonomous platforms.\n\n\nIn summary, 2025 was an excellent year for AMD, marking the start of a new\ngrowth trajectory for the company. We are entering a multiyear demand super\ncycle for high performance and AI computing that is creating significant\ngrowth opportunities across each of our businesses. AMD is well positioned\nto capture that growth with highly differentiated products, a proven\nexecution engine, deep customer partnerships and significant operational\nscale.\n\n\nAnd as AI reshapes the compute landscape, we have the breadth of solutions\nand partnerships required for end-to-end leadership. From Helios in the\ncloud for at-scale training and inference to an expanded Instinct portfolio\nfor sovereign, supercomputing and enterprise AI deployment. At the same\ntime, demand for EPYC CPUs is surging as agentic and emerging AI workloads\nrequire high-performance CPUs to power head nodes and run parallel tasks\nalongside GPUs. And at the edge and in PCs where AI adoption is just\nbeginning, our industry-leading Ryzen and Embedded processors are powering\nreal-time on-device AI. As a result, we expect significant top line and\nbottom line growth in 2026, led by increased adoption of EPYC and Instinct,\ncontinued client share gains and a return to growth in our Embedded\nsegment.\n\n\nLooking further ahead, we see a clear path to achieve the ambitious targets\nwe laid out at our Financial Analyst Day last November, including growing\nrevenue at greater than 35% CAGR over the next 3 to 5 years, significantly\nexpanding operating margins and generating annual EPS of more than $20 in\nthe strategic time frame, driven by growth in all of our segments and the\nrapid scaling of our Data Center AI business.\n\n\nNow I'll turn the call over to Jean to provide additional color on our\nfourth quarter results and full year results. Jean?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of\nour financial results and then provide our current outlook for the first\nquarter of fiscal 2026.\n\n\nAMD executed very well in 2025, delivering record revenue of $34.6 billion,\nup 34% year-over-year, driven by 32% growth in our Data Center segment and\n51% growth in our Client and Gaming segment. Gross margin was 52%, and we\ndelivered record earnings per share of $4.17, up 26% year-over-year while\ncontinuing to invest aggressively in AI and the data center to support our\nlong-term growth.\n\n\nFor the fourth quarter of 2025, revenue was a record $10.3 billion, growing\n34% year-over-year, driven by strong growth in the Data Center and Client\nand Gaming segment, including approximately $390 million in revenue from\nMI308 sales to China, which was not included in our fourth quarter\nguidance. Revenue was up 11% sequentially, primarily driven by continued\nstrong growth in data center from both server and Data Center AI business\nas well as a return to year-over-year growth in the Embedded segment.\n\n\nGross margin was 57%, up 290 basis points year-over-year. We benefited from\nthe release of $360 million in previously writing down MI308 inventory\nreserves. Excluding the inventory reserve release and MI308 revenue from\nChina, gross margin would have been approximately 55%, up 80 basis points\nyear-over-year, driven by favorable product mix.\n\n\nOperating expenses were $3 billion, an increase of 42% year-over-year as we\ncontinue to invest in R&D go-to-market activities to support our AI road\nmap and long-term growth opportunities as well as higher employee\nperformance-based incentives. Operating income was a record $2.9 billion,\nrepresenting a 28% operating margin. Tax, interest and other resulted in a\nnet expense of approximately $335 million.\n\n\nFor the fourth quarter, diluted earnings per share was a record $1.53, an\nincrease of 40% year-over-year, reflecting strong execution and operating\nleverage in our business model.\n\n\nNow turning to our reportable segment. Starting with the Data Center\nsegment. Revenue was a record $5.4 billion, up 39% year-over-year and 24%\nsequentially, driven by strong demand for EPYC processors and the continued\nramp of MI350 products. Data Center segment operating income was $1.8\nbillion or 33% of revenue compared to $1.2 billion or 30% a year ago,\nreflecting higher revenue and inventory reserve release, partially offset\nby continued investment to support our AI hardware and software road maps.\n\n\nClient and Gaming segment revenue was $3.9 billion, up 37% year-over-year,\ndriven primarily by strong demand for our leadership AMD Ryzen processors.\nOn a sequential basis, revenue was down 3% due to lower semi customer\nrevenue. The client business revenue was a record $3.1 billion, up 34% year-\nover-year and 13% sequentially, led by strong demand from both the channel\nand the PC OEMs and continued market share gains.\n\n\nThe gaming business revenue was $843 million, up 50% year-over-year,\nprimarily driven by higher semi customer revenue and strong demand for AMD\nRadeon GPUs. Sequentially, gaming revenue was down 35% due to lower semi\ncustomer sales. Client and Gaming segment operating income was $725 million\nor 18% of revenue compared to $496 million or 17% a year ago.\n\n\nEmbedded segment revenue was $950 million, up 3% year-over-year and 11%\nsequentially as demand strengthened across several end markets. Embedded\nsegment operating income was $357 million or 38% of revenue compared to\n$362 million or 39% a year ago.\n\n\nBefore I review the balance sheet and cash flow, as a reminder, we closed\nthe sale of ZT Systems manufacturing business to Sanmina in late October.\nThe fourth quarter financial results of the ZT manufacturing business are\nreported separately in our financial statement as discontinued operations\nand are excluded from our non-GAAP financials.\n\n\nTurning to the balance sheet and cash flow. During the quarter, we\ngenerated a record $2.3 billion in cash from continuing operations and a\nrecord of $2.1 billion in free cash flow. Inventory increased sequentially\nby approximately $607 million to $7.9 billion to support strong data center\ndemand. At the end of the quarter, cash, cash equivalents and short-term\ninvestments were $10.6 billion.\n\n\nFor the year, we repurchased 12.4 million shares and returned $1.3 billion\nto shareholders. We ended the year with $9.4 billion authorization\nremaining under our share repurchase program.\n\n\nNow turning to our first quarter 2026 outlook. We expect revenue to be\napproximately $9.8 billion, plus or minus $300 million, including\napproximately $100 million of MI308 sales to China. At the midpoint of our\nguidance, revenue is expected to be up 32% year-over-year, driven by strong\ngrowth in our Data Center and Client and Gaming segments and modest growth\nin our Embedded segment.\n\n\nSequentially, we expect revenue to be down approximately 5%, driven by\nseasonal decline in our Client and Gaming and Embedded segment, partially\noffset by growth in our Data Center segment. In addition, we expect fourth\nquarter non-GAAP gross margin to be approximately 55%. Non-GAAP operating\nexpense to be approximately $3.05 billion. Non-GAAP other net income to be\napproximately $35 million. Non-GAAP effective tax rate to be 13% and\ndiluted share count is expected to be approximately 1.65 billion shares.\n\n\nIn closing, 2025 was an outstanding year for AMD, reflecting disciplined\nexecution across the business to deliver strong revenue growth, increased\nprofitability and cash generation while investing aggressively in AI and\ninnovation to support our long-term growth strategy. Looking ahead, we are\nvery well positioned for continued strong top line revenue growth and\nearnings expansion in 2026 with a focus on driving data center AI growth,\noperating leverage and delivering long-term value to shareholders.\n\n\nWith that, I'll turn it back to Matt for the Q&A session.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor RelationsYes. Thank you\nvery much, Jean. Operator, please go ahead and open the Q&A session. Thank\nyou.",
  "qa_text": "Operator\n\n[Operator Instructions] And the first question comes from the line of Aaron\nRakers with Wells Fargo.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nLisa, at your Analyst Day back in November, you seem to kind of endorse the\nhigh $20 billion AI revenue expectation that was out there on the Street\nfor 2027. I know today, you're reaffirming the path to strong double-digit\ngrowth. So I guess my question is, can you talk a little bit about what\nyou've seen as far as customer engagements, how those might have expanded?\nI think you've alluded to in the past, multiple multi-gigawatt\nopportunities. Just any -- just double-click on what you've seen for the\nMI455 and Helios platform from a demand shaping perspective as we look into\nthe back half of the year?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Aaron. Thanks for the question. So first of all, I think the\nMI450 Series development is going extremely well. So we're very happy with\nthe progress that we have. We're right on track for a second half launch\nand beginning of production. And as it relates to sort of the shape of the\nramp and the customer engagements, I would say the customer engagements\ncontinue to proceed very well. We have obviously a very strong relationship\nwith OpenAI, and we're planning that ramp starting in the second half of\nthe year going into 2027. That is on track.\n\n\nWe're also working closely with a number of other customers who are very\ninterested in ramping MI450 quickly, just given the strength of the\nproduct, and we see that across both inference and training. And that is\nthe opportunity that we see in front of us. So we feel very good about sort\nof the data center growth overall for us in 2026 and then certainly going\ninto 2027, we've talked about tens of billions of dollars of data center AI\nrevenue, and we feel very good about that.\n\n\nOperator\n\nThe next question comes from the line of Tim Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nJean, I'm wondering if you can maybe give us a little bit of detail under\nthe hood for the March guidance. I know you basically told us that -- you\ntold us about, what, Embedded is going to be up a bit year-over-year.\nClient sounds like it's down seasonally, which I take to be maybe down 10%.\nSo can you give us a sense maybe of the other pieces?\n\n\nAnd then also, can you give us a sense of how Data Center GPU is going to\nramp through the year? I know it's a back half loaded year, but I think\npeople are thinking at least somewhere in the $14 billion range this year.\nThat's what investors are thinking. I don't -- I'm not asking you to\nendorse that. But if you can give us a little flavor for sort of how the\nramp will look for the year, that would be great.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nTim, thanks for your question. We're guiding one quarter at a time, but I\ncan give you some color about our Q1 guide. First is right, sequentially,\nwe guided a decline around 5%, but Data Center is actually going to be up.\nAnd when you think about it, right, our CPU business seasonal actually in a\nregular seasonal pattern, it's going to be down high single digit. And in\nour current guide, we actually guide CPU revenue up sequentially very\nnicely.\n\n\nAlso with the Data Center GPU side, we also feel really good about GPU\nrevenue, including China, will be also up. So very nice guide for the Data\nCenter overall. On the Client side, we do see seasonality sequentially\ndecline. Embedded and Gaming, they also have a seasonal decline.\n\n\nLisa T. Su\nChair, President & CEO\n\nAnd maybe, Tim, if I just give you a little bit on the full year\ncommentary. I think the important thing, as we look at the full year, we're\nvery bullish on the year. We're not -- if you look at the key themes, we're\nseeing very strong growth in the Data Center, and that's across 2 growth\nvectors. We see server CPU growth actually very strong. I mean we've talked\nabout the fact that CPUs are very important as AI continues to ramp. And\nwe've seen the CPU order book continue to strengthen as we go through the\nlast few quarters and especially over the last 60 days.\n\n\nSo we see that as a strong growth driver for us. As Jean said, we see\nserver CPU growing from Q4 into Q1 in what normally is seasonally down, and\nthat continues throughout the year. And then on the Data Center AI side,\nit's a very important year for us. It's really an inflection point. MI355\nhas done well, and we were pleased with the performance in Q4, and we\ncontinue to ramp that in the first half of the year. But as we get into the\nsecond half of the year, the MI450 is really an inflection point for us. So\nthat revenue will start in the third quarter, but it will ramp significant\nvolume in the fourth quarter as we get into 2027. So that gives you a\nlittle bit of sort of what the data center ramp looks like throughout the\nyear.\n\n\nOperator\n\nAnd the next question comes from the line of Vivek Arya with Bank of\nAmerica.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nFirst, just a clarification on what you're assuming for your China MI308\nsales beyond Q1. And then Lisa, specific to 2026, can your Data Center\nrevenues grow at your target 60% plus growth rate? I realize that that's a\nmultiyear target, but do you think that there are enough drivers, whether\nit's on the server CPU side or GPU side for you to grow at that target base\neven in 2026?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Vivek. So let me talk a little bit about China first because\nthat's, I think, important for us to make sure that's clear. Look, we were\npleased to have some MI308 sales in the fourth quarter. They were actually\na license that was approved through work with the administration. And those\norders were actually from very early in 2025. And so we saw some revenue in\nQ4, and we're forecasting for about $100 million of revenue in Q1. We are\nnot forecasting any additional revenue from China just because it's a very\ndynamic situation.\n\n\nSo given that it's a dynamic situation, we're still waiting for -- we've\nsubmitted licenses for the MI325, and we're continuing to work with\ncustomers and understanding sort of their customer demand. We thought it\nprudent not to forecast any additional revenue other than the $100 million\nthat we called out in the Q1 guide.\n\n\nNow as it relates to overall Data Center, as I mentioned in the question to\nTim, like we're very bullish about data center. I think the combination of\ndrivers that we have across our CPU franchise, I mean, the EPYC product\nline, both Turin and Genoa continue to ramp well. And in the second half of\nthe year, we will be launching Venice, which we believe actually extends\nour leadership and the MI450 ramp, which is also very significant in the\nsecond half of 2026. We're not obviously guiding specifically by segment,\nbut the long-term target of, let's call it, greater than 60% is certainly\npossible in 2026.\n\n\nOperator\n\n[Operator Instructions] The next question comes from the line of C.J. Muse\nwith Cantor.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI'm curious on the server CPU side of the house and given the dramatic\ntightness, curious your ability to source incremental capacity from TSMC\nand elsewhere. And I guess, how long will it take for that to see wafers\nout? And how should we think about the implications for kind of the growth\ntrajectory throughout all of calendar '26? And I guess as part of that, if\nyou could speak to how we should be thinking about inflection in pricing as\nwell, that would be very helpful.\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, C.J. So a couple of points about the server CPU market. First of all,\nwe think the overall server CPU TAM is going to grow, let's call it, strong\ndouble digits in 2026, just given the -- as we said, the relationship\nbetween CPU demand and overall AI ramp. So I think that's a positive.\n\n\nRelative to our ability to support that, we've been seeing this trend for\nthe last couple of quarters. So we have increased our supply capacity\ncapability for server CPUs. And that's one of the reasons we're able to\nincrease our Q1 guide as it relates to the server business, and we see the\nability to continue to grow that throughout the year. There's no question\nthat demand continues to be strong. And so we're working with our supply\nchain partners to increase supply as well. But from what we see today, I\nthink the overall server situation is strong, and we are increasing supply\nto address that.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nC.J., do you have a follow-up question?\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI do maybe for Jean, if you could kind of touch on gross margins through\nthe year and as you balance kind of strengthening server CPU with perhaps\ngreater GPU accelerating in the second half. Is there kind of a framework\nthat we should be working off of?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes. Thank you for the question. We are very pleased with our gross margin\nQ4 performance and the Q1 guide at 55%, which actually is 130 basis points\nup year-over-year, while we continue to ramp our MI355 year-over-year very\nsignificantly. I think we are benefiting from a very favorable product mix\nacross all our business. If you think about in Data Center, we're ramping\nour new product, new generation product, Turin and MI355, which helps the\ngross margin. In Client, we continue to move up the stack and also gaining\nmomentum in our commercial business.\n\n\nOur Client business gross margin has been improving nicely. In addition,\ncertainly, we see the recovery of our Embedded business, which is also\nmargin accretive. So all those tailwinds we are seeing, we continue to see\nin the next few quarters. And when MI450 ramp, of course, in Q4, our gross\nmargin will be driven largely by mix. And I think we'll give you more color\nwhen we get there. But overall, we feel really good about our gross margin\nprogression this year.\n\n\nOperator\n\nThe next question comes from the line of Joe Moore with Morgan Stanley.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOn the MI455 ramp, will 100% of the business be racks? Will there be kind\nof an 8-way server business around that architecture? And then is the\nrevenue recognition when you ship to the rack vendor? Or is there something\nto understand about that?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Joe. So we do have multiple variants of the MI450 series, including an\n8-way GPU form factor. But for 2026, I would say the vast majority of it is\ngoing to be Rack Scale solutions. And yes, we will take revenue when we\nship to the rack builder.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOkay. Great. And then can you talk to any risks that you may have in terms\nof once you get silicon out, turning that into racks, any potential issues\nas you ramp that? I know your competitor had some last year, and you said\nyou learned from that. Is there anything you've done with kind of\nprebuilding racks to sort of ensure you won't have those issues? Just any\nrisk that we need to understand around that?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean, I think, Joe, the main thing is the development is going\nreally well. It is -- we're right on track with the MI450 series as well as\nthe Helios rack development. We've done a lot of testing already both at\nthe Rack Scale level as well as at the silicon level. So far, so good. We\nare getting, let's call it, a lot of input from our customers on things to\ntest so that we can do a lot of testing in parallel. And our expectation is\nthat we will be on track for our second half launch.\n\n\nOperator\n\nOur next question comes from the line of Stacy Rasgon with Research.\n\n\nStacy Aaron Rasgon\nBernstein Institutional Services LLC, Research Division\n\nFirst, Lisa, I just wanted to ask about OpEx. Like every quarter, you guys\nare guiding it up and then it's coming in even higher and then you're\nguiding it up again. And I understand, given the growth trajectory that you\nneed to invest. But how should we think about the ramp of that OpEx and\nthat spending number, especially as the GPU revenue starts to inflect? Do\nwe get leverage on that? Or should we be expecting the OpEx to be growing\neven more materially as the AI revenue starts to ramp?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Stacy. Thanks for the question. Look, I think in terms of OpEx,\nwe're at a point where we have very high conviction in the road map that we\nhave. And so in 2025, as the revenue increased. We did lean in on OpEx, and\nI think it was for all the right reasons. As we get into 2026 and as we see\nsome of the significant growth that we're expecting, we should absolutely\nsee leverage. And the way to think about it is we've always said in our\nlong-term model that OpEx should grow slower than revenue, and we would\nexpect that in 2026 as well, especially as we get into the second half of\nthe year and we see inflection in the revenue. But at this point, I think\nthe -- if you look at our free cash flow generation and the overall revenue\ngrowth, I think the investment in OpEx is absolutely the right thing to do.\n\n\n\nStacy Aaron Rasgon\nBernstein Institutional Services LLC, Research Division\n\nFor my follow-up, I actually have 2 sort of one-line answers I'm looking\nfor. Just first, the $100 million in China revenue in Q1, does that also\ndrop through a 0 cost basis like we had in Q4? And is that a margin\nheadwind? And number two, I know you don't give us the AI number, but could\nyou just give us the annual like 2025 Instinct number now that we're\nthrough the year? Like how big was it?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nSo Stacy, let me answer your first question on the $100 million revenue in\nQ1. Actually, the inventory reserve reversed in Q4, which was $360 million,\nnot only associated with the Q4 revenue, China revenue, but also covers the\n$100 million revenue we expect to ship in Q1 to China with our MI308. So\nthe Q1 gross margin guide is a very clean guide.\n\n\nLisa T. Su\nChair, President & CEO\n\nAnd Stacy, for your second question, as you know, we don't guide at the\nbusiness level, but to help you with your models, I think you can -- if you\nlook at the Q4 data center AI number, even if you were to back out the\nChina number, which was, let's call it, not a recurring number, you would\nstill see growth -- you'll see growth from Q3 to Q4. So that should help\nyou a little bit with your modeling.\n\n\nOperator\n\nAnd the next question comes from the line of Joshua Buchalter with TD\nCowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nI want to ask about clients. So the segment beat pretty handily in the\nfourth quarter, and I recognize you guys have been gaining share with\nRyzen. But I think given what we've been seeing in the memory market,\nthere's a lot of concern about inflationary costs and the potential for\npull-ins. Were there any changes in your order patterns during the quarter?\nAnd maybe bigger picture, how are you thinking about client growth and the\nhealth of that market into 2026?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Thanks for the question, Josh. The client market has performed\nextremely well for us throughout 2025, very strong growth for us, both in\nterms of ASP mixing up the stack as well as just unit growth. Going into\n2026, we are certainly watching the development of the business. I think\nthe PC market is an important market. Based on everything that we see\ntoday, we're probably seeing the PC TAM down a bit just given some of the\ninflationary pressures of the commodities pricing, including memory.\n\n\nThe way we are modeling the year is, let's call it, second half a bit\nsubseasonal to first half, just given everything that we see. Even in that\nenvironment with the PC market down, we believe we can grow the -- our PC\nbusiness. And our focus areas are enterprise. That's a place where we're\nmaking a very nice progress in 2025, and we expect that into 2026 and just\ncontinuing to grow sort of at the premium higher end of the market.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nAnd then I want to ask about the Instinct family. So we've seen your big\nGPU competitor make a deal with an SRAM-based spatial architecture provider\nand then OpenAI has reportedly been linked to one as well. Could you speak\nto the competitive implications of that? You've done well in inferencing, I\nthink, partly because of your leadership in HBM content. So I was wondering\nif you could maybe address the pull seemingly motivated by lower latency\ninference and how Instinct is positioned to service this if you're indeed\nseeing it as well.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I think, Josh, it's really, I think, the evolution that you might\nexpect as the AI market matures. What we're seeing is as inference ramps,\nthe -- really the tokens per dollar or the efficiency of the inference\nstack becomes more and more important. As you know, with our chiplet\narchitecture, we have a lot of ability to optimize across inference\ntraining and even across sort of the different stages of inference as well.\n\n\n\nSo I think I view this as very much as you go into the future, you'll see\nmore workload optimized products. And you can do that with GPUs as well as\nwith other more ASIC-like architectures. I think we have the full compute\nstack to do all of those things. And from that standpoint, we're going to\ncontinue to lean into inference as we view that as a significant\nopportunity for us in addition to ramping our training capabilities.\n\n\nOperator\n\nAnd the next question comes from the line of Ben Reitzes with Melius\nResearch.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nLisa, I wanted to ask you about OpenAI. I'm sure a lot of the volatility\nout there is not lost on you. Is everything on track for the second half\nfor starting the 6 gigawatts and the 3.5-year time line as far as you know?\nAnd is there any other color that you'd just like to give on that\nrelationship? And then I have a follow-up.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean I think, Ben, what I would say is we're very much working in\npartnership with OpenAI as well as our CSP partners to deliver on MI450\nseries and deliver on the ramp. The ramp is on schedule to start in the\nsecond half of the year. MI450 is doing great. Helios is doing well. We are\nin, let's call it, deep co-development across all of those parties. And as\nwe look forward, I think we are optimistic about the MI450 ramp for OpenAI.\nBut I also want to remind everyone that we have a broad set of customers\nthat are very excited about MI450 series. And so in addition to the work\nthat we're doing with OpenAI, there are a number of customers that we're\nworking to ramp in that time frame as well.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nAll right. I appreciate that. And I wanted to shift to the server CPU and\njust talk about x86 versus ARM. There's some view out there that x86 has a\nparticular edge in agents, big picture, do you agree with that? And what\nare you seeing from customers? And in particular, obviously, your big\ncompetitor is going to be selling an ARM CPU separately now in the second\nhalf. So if there's just anything on that competitive dynamic versus ARM\nand what NVIDIA is doing and your views on that, that'd be great to hear.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Ben, what I would say about the CPU market is there is a great need\nfor high-performance CPUs right now. And that goes towards agentic\nworkloads where when you have these AI processes or AI agents that are\nspinning off a lot of work, in an enterprise, they're actually going to a\nlot of traditional CPU tasks and the vast majority of them are on x86\ntoday. I think the beauty of EPYC is that we've optimized. We've done\nworkload optimization. So we have the best cloud processor out there. We\nhave the best enterprise processor. We also have some lower-cost variants\nfor storage and other elements. And I think all of that comes into play as\nwe think about the entirety of the AI infrastructure that needs to be put\nin place.\n\n\nI think the CPUs are going to continue to be as important as a piece of the\nAI infrastructure ramp. And that's one of the things that we mentioned at\nour Analyst Day back in November, is really this multiyear CPU cycle, and\nwe continue to see that. I think we've optimized EPYC to satisfy all of\nthose workloads, and we're going to continue to work with our customers to\nexpand our EPYC footprint.\n\n\nOperator\n\nAnd the next question comes from the line of Tom O'Malley with Barclays.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nLisa, I just wanted to ask, you mentioned on memory earlier as a sticking\npoint in terms of inflationary cost. Different customers do this in\ndifferent ways, different suppliers do this in different ways. But can you\nmaybe talk about your procurement of memory, when that takes place,\nparticularly on the HBM side? Is that something that gets done a year in\nadvance, 6 months in advance? Different accelerator guys have talked about\ndifferent time lines. I would be curious to kind of hear when you do the\nprocurement.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I mean, given the lead times for things like HBM and wafers and these\nparts of the supply chain, I mean, we're working closely with our suppliers\nover a multiyear time frame in terms of what we see in demand, how we ramp,\nhow we ensure that our development is very closely tied together. So I feel\nvery good about our supply chain capabilities. We have been planning for\nthis ramp. So independent of the current market conditions, we've been\nplanning for a significant ramp in our -- both CPU as well as our GPU\nbusiness over the past couple of years. And so from that standpoint, I\nthink we're well positioned to grow substantially in 2026. And now we are\nalso doing multiyear agreements that extend beyond that given the tightness\nof the supply chain.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nAnd just as a follow-up, you've seen a variety of different things in the\nindustry in terms of system accelerators, so KV cache offload, more\ndiscrete ASIC style compute, CPX. If you look at what your competitors are\ndoing and you look at your first generation of system architecture coming\nout, maybe spend some time on -- do you see yourself following in the\nfootsteps of some of these different type of architectural changes? Do you\nthink that you'll go in a different direction? Anything just on the\nevolution of your system-based architecture and then the adjoining products\nand/or silicon within?\n\n\nLisa T. Su\nChair, President & CEO\n\nI think, Tom, what we have is the ability with a very flexible\narchitecture, with our chiplet architecture, and then we also have a\nflexible platform architecture that allows us to really have different\nsystem solutions for the different requirements. I think we're very\ncognizant that there will be different solutions. So there's no -- I've\noften said there's no one size fits all, and I'll say that again, there's\nno one size fits all.\n\n\nBut that being the case, it's clear that the Rack Scale architecture is\nvery, very good for the highest end applications when you're talking about\ninference -- distributed inference and training. But we also see an\nopportunity with enterprise AI to use some of these other form factors. And\nso we're investing across that spectrum.\n\n\nOperator\n\nAnd the next question comes from the line of Ross Seymore with Deutsche\nBank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nA couple of I guess my first question is back on the gross margin side of\nthings. As you go from the MI300 to the 400 to the 500 eventually, do you\nsee any changes in the gross margin throughout that period? In the past,\nyou've talked about optimizing dollars more so than percentages. But just\non the percentage side, does it go up, down? Or is there volatility as you\ngo from one to the next for any reason? Just wondered on the trajectory\nthere.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nRoss, thank you for the question. At a very high level, each generation, we\nactually provide much more capabilities, more memory, help our customers\nmore. So in general, the gross margin should progress each generation when\nyou offer more capabilities to your customers. But typically, when you\nfirst ramp -- at the beginning of ramp of generation, it tends to be lower\nwhen you get to the scale, get to the yield improvement, the testing\nimprovement and also overall performance improvement, you will see gross\nmargin improving within each generation. So it's kind of a dynamic gross\nmargin. But in the longer term, you should expect each generation should\nhave a higher gross margin.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nAnd then one on a small segment of your business, but it seems quite\nvolatile and you talked a little bit about further off than you usually do\nis the gaming side of things. What is the magnitude down you're talking\nabout this year? Because in 2025, you thought it was going to be flat and\nit ended up growing 50%, which was a nice positive surprise. But now that\nyou're talking about this year being down, but then the next-gen Xbox\nramping in 2027, I just hope to get some color on what you see as kind of\nthe annual trajectory there.\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes. So Lisa can add more. So 2026, actually, it's the seventh year of\ncurrent product cycle. Typically, when you're at this stage of the cycle,\nrevenue tend to come down. We do expect the revenue on the semi customer\nrevenue side to come down significantly double digit for 2026, as Lisa\nmentioned in her prepared remarks. For the next generation?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. I think we'll -- I mean we'll certainly talk about that going forward.\nBut as we ramp the new generation, you would expect a reversal of that.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nOperator, I think we have time for one more caller on the call, please.\n\n\nOperator\n\nAnd our final question comes from the line of Jim Schneider with Goldman\nSachs.\n\n\nJames Edward Schneider\nGoldman Sachs Group, Inc., Research Division\n\nRelative to the ramp of your recallable systems, would you expect any kind\nof bottleneck in terms of supply constraints in terms of the ramp as you\nramp the second half of the year to potentially impact or limit the revenue\ngrowth? In other words, maybe talk about whether you expect supply to\nreally kind of mute the growth in Q4 sequentially relative to -- sorry, Q3\nrelative to Q4?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Jim, we are planning this at the -- every component level. So I think\nrelative to our data center AI ramp, I do not believe that we will be\nsupply limited in terms of the ramp that we put in place. I think we have\nan aggressive ramp. I think it's a very doable ramp. And as we think about\nthe size and scale of AMD, clearly, our priority is ensuring that the data\ncenter ramps go very well, and that's both on the data center AI, the GPU\nside as well as on the CPU side.\n\n\nJames Edward Schneider\nGoldman Sachs Group, Inc., Research Division\n\nAnd then maybe as a follow-up to the earlier question on OpEx. Could you\nmaybe address what are some of the largest investment areas you made in\n2025? And then what are the largest incremental OpEx investment areas for\n'26?\n\n\nJean X. Hu\nExecutive VP, CFO & Treasurer\n\nYes, Jim, on the 2025 investment, the priority and the investment --\nlargest investment in Data Center AI. Our hardware road map, we accelerated\nthat road map. We expand our software capabilities. We also acquired ZT\nSystems, which added significant system-level solutions and capabilities.\nThose are the primary investment in 2025.\n\n\nWe also invest heavily in go-to-market to really expand our go-to-market\ncapabilities to support the revenue growth and also expand our commercial\nbusiness and enterprise business for our CPU franchise. In 2026, you should\nexpect us to continue to invest aggressively. But as Lisa mentioned\nearlier, we do expect revenue to expand faster than operating expense\nincrease to drive the earnings per share expansion.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nAll right. Thank you, everybody, for participating on the call. Operator, I\nthink we can go ahead and close the call now. Thank you. Good evening.\n\n\nOperatorThank you. And ladies and gentlemen, that does conclude the\nquestion-and-answer session, and that also concludes today's\nteleconference. You may disconnect your lines at this time, and have a\ngreat rest of the day.\nCopyright  2026 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2026 S&P Global Market Intelligence.",
  "has_qa": 1,
  "speaker_turns": [
    {
      "speaker": "Unknown",
      "role": "",
      "text": "Advanced Micro Devices, Inc. NasdaqGS:AMD FQ4 2025 Earnings Call Transcripts Tuesday, February 3, 2026 10:00 PM GMT S&P Global Market Intelligence Estimates Presentation"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "Greetings, and welcome to the AMD Fourth Quarter and Full Year 2025 Conference Call. [Operator Instructions]. And please note that this conference is being recorded. I will now turn the conference over to Matt Ramsay, VP of Financial Strategy and IR. Thank you. You may begin."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor Relations",
      "text": "Vice President of Financial Strategy & Investor Relations Thank you, and welcome to AMD's Fourth Quarter and 2025 Full Year Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and accompanying slides. If you have not had the opportunity to review these materials, they can be found on the Investor Relations page of amd.com. Today, we will refer primarily to non-GAAP financial measures on the call. The full non-GAAP to GAAP reconciliations are available in today's press release and in the slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our Executive Vice President, CFO and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Mark Papermaster, Executive Vice President and CTO, will present at Morgan Stanley's TMT Conference on Tuesday, March 3. Today's discussions contain forward-looking statements based on our current beliefs, assumptions and expectations, speak only as of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause actual results to differ materially. With that, I will hand the call to Lisa."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Thank you, Matt, and good afternoon to all those listening today. 2025 was a defining year for AMD with record revenue, net income and free cash flow driven by broad-based demand for our high-performance computing and AI products. We ended the year with significant momentum with every part of our business performing very well. We saw demand accelerate across the data center, PC, gaming and embedded markets, launched the broadest set of leadership products in our history, gained significant server and PC processor share and rapidly scaled our Data Center AI business as Instinct and ROCm adoption increased with cloud, enterprise and AI customers. Looking at our fourth quarter, fourth quarter revenue grew 34% year-over- year to $10.3 billion, led by record EPYC, Ryzen and Instinct processor sales. Net income increased 42% to a record $2.5 billion and free cash flow nearly doubled year-over-year to a record $2.1 billion. For the full year, revenue grew 34% to $34.6 billion, and we added more than $7.6 billion of Data Center segment and client revenue. Turning to our fourth quarter segment results. Data Center segment revenue increased 39% year-over-year to a record $5.4 billion, led by accelerating Instinct MI350 Series GPU deployments and server share gains. In server, adoption of fifth-gen EPYC turn CPUs accelerated in the quarter, accounting for more than half of the total server revenue. Fourth-gen EPYC sales were also robust as our prior generation CPUs continue to deliver superior performance and TCO compared to competitive offerings across a wide range of workloads. As a result, we had record server CPU sales to both cloud and enterprise customers in the quarter and exited the year with record share. In cloud, hyperscaler demand was very strong as North American customers expanded deployments. EPYC-powered public cloud offerings grew significantly in the quarter with AWS, Google and others launching more than 230 new AMD instances. Hyperscalers launched more than 500 AMD-based instances in 2025, increasing the number of EPYC cloud instances more than 50% year-over-year to nearly 1,600. In the enterprise, we are seeing a meaningful shift in EPYC adoption, driven by our leadership performance, expanded platform availability, broad software enablement and increased go-to-market programs. The leading server providers now offer more than 3,000 solutions powered by fourth and fifth- gen EPYC CPUs that are optimized for all major enterprise workloads. As a result, the number of large businesses deploying EPYC on-prem more than doubled in 2025, and we exited the year with record server sell-through. Looking ahead, server CPU demand remains very strong. Hyperscalers are expanding their infrastructure to meet growing demand for cloud services and AI while enterprises are modernizing their data centers to ensure they have the right compute required to enable new AI workflows. Against this backdrop, EPYC has become the processor of choice for the modern data center, delivering leadership performance, efficiency and TCO. Our next- generation Venice CPU extends our leadership across each of these metrics. Customer pull for Venice is very high with engagements underway to support large-scale cloud deployments and broad OEM platform availability when Venice launches later this year. Turning to our Data Center AI business. We delivered record Instinct GPU revenue in the fourth quarter, led by the ramp of MI350 Series shipments. We also had some revenue from MI308 sales to customers in China. Instinct adoption broadened in the quarter. Today, 8 of the top 10 AI companies use Instinct to power production workloads across a growing range of use cases. With the MI350 Series, we are entering the next phase of Instinct adoption, expanding our footprint with existing partners and adding new customers. In the fourth quarter, hyperscalers expanded MI350 Series availability, leading AI companies scale their deployments to support additional workloads and multiple neocloud providers launched MI350 Series offerings that deliver on-demand access to Instinct infrastructure in the cloud. Turning to our AI software stack. We expanded the ROCm ecosystem in the fourth quarter, enabling customers to deploy Instinct faster and with higher performance across a broader range of workloads. Millions of large language and multimodal models run out of the box on AMD with the leading models launching with day zero support for Instinct GPUs. This capability highlights our rapidly expanding open source community enablement, including new upstream integration of AMD GPUs in vLLM, one of the most widely used inference engines. To drive Instinct adoption with industry-specific use cases, we're also adding support for domain-specific models in key verticals. As one example, in health care, we added ROCm support for the leading medical imaging framework to enable developers to train and deploy highly performing deep learning models on Instinct GPUs. For large businesses, we introduced our enterprise AI suite, a full stack software platform with enterprise-grade tools, inference microservices and solutions blueprints designed to simplify and accelerate production deployments at scale. We also announced a strategic partnership with Tata Consultancy Services to co-develop industry-specific AI solutions and help customers deploy AI across their operations. Looking ahead, customer engagements for our next- gen MI400 Series and Helios platform continue expanding. In addition to our multi-generation partnership with OpenAI to deploy 6 gigawatts of Instinct GPUs, we are in active discussions with other customers on at-scale multiyear deployments starting with Helios and MI450 later this year. With the MI400 series, we are also expanding our portfolio to address the full range of cloud, HPC and enterprise AI workloads. This includes MI455X and Helios for AI superclusters, MI430X for HPC and sovereign AI and MI440X servers for enterprise customers requiring leadership training and inference performance in a compact 8-GPU solution that integrates easily into existing infrastructure. Multiple OEMs publicly announced plans to launch Helios systems in 2026 with deep engineering engagements underway to support smooth production ramps. In December, HPE announced that they will offer Helios racks with purpose-built HPE Juniper Ethernet switches, an optimized software for high- bandwidth scale-up networking. And in January, Lenovo announced plans to offer Helios racks. MI430X adoption also grew in the quarter with new exascale class supercomputers announced by GENCI in France and HLRS in Germany. Looking further ahead, development of our next-generation MI500 Series is well underway. MI500 is powered by our CDNA 6 architecture built on advanced 2-nanometer process technology and features high-speed HBM4E memory. We are on track to launch MI500 in 2027 and expect MI500 to deliver another major leap in AI performance to power the next wave of large-scale multimodal models. In summary, our AI business is accelerating with the launch of MI400 Series and Helios representing a major inflection point for the business as we deliver leadership performance and TCO at the chip, compute tray and rack level. Based on the strength of our EPYC and Instinct road maps, we are well positioned to grow Data Center segment revenue by more than 60% annually over the next 3 to 5 years and scale our AI business to tens of billions in annual revenue in 2027. Turning to Client and Gaming. Segment revenue increased 37% year-over-year to $3.9 billion. In client, our PC processor business performed exceptionally well. Revenue increased 34% year-over-year to a record $3.1 billion, driven by increased demand for multiple generations of Ryzen desktop and mobile CPUs. Desktop CPU sales set a record for the fourth consecutive quarter. Ryzen CPUs topped the bestseller list at major global retailers and e-tailers throughout the holiday period with strong demand across all price points in every region, driving record desktop channel sell-out. In mobile, strong demand for AMD-powered notebooks drove record Ryzen PC sell-through in the quarter. That momentum extended into commercial PCs, where Ryzen adoption accelerated as we established a new long-term growth engine for our client business. Sell-through of Ryzen CPUs for commercial notebooks and desktops grew by more than 40% year-over-year in the fourth quarter, and we closed large wins with major telecom, financial services, aerospace, automotive, energy and technology customers. At CES, we expanded our Ryzen portfolio with CPUs that further extend our performance leadership. Our new Ryzen AI 400 mobile processors deliver significantly faster content creation and multitasking performance than the competition. Notebooks powered by Ryzen AI 400 are already available with the broadest lineup of AMD-based consumer and commercial AI PCs set to launch throughout the year. We also introduced our Ryzen AI Halo platform, the world's smallest AI development system, featuring our highest-end Ryzen AI MAX processor with 128 gigabytes of unified memory that can run models with up to 200 billion parameters locally. In gaming, revenue increased 50% year-over-year to $843 million. Semi- custom sales increased year-over-year and declined sequentially as expected. For 2026, we expect semi-custom SoC annual revenue to decline by a significant double-digit percentage as we enter the seventh year of what has been a very strong console cycle. From a product standpoint, Valve is on track to begin shipping its AMD- powered steam machine early this year and development of Microsoft's next- gen Xbox featuring an AMD semi-custom SoC is progressing well to support a launch in 2027. Gaming GPU revenue also increased year-over-year with higher channel sell-out driven by demand throughout the holiday sales period for our latest generation Radeon RX 9000 series GPUs. We also launched FSR 4 Redstone in the quarter, our most advanced AI-powered upscaling technology, delivering higher image quality and smoother frame rates for gamers. Turning to our Embedded segment. Revenue increased 3% year-over-year to $950 million, led by strength with test and measurement and aerospace customers and growing adoption of our Embedded x86 CPUs. Channel sell- through accelerated in the quarter as end customer demand improved across several end markets, led by test, measurement and emulation. Design win momentum remains one of the clearest indicators of long-term growth for our embedded business, and we delivered another record year. We closed $17 billion in design wins in 2025, up nearly 20% year-over-year as we've now won more than $50 billion of embedded designs since acquiring Xilinx. We also strengthened our Embedded portfolio in the quarter. We began production of our Versal AI Edge Gen 2 SoCs for low-latency inference workloads and started shipping our highest-end Spartan UltraScale+ devices for cost-optimized application. We also launched new embedded CPUs, including our EPYC 2005 series for network security and industrial edge applications, Ryzen P100 series for in-vehicle infotainment and industrial systems and Ryzen X100 series for physical AI and autonomous platforms. In summary, 2025 was an excellent year for AMD, marking the start of a new growth trajectory for the company. We are entering a multiyear demand super cycle for high performance and AI computing that is creating significant growth opportunities across each of our businesses. AMD is well positioned to capture that growth with highly differentiated products, a proven execution engine, deep customer partnerships and significant operational scale. And as AI reshapes the compute landscape, we have the breadth of solutions and partnerships required for end-to-end leadership. From Helios in the cloud for at-scale training and inference to an expanded Instinct portfolio for sovereign, supercomputing and enterprise AI deployment. At the same time, demand for EPYC CPUs is surging as agentic and emerging AI workloads require high-performance CPUs to power head nodes and run parallel tasks alongside GPUs. And at the edge and in PCs where AI adoption is just beginning, our industry-leading Ryzen and Embedded processors are powering real-time on-device AI. As a result, we expect significant top line and bottom line growth in 2026, led by increased adoption of EPYC and Instinct, continued client share gains and a return to growth in our Embedded segment. Looking further ahead, we see a clear path to achieve the ambitious targets we laid out at our Financial Analyst Day last November, including growing revenue at greater than 35% CAGR over the next 3 to 5 years, significantly expanding operating margins and generating annual EPS of more than $20 in the strategic time frame, driven by growth in all of our segments and the rapid scaling of our Data Center AI business. Now I'll turn the call over to Jean to provide additional color on our fourth quarter results and full year results. Jean?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the first quarter of fiscal 2026. AMD executed very well in 2025, delivering record revenue of $34.6 billion, up 34% year-over-year, driven by 32% growth in our Data Center segment and 51% growth in our Client and Gaming segment. Gross margin was 52%, and we delivered record earnings per share of $4.17, up 26% year-over-year while continuing to invest aggressively in AI and the data center to support our long-term growth. For the fourth quarter of 2025, revenue was a record $10.3 billion, growing 34% year-over-year, driven by strong growth in the Data Center and Client and Gaming segment, including approximately $390 million in revenue from MI308 sales to China, which was not included in our fourth quarter guidance. Revenue was up 11% sequentially, primarily driven by continued strong growth in data center from both server and Data Center AI business as well as a return to year-over-year growth in the Embedded segment. Gross margin was 57%, up 290 basis points year-over-year. We benefited from the release of $360 million in previously writing down MI308 inventory reserves. Excluding the inventory reserve release and MI308 revenue from China, gross margin would have been approximately 55%, up 80 basis points year-over-year, driven by favorable product mix. Operating expenses were $3 billion, an increase of 42% year-over-year as we continue to invest in R&D go-to-market activities to support our AI road map and long-term growth opportunities as well as higher employee performance-based incentives. Operating income was a record $2.9 billion, representing a 28% operating margin. Tax, interest and other resulted in a net expense of approximately $335 million. For the fourth quarter, diluted earnings per share was a record $1.53, an increase of 40% year-over-year, reflecting strong execution and operating leverage in our business model. Now turning to our reportable segment. Starting with the Data Center segment. Revenue was a record $5.4 billion, up 39% year-over-year and 24% sequentially, driven by strong demand for EPYC processors and the continued ramp of MI350 products. Data Center segment operating income was $1.8 billion or 33% of revenue compared to $1.2 billion or 30% a year ago, reflecting higher revenue and inventory reserve release, partially offset by continued investment to support our AI hardware and software road maps. Client and Gaming segment revenue was $3.9 billion, up 37% year-over-year, driven primarily by strong demand for our leadership AMD Ryzen processors. On a sequential basis, revenue was down 3% due to lower semi customer revenue. The client business revenue was a record $3.1 billion, up 34% year- over-year and 13% sequentially, led by strong demand from both the channel and the PC OEMs and continued market share gains. The gaming business revenue was $843 million, up 50% year-over-year, primarily driven by higher semi customer revenue and strong demand for AMD Radeon GPUs. Sequentially, gaming revenue was down 35% due to lower semi customer sales. Client and Gaming segment operating income was $725 million or 18% of revenue compared to $496 million or 17% a year ago. Embedded segment revenue was $950 million, up 3% year-over-year and 11% sequentially as demand strengthened across several end markets. Embedded segment operating income was $357 million or 38% of revenue compared to $362 million or 39% a year ago. Before I review the balance sheet and cash flow, as a reminder, we closed the sale of ZT Systems manufacturing business to Sanmina in late October. The fourth quarter financial results of the ZT manufacturing business are reported separately in our financial statement as discontinued operations and are excluded from our non-GAAP financials. Turning to the balance sheet and cash flow. During the quarter, we generated a record $2.3 billion in cash from continuing operations and a record of $2.1 billion in free cash flow. Inventory increased sequentially by approximately $607 million to $7.9 billion to support strong data center demand. At the end of the quarter, cash, cash equivalents and short-term investments were $10.6 billion. For the year, we repurchased 12.4 million shares and returned $1.3 billion to shareholders. We ended the year with $9.4 billion authorization remaining under our share repurchase program. Now turning to our first quarter 2026 outlook. We expect revenue to be approximately $9.8 billion, plus or minus $300 million, including approximately $100 million of MI308 sales to China. At the midpoint of our guidance, revenue is expected to be up 32% year-over-year, driven by strong growth in our Data Center and Client and Gaming segments and modest growth in our Embedded segment. Sequentially, we expect revenue to be down approximately 5%, driven by seasonal decline in our Client and Gaming and Embedded segment, partially offset by growth in our Data Center segment. In addition, we expect fourth quarter non-GAAP gross margin to be approximately 55%. Non-GAAP operating expense to be approximately $3.05 billion. Non-GAAP other net income to be approximately $35 million. Non-GAAP effective tax rate to be 13% and diluted share count is expected to be approximately 1.65 billion shares. In closing, 2025 was an outstanding year for AMD, reflecting disciplined execution across the business to deliver strong revenue growth, increased profitability and cash generation while investing aggressively in AI and innovation to support our long-term growth strategy. Looking ahead, we are very well positioned for continued strong top line revenue growth and earnings expansion in 2026 with a focus on driving data center AI growth, operating leverage and delivering long-term value to shareholders. With that, I'll turn it back to Matt for the Q&A session."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor RelationsYes. Thank you",
      "text": "Vice President of Financial Strategy & Investor RelationsYes. Thank you very much, Jean. Operator, please go ahead and open the Q&A session. Thank you. Question and Answer"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "[Operator Instructions] And the first question comes from the line of Aaron Rakers with Wells Fargo."
    },
    {
      "speaker": "Aaron Christopher Rakers",
      "role": "Wells Fargo Securities, LLC, Research Division",
      "text": "Wells Fargo Securities, LLC, Research Division Lisa, at your Analyst Day back in November, you seem to kind of endorse the high $20 billion AI revenue expectation that was out there on the Street for 2027. I know today, you're reaffirming the path to strong double-digit growth. So I guess my question is, can you talk a little bit about what you've seen as far as customer engagements, how those might have expanded? I think you've alluded to in the past, multiple multi-gigawatt opportunities. Just any -- just double-click on what you've seen for the MI455 and Helios platform from a demand shaping perspective as we look into the back half of the year?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Sure, Aaron. Thanks for the question. So first of all, I think the MI450 Series development is going extremely well. So we're very happy with the progress that we have. We're right on track for a second half launch and beginning of production. And as it relates to sort of the shape of the ramp and the customer engagements, I would say the customer engagements continue to proceed very well. We have obviously a very strong relationship with OpenAI, and we're planning that ramp starting in the second half of the year going into 2027. That is on track. We're also working closely with a number of other customers who are very interested in ramping MI450 quickly, just given the strength of the product, and we see that across both inference and training. And that is the opportunity that we see in front of us. So we feel very good about sort of the data center growth overall for us in 2026 and then certainly going into 2027, we've talked about tens of billions of dollars of data center AI revenue, and we feel very good about that."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Tim Arcuri with UBS."
    },
    {
      "speaker": "Timothy Michael Arcuri",
      "role": "UBS Investment Bank, Research Division",
      "text": "UBS Investment Bank, Research Division Jean, I'm wondering if you can maybe give us a little bit of detail under the hood for the March guidance. I know you basically told us that -- you told us about, what, Embedded is going to be up a bit year-over-year. Client sounds like it's down seasonally, which I take to be maybe down 10%. So can you give us a sense maybe of the other pieces? And then also, can you give us a sense of how Data Center GPU is going to ramp through the year? I know it's a back half loaded year, but I think people are thinking at least somewhere in the $14 billion range this year. That's what investors are thinking. I don't -- I'm not asking you to endorse that. But if you can give us a little flavor for sort of how the ramp will look for the year, that would be great."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Tim, thanks for your question. We're guiding one quarter at a time, but I can give you some color about our Q1 guide. First is right, sequentially, we guided a decline around 5%, but Data Center is actually going to be up. And when you think about it, right, our CPU business seasonal actually in a regular seasonal pattern, it's going to be down high single digit. And in our current guide, we actually guide CPU revenue up sequentially very nicely. Also with the Data Center GPU side, we also feel really good about GPU revenue, including China, will be also up. So very nice guide for the Data Center overall. On the Client side, we do see seasonality sequentially decline. Embedded and Gaming, they also have a seasonal decline."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO And maybe, Tim, if I just give you a little bit on the full year commentary. I think the important thing, as we look at the full year, we're very bullish on the year. We're not -- if you look at the key themes, we're seeing very strong growth in the Data Center, and that's across 2 growth vectors. We see server CPU growth actually very strong. I mean we've talked about the fact that CPUs are very important as AI continues to ramp. And we've seen the CPU order book continue to strengthen as we go through the last few quarters and especially over the last 60 days. So we see that as a strong growth driver for us. As Jean said, we see server CPU growing from Q4 into Q1 in what normally is seasonally down, and that continues throughout the year. And then on the Data Center AI side, it's a very important year for us. It's really an inflection point. MI355 has done well, and we were pleased with the performance in Q4, and we continue to ramp that in the first half of the year. But as we get into the second half of the year, the MI450 is really an inflection point for us. So that revenue will start in the third quarter, but it will ramp significant volume in the fourth quarter as we get into 2027. So that gives you a little bit of sort of what the data center ramp looks like throughout the year."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Vivek Arya with Bank of America."
    },
    {
      "speaker": "Vivek  Arya",
      "role": "BofA Securities, Research Division",
      "text": "BofA Securities, Research Division First, just a clarification on what you're assuming for your China MI308 sales beyond Q1. And then Lisa, specific to 2026, can your Data Center revenues grow at your target 60% plus growth rate? I realize that that's a multiyear target, but do you think that there are enough drivers, whether it's on the server CPU side or GPU side for you to grow at that target base even in 2026?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Sure, Vivek. So let me talk a little bit about China first because that's, I think, important for us to make sure that's clear. Look, we were pleased to have some MI308 sales in the fourth quarter. They were actually a license that was approved through work with the administration. And those orders were actually from very early in 2025. And so we saw some revenue in Q4, and we're forecasting for about $100 million of revenue in Q1. We are not forecasting any additional revenue from China just because it's a very dynamic situation. So given that it's a dynamic situation, we're still waiting for -- we've submitted licenses for the MI325, and we're continuing to work with customers and understanding sort of their customer demand. We thought it prudent not to forecast any additional revenue other than the $100 million that we called out in the Q1 guide. Now as it relates to overall Data Center, as I mentioned in the question to Tim, like we're very bullish about data center. I think the combination of drivers that we have across our CPU franchise, I mean, the EPYC product line, both Turin and Genoa continue to ramp well. And in the second half of the year, we will be launching Venice, which we believe actually extends our leadership and the MI450 ramp, which is also very significant in the second half of 2026. We're not obviously guiding specifically by segment, but the long-term target of, let's call it, greater than 60% is certainly possible in 2026."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "[Operator Instructions] The next question comes from the line of C.J. Muse with Cantor."
    },
    {
      "speaker": "Christopher James Muse",
      "role": "Cantor Fitzgerald & Co., Research Division",
      "text": "Cantor Fitzgerald & Co., Research Division I'm curious on the server CPU side of the house and given the dramatic tightness, curious your ability to source incremental capacity from TSMC and elsewhere. And I guess, how long will it take for that to see wafers out? And how should we think about the implications for kind of the growth trajectory throughout all of calendar '26? And I guess as part of that, if you could speak to how we should be thinking about inflection in pricing as well, that would be very helpful."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, C.J. So a couple of points about the server CPU market. First of all, we think the overall server CPU TAM is going to grow, let's call it, strong double digits in 2026, just given the -- as we said, the relationship between CPU demand and overall AI ramp. So I think that's a positive. Relative to our ability to support that, we've been seeing this trend for the last couple of quarters. So we have increased our supply capacity capability for server CPUs. And that's one of the reasons we're able to increase our Q1 guide as it relates to the server business, and we see the ability to continue to grow that throughout the year. There's no question that demand continues to be strong. And so we're working with our supply chain partners to increase supply as well. But from what we see today, I think the overall server situation is strong, and we are increasing supply to address that."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor Relations",
      "text": "Vice President of Financial Strategy & Investor Relations C.J., do you have a follow-up question?"
    },
    {
      "speaker": "Christopher James Muse",
      "role": "Cantor Fitzgerald & Co., Research Division",
      "text": "Cantor Fitzgerald & Co., Research Division I do maybe for Jean, if you could kind of touch on gross margins through the year and as you balance kind of strengthening server CPU with perhaps greater GPU accelerating in the second half. Is there kind of a framework that we should be working off of?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Yes. Thank you for the question. We are very pleased with our gross margin Q4 performance and the Q1 guide at 55%, which actually is 130 basis points up year-over-year, while we continue to ramp our MI355 year-over-year very significantly. I think we are benefiting from a very favorable product mix across all our business. If you think about in Data Center, we're ramping our new product, new generation product, Turin and MI355, which helps the gross margin. In Client, we continue to move up the stack and also gaining momentum in our commercial business. Our Client business gross margin has been improving nicely. In addition, certainly, we see the recovery of our Embedded business, which is also margin accretive. So all those tailwinds we are seeing, we continue to see in the next few quarters. And when MI450 ramp, of course, in Q4, our gross margin will be driven largely by mix. And I think we'll give you more color when we get there. But overall, we feel really good about our gross margin progression this year."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Joe Moore with Morgan Stanley."
    },
    {
      "speaker": "Joseph Lawrence Moore",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division On the MI455 ramp, will 100% of the business be racks? Will there be kind of an 8-way server business around that architecture? And then is the revenue recognition when you ship to the rack vendor? Or is there something to understand about that?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes, Joe. So we do have multiple variants of the MI450 series, including an 8-way GPU form factor. But for 2026, I would say the vast majority of it is going to be Rack Scale solutions. And yes, we will take revenue when we ship to the rack builder."
    },
    {
      "speaker": "Joseph Lawrence Moore",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division Okay. Great. And then can you talk to any risks that you may have in terms of once you get silicon out, turning that into racks, any potential issues as you ramp that? I know your competitor had some last year, and you said you learned from that. Is there anything you've done with kind of prebuilding racks to sort of ensure you won't have those issues? Just any risk that we need to understand around that?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. I mean, I think, Joe, the main thing is the development is going really well. It is -- we're right on track with the MI450 series as well as the Helios rack development. We've done a lot of testing already both at the Rack Scale level as well as at the silicon level. So far, so good. We are getting, let's call it, a lot of input from our customers on things to test so that we can do a lot of testing in parallel. And our expectation is that we will be on track for our second half launch."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "Our next question comes from the line of Stacy Rasgon with Research."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Bernstein Institutional Services LLC, Research Division",
      "text": "Bernstein Institutional Services LLC, Research Division First, Lisa, I just wanted to ask about OpEx. Like every quarter, you guys are guiding it up and then it's coming in even higher and then you're guiding it up again. And I understand, given the growth trajectory that you need to invest. But how should we think about the ramp of that OpEx and that spending number, especially as the GPU revenue starts to inflect? Do we get leverage on that? Or should we be expecting the OpEx to be growing even more materially as the AI revenue starts to ramp?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Sure, Stacy. Thanks for the question. Look, I think in terms of OpEx, we're at a point where we have very high conviction in the road map that we have. And so in 2025, as the revenue increased. We did lean in on OpEx, and I think it was for all the right reasons. As we get into 2026 and as we see some of the significant growth that we're expecting, we should absolutely see leverage. And the way to think about it is we've always said in our long-term model that OpEx should grow slower than revenue, and we would expect that in 2026 as well, especially as we get into the second half of the year and we see inflection in the revenue. But at this point, I think the -- if you look at our free cash flow generation and the overall revenue growth, I think the investment in OpEx is absolutely the right thing to do."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Bernstein Institutional Services LLC, Research Division",
      "text": "Bernstein Institutional Services LLC, Research Division For my follow-up, I actually have 2 sort of one-line answers I'm looking for. Just first, the $100 million in China revenue in Q1, does that also drop through a 0 cost basis like we had in Q4? And is that a margin headwind? And number two, I know you don't give us the AI number, but could you just give us the annual like 2025 Instinct number now that we're through the year? Like how big was it?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer So Stacy, let me answer your first question on the $100 million revenue in Q1. Actually, the inventory reserve reversed in Q4, which was $360 million, not only associated with the Q4 revenue, China revenue, but also covers the $100 million revenue we expect to ship in Q1 to China with our MI308. So the Q1 gross margin guide is a very clean guide."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO And Stacy, for your second question, as you know, we don't guide at the business level, but to help you with your models, I think you can -- if you look at the Q4 data center AI number, even if you were to back out the China number, which was, let's call it, not a recurring number, you would still see growth -- you'll see growth from Q3 to Q4. So that should help you a little bit with your modeling."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Joshua Buchalter with TD Cowen."
    },
    {
      "speaker": "Joshua Louis Buchalter",
      "role": "TD Cowen, Research Division",
      "text": "TD Cowen, Research Division I want to ask about clients. So the segment beat pretty handily in the fourth quarter, and I recognize you guys have been gaining share with Ryzen. But I think given what we've been seeing in the memory market, there's a lot of concern about inflationary costs and the potential for pull-ins. Were there any changes in your order patterns during the quarter? And maybe bigger picture, how are you thinking about client growth and the health of that market into 2026?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Thanks for the question, Josh. The client market has performed extremely well for us throughout 2025, very strong growth for us, both in terms of ASP mixing up the stack as well as just unit growth. Going into 2026, we are certainly watching the development of the business. I think the PC market is an important market. Based on everything that we see today, we're probably seeing the PC TAM down a bit just given some of the inflationary pressures of the commodities pricing, including memory. The way we are modeling the year is, let's call it, second half a bit subseasonal to first half, just given everything that we see. Even in that environment with the PC market down, we believe we can grow the -- our PC business. And our focus areas are enterprise. That's a place where we're making a very nice progress in 2025, and we expect that into 2026 and just continuing to grow sort of at the premium higher end of the market."
    },
    {
      "speaker": "Joshua Louis Buchalter",
      "role": "TD Cowen, Research Division",
      "text": "TD Cowen, Research Division And then I want to ask about the Instinct family. So we've seen your big GPU competitor make a deal with an SRAM-based spatial architecture provider and then OpenAI has reportedly been linked to one as well. Could you speak to the competitive implications of that? You've done well in inferencing, I think, partly because of your leadership in HBM content. So I was wondering if you could maybe address the pull seemingly motivated by lower latency inference and how Instinct is positioned to service this if you're indeed seeing it as well."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. I think, Josh, it's really, I think, the evolution that you might expect as the AI market matures. What we're seeing is as inference ramps, the -- really the tokens per dollar or the efficiency of the inference stack becomes more and more important. As you know, with our chiplet architecture, we have a lot of ability to optimize across inference training and even across sort of the different stages of inference as well. So I think I view this as very much as you go into the future, you'll see more workload optimized products. And you can do that with GPUs as well as with other more ASIC-like architectures. I think we have the full compute stack to do all of those things. And from that standpoint, we're going to continue to lean into inference as we view that as a significant opportunity for us in addition to ramping our training capabilities."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Ben Reitzes with Melius Research."
    },
    {
      "speaker": "Benjamin Alexander Reitzes",
      "role": "Melius Research LLC",
      "text": "Melius Research LLC Lisa, I wanted to ask you about OpenAI. I'm sure a lot of the volatility out there is not lost on you. Is everything on track for the second half for starting the 6 gigawatts and the 3.5-year time line as far as you know? And is there any other color that you'd just like to give on that relationship? And then I have a follow-up."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. I mean I think, Ben, what I would say is we're very much working in partnership with OpenAI as well as our CSP partners to deliver on MI450 series and deliver on the ramp. The ramp is on schedule to start in the second half of the year. MI450 is doing great. Helios is doing well. We are in, let's call it, deep co-development across all of those parties. And as we look forward, I think we are optimistic about the MI450 ramp for OpenAI. But I also want to remind everyone that we have a broad set of customers that are very excited about MI450 series. And so in addition to the work that we're doing with OpenAI, there are a number of customers that we're working to ramp in that time frame as well."
    },
    {
      "speaker": "Benjamin Alexander Reitzes",
      "role": "Melius Research LLC",
      "text": "Melius Research LLC All right. I appreciate that. And I wanted to shift to the server CPU and just talk about x86 versus ARM. There's some view out there that x86 has a particular edge in agents, big picture, do you agree with that? And what are you seeing from customers? And in particular, obviously, your big competitor is going to be selling an ARM CPU separately now in the second half. So if there's just anything on that competitive dynamic versus ARM and what NVIDIA is doing and your views on that, that'd be great to hear."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes, Ben, what I would say about the CPU market is there is a great need for high-performance CPUs right now. And that goes towards agentic workloads where when you have these AI processes or AI agents that are spinning off a lot of work, in an enterprise, they're actually going to a lot of traditional CPU tasks and the vast majority of them are on x86 today. I think the beauty of EPYC is that we've optimized. We've done workload optimization. So we have the best cloud processor out there. We have the best enterprise processor. We also have some lower-cost variants for storage and other elements. And I think all of that comes into play as we think about the entirety of the AI infrastructure that needs to be put in place. I think the CPUs are going to continue to be as important as a piece of the AI infrastructure ramp. And that's one of the things that we mentioned at our Analyst Day back in November, is really this multiyear CPU cycle, and we continue to see that. I think we've optimized EPYC to satisfy all of those workloads, and we're going to continue to work with our customers to expand our EPYC footprint."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Tom O'Malley with Barclays."
    },
    {
      "speaker": "Thomas James O'Malley",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division Lisa, I just wanted to ask, you mentioned on memory earlier as a sticking point in terms of inflationary cost. Different customers do this in different ways, different suppliers do this in different ways. But can you maybe talk about your procurement of memory, when that takes place, particularly on the HBM side? Is that something that gets done a year in advance, 6 months in advance? Different accelerator guys have talked about different time lines. I would be curious to kind of hear when you do the procurement."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. I mean, given the lead times for things like HBM and wafers and these parts of the supply chain, I mean, we're working closely with our suppliers over a multiyear time frame in terms of what we see in demand, how we ramp, how we ensure that our development is very closely tied together. So I feel very good about our supply chain capabilities. We have been planning for this ramp. So independent of the current market conditions, we've been planning for a significant ramp in our -- both CPU as well as our GPU business over the past couple of years. And so from that standpoint, I think we're well positioned to grow substantially in 2026. And now we are also doing multiyear agreements that extend beyond that given the tightness of the supply chain."
    },
    {
      "speaker": "Thomas James O'Malley",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division And just as a follow-up, you've seen a variety of different things in the industry in terms of system accelerators, so KV cache offload, more discrete ASIC style compute, CPX. If you look at what your competitors are doing and you look at your first generation of system architecture coming out, maybe spend some time on -- do you see yourself following in the footsteps of some of these different type of architectural changes? Do you think that you'll go in a different direction? Anything just on the evolution of your system-based architecture and then the adjoining products and/or silicon within?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO I think, Tom, what we have is the ability with a very flexible architecture, with our chiplet architecture, and then we also have a flexible platform architecture that allows us to really have different system solutions for the different requirements. I think we're very cognizant that there will be different solutions. So there's no -- I've often said there's no one size fits all, and I'll say that again, there's no one size fits all. But that being the case, it's clear that the Rack Scale architecture is very, very good for the highest end applications when you're talking about inference -- distributed inference and training. But we also see an opportunity with enterprise AI to use some of these other form factors. And so we're investing across that spectrum."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Ross Seymore with Deutsche Bank."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division A couple of I guess my first question is back on the gross margin side of things. As you go from the MI300 to the 400 to the 500 eventually, do you see any changes in the gross margin throughout that period? In the past, you've talked about optimizing dollars more so than percentages. But just on the percentage side, does it go up, down? Or is there volatility as you go from one to the next for any reason? Just wondered on the trajectory there."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Ross, thank you for the question. At a very high level, each generation, we actually provide much more capabilities, more memory, help our customers more. So in general, the gross margin should progress each generation when you offer more capabilities to your customers. But typically, when you first ramp -- at the beginning of ramp of generation, it tends to be lower when you get to the scale, get to the yield improvement, the testing improvement and also overall performance improvement, you will see gross margin improving within each generation. So it's kind of a dynamic gross margin. But in the longer term, you should expect each generation should have a higher gross margin."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division And then one on a small segment of your business, but it seems quite volatile and you talked a little bit about further off than you usually do is the gaming side of things. What is the magnitude down you're talking about this year? Because in 2025, you thought it was going to be flat and it ended up growing 50%, which was a nice positive surprise. But now that you're talking about this year being down, but then the next-gen Xbox ramping in 2027, I just hope to get some color on what you see as kind of the annual trajectory there."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Yes. So Lisa can add more. So 2026, actually, it's the seventh year of current product cycle. Typically, when you're at this stage of the cycle, revenue tend to come down. We do expect the revenue on the semi customer revenue side to come down significantly double digit for 2026, as Lisa mentioned in her prepared remarks. For the next generation?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. I think we'll -- I mean we'll certainly talk about that going forward. But as we ramp the new generation, you would expect a reversal of that."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor Relations",
      "text": "Vice President of Financial Strategy & Investor Relations Operator, I think we have time for one more caller on the call, please."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And our final question comes from the line of Jim Schneider with Goldman Sachs."
    },
    {
      "speaker": "James Edward Schneider",
      "role": "Goldman Sachs Group, Inc., Research Division",
      "text": "Goldman Sachs Group, Inc., Research Division Relative to the ramp of your recallable systems, would you expect any kind of bottleneck in terms of supply constraints in terms of the ramp as you ramp the second half of the year to potentially impact or limit the revenue growth? In other words, maybe talk about whether you expect supply to really kind of mute the growth in Q4 sequentially relative to -- sorry, Q3 relative to Q4?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Jim, we are planning this at the -- every component level. So I think relative to our data center AI ramp, I do not believe that we will be supply limited in terms of the ramp that we put in place. I think we have an aggressive ramp. I think it's a very doable ramp. And as we think about the size and scale of AMD, clearly, our priority is ensuring that the data center ramps go very well, and that's both on the data center AI, the GPU side as well as on the CPU side."
    },
    {
      "speaker": "James Edward Schneider",
      "role": "Goldman Sachs Group, Inc., Research Division",
      "text": "Goldman Sachs Group, Inc., Research Division And then maybe as a follow-up to the earlier question on OpEx. Could you maybe address what are some of the largest investment areas you made in 2025? And then what are the largest incremental OpEx investment areas for '26?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO & Treasurer",
      "text": "Executive VP, CFO & Treasurer Yes, Jim, on the 2025 investment, the priority and the investment -- largest investment in Data Center AI. Our hardware road map, we accelerated that road map. We expand our software capabilities. We also acquired ZT Systems, which added significant system-level solutions and capabilities. Those are the primary investment in 2025. We also invest heavily in go-to-market to really expand our go-to-market capabilities to support the revenue growth and also expand our commercial business and enterprise business for our CPU franchise. In 2026, you should expect us to continue to invest aggressively. But as Lisa mentioned earlier, we do expect revenue to expand faster than operating expense increase to drive the earnings per share expansion."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor Relations",
      "text": "Vice President of Financial Strategy & Investor Relations All right. Thank you, everybody, for participating on the call. Operator, I think we can go ahead and close the call now. Thank you. Good evening. OperatorThank you. And ladies and gentlemen, that does conclude the question-and-answer session, and that also concludes today's teleconference. You may disconnect your lines at this time, and have a great rest of the day. Copyright  2026 by S&P Global Market Intelligence, a division of S&P Global Inc. All rights reserved. These materials have been prepared solely for information purposes based upon information generally available to the public and from sources believed to be reliable. No content (including index data, ratings, credit- related analyses and data, research, model, software or other application or output therefrom) or any part thereof (Content) may be modified, reverse engineered, reproduced or distributed in any form by any means, or stored in a database or retrieval system, without the prior written permission of S&P Global Market Intelligence or its affiliates (collectively, S&P Global). The Content shall not be used for any unlawful or unauthorized purposes. S&P Global and any third-party providers, (collectively S&P Global Parties) do not guarantee the accuracy, completeness, timeliness or availability of the Content. S&P Global Parties are not responsible for any errors or omissions, regardless of the cause, for the results obtained from the use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P GLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR DEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE CONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no event shall S&P Global Parties be liable to any party for any direct, indirect, incidental, exemplary, compensatory, punitive, special or consequential damages, costs, expenses, legal fees, or losses (including, without limitation, lost income or lost profits and opportunity costs or losses caused by negligence) in connection with any use of the Content even if advised of the possibility of such damages. S&P Global Market Intelligence's opinions, quotes and credit-related and other analyses are statements of opinion as of the date they are expressed and not statements of fact or recommendations to purchase, hold, or sell any securities or to make any investment decisions, and do not address the suitability of any security. S&P Global Market Intelligence may provide index data. Direct investment in an index is not possible. Exposure to an asset class represented by an index is available through investable instruments based on that index. S&P Global Market Intelligence assumes no obligation to update the Content following publication in any form or format. The Content should not be relied on and is not a substitute for the skill, judgment and experience of the user, its management, employees, advisors and/or clients when making investment and other business decisions. S&P Global Market Intelligence does not act as a fiduciary or an investment advisor except where registered as such. S&P Global keeps certain activities of its divisions separate from each other in order to preserve the independence and objectivity of their respective activities. As a result, certain divisions of S&P Global may have information that is not available to other S&P Global divisions. S&P Global has established policies and procedures to maintain the confidentiality of certain nonpublic information received in connection with each analytical process. S&P Global may receive compensation for its ratings and certain analyses, normally from issuers or underwriters of securities or from obligors. S&P Global reserves the right to disseminate its opinions and analyses. S&P Global's public ratings and analyses are made available on its Web sites, www.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and www.globalcreditportal.com (subscription), and may be distributed through other means, including via S&P Global publications and third-party redistributors. Additional information about our ratings fees is available at www.standardandpoors.com/usratingsfees.  2026 S&P Global Market Intelligence."
    }
  ],
  "source_file": "Advanced Micro Devices, Inc., Q4 2025 Earnings Call, Feb 03, 2026.rtf"
}