{
  "event_id": "AVGO_2025-06-05",
  "ticker": "AVGO",
  "company": "Broadcom Inc.",
  "quarter": 2,
  "fiscal_year": 2025,
  "call_date": "2025-06-05",
  "call_start_ts": "2025-06-05 21:00:00+00:00",
  "raw_text": "\n|[pic]                     |\n\nBroadcom Inc. NasdaqGS:AVGO\nFQ2 2025 Earnings Call Transcripts\nThursday, June 5, 2025 9:00 PM GMT\nS&P Global Market Intelligence Estimates\n|      |-FQ2 2025-           |-FQ3 2025-   |-FY   |-FY   |\n|      |                     |             |2025- |2026- |\n|                              |CONSENSUS      |ACTUAL         |SURPRISE       |\n|                   |CONSENSUS          |ACTUAL             |SURPRISE           |\n|FQ3 2024           |1.21               |1.24               |[pic]2.48 %        |\n|FQ4 2024           |1.39               |1.42               |[pic]2.16 %        |\n|FQ1 2025           |1.51               |1.60               |[pic]5.96 %        |\n|FQ2 2025           |1.57               |1.58               |[pic]0.64 %        |\n\n|Table of Contents                                     |   |\n|Call Participants          |..............................................|3      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Presentation               |..............................................|4      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Question and Answer        |..............................................|7      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|                                                                                  |\n|Call Participants                                                                 |\n|                           |                           |                           |\n|EXECUTIVES                 |                           |                           |\n|                           |Ross Clark Seymore         |                           |\n|                           |Deutsche Bank AG, Research |                           |\n|Hock E. Tan                |Division                   |                           |\n|President, CEO & Executive |                           |                           |\n|Director                   |                           |                           |\n|                           |Srinivas Reddy Pajjuri     |                           |\n|                           |Raymond James & Associates,|                           |\n|Ji  Yoo                    |Inc., Research Division    |                           |\n|Director of Investor       |                           |                           |\n|Relations                  |                           |                           |\n|                           |Stacy Aaron Rasgon         |                           |\n|                           |Sanford C. Bernstein & Co.,|                           |\n|Kirsten M. Spears          |LLC., Research Division    |                           |\n|CFO & Chief Accounting     |                           |                           |\n|Officer                    |                           |                           |\n|                           |Timothy Michael Arcuri     |                           |\n|                           |UBS Investment Bank,       |                           |\n|ANALYSTS                   |Research Division          |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Aaron Christopher Rakers   |Vijay Raghavan Rakesh      |                           |\n|Wells Fargo Securities,    |Mizuho Securities USA LLC, |                           |\n|LLC, Research Division     |Research Division          |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Benjamin Alexander Reitzes |Vivek  Arya                |                           |\n|                           |BofA Securities, Research  |                           |\n|Melius Research LLC        |Division                   |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Blayne Peter Curtis        |William  Stein             |                           |\n|Jefferies LLC, Research    |Truist Securities, Inc.,   |                           |\n|Division                   |Research Division          |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Christopher Adam Jackson   |                           |                           |\n|Rolland                    |                           |                           |\n|Susquehanna Financial      |                           |                           |\n|Group, LLLP, Research      |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Christopher James Muse     |                           |                           |\n|Cantor Fitzgerald & Co.,   |                           |                           |\n|Research Division          |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Harlan L.  Sur             |                           |                           |\n|JPMorgan Chase & Co,       |                           |                           |\n|Research Division          |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joseph Lawrence Moore      |                           |                           |\n|Morgan Stanley, Research   |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joshua Louis Buchalter     |                           |                           |\n|TD Cowen, Research Division|                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Karl  Ackerman             |                           |                           |\n|BNP Paribas Exane, Research|                           |                           |\n|Division                   |                           |                           |\n|                                                                                  |\n\n\nPresentation\n\n\nOperator\n\nWelcome to Broadcom Inc.'s Second Quarter Fiscal Year 2025 Financial\nResults Conference Call. At this time, for opening remarks and\nintroductions, I would like to turn the call over to Ji Yoo, Head of\nInvestor Relations of Broadcom Inc.\n\n\nJi  Yoo\nDirector of Investor Relations\n\nThank you, operator, and good afternoon, everyone. Joining me on today's\ncall are Hock Tan, President and CEO; Kirsten Spears, Chief Financial\nOfficer; and Charlie Kawwas, President, Semiconductor Solutions Group.\nBroadcom distributed a press release and financial tables after the market\nclosed, describing our financial performance for the second quarter of\nfiscal year 2025. If you did not receive a copy, you may obtain the\ninformation from the Investors section of the Broadcom's website at\nbroadcom.com.\n\n\nThis conference call is being webcast live, and an audio replay of the call\ncan be accessed for 1 year through the Investors section of Broadcom's\nwebsite. During the prepared comments, Hock and Kirsten will be providing\ndetails of our second quarter fiscal year 2025 results, guidance for our\nthird quarter of fiscal year 2025 as well as commentary regarding the\nbusiness environment. We'll take questions after the end of our prepared\ncomments.\n\n\nPlease refer to our press release today and our recent filings with the SEC\nfor information on the specific risk factors that could cause our actual\nresults to differ materially from the forward-looking statements made on\nthis call. In addition to U.S. GAAP reporting, Broadcom reports certain\nfinancial measures on a non-GAAP basis. A reconciliation between GAAP and\nnon-GAAP measures is included in the tables attached to today's press\nrelease. Comments made during today's call will primarily refer to our non-\nGAAP financial results.\n\n\nI will now turn the call over to Hock.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThank you, Ji, and thank you, everyone, for joining us today. In our fiscal\nQ2 2025, total revenue was a record $15 billion, up 20% year-on-year. This\n20% year-on-year growth was all organic as Q2 last year was the first full\nquarter with VMware. Now revenue was driven by continued strength in AI\nsemiconductors and the momentum we have achieved in VMware. Now reflecting\nexcellent operating leverage, Q2 consolidated adjusted EBITDA was $10\nbillion, up 35% year-on-year. Now let me provide more color. Q2\nsemiconductor revenue was $8.4 billion, with growth accelerating to 17%\nyear-on-year, up from 11% in Q1. And of course, driving this growth was AI\nsemiconductor revenue of over $4.4 billion, which is up 46% year-on-year\nand continues the trajectory of 9 consecutive quarters of strong growth.\n\n\nWithin this, custom AI accelerators grew double digits year-on-year, while\nAI networking grew over 170% year-on-year. AI networking, which is based on\nEthernet was robust and represented 40% of our AI revenue. As a standard-\nbased open protocol, Ethernet enables one single fabric for both scale out\nand scale up and remains the preferred choice by our hyperscale customers.\nOur networking portfolio of Tomahawk switches, Jericho routers and NICs is\nwhat's driving our success within AI clusters in hyperscalers.\n\n\nAnd the momentum continues with our breakthrough Tomahawk 6 switch just\nannounced this week. This represents the next-generation 102.4 terabits per\nsecond switch capacity. Tomahawk 6 enables clusters of more than 100,000 AI\naccelerators to be deployed in just 2 tiers instead of 3. This flattening\nof the AI cluster is huge because it enables much better performance in\ntraining next-generation frontier models through a lower latency, higher\nbandwidth and lower power.\n\n\nTurning to XPUs or custom accelerators. We continue to make excellent\nprogress on the multiyear journey of enabling our 3 customers and 4\nprospects to deploy custom AI accelerators. As we had articulated over 6\nmonths ago, we eventually expect at least 3 customers to each deploy 1\nmillion AI accelerated clusters in 2027, largely for training their\nfrontier models. And we forecast and continue to do so a significant\npercentage of these deployments to be custom XPUs. These partners are still\nunwavering in their plan to invest despite the certain economic\nenvironment.\n\n\nIn fact, what we've seen recently is that they are doubling down on\ninference in order to monetize their platforms. And reflecting this, we may\nactually see an acceleration of XPU demand into the back half of 2026 to\nmeet urgent demand for inference on top of the demand we have indicated\nfrom training. And accordingly, we do anticipate now our fiscal 2025 growth\nrate of AI semiconductor revenue to sustain into fiscal 2026.\n\n\nTurning to our Q3 outlook. As we continue our current trajectory of growth,\nwe forecast AI semiconductor revenue to be $5.1 billion, up 60% year-on-\nyear, which would be the 10th consecutive quarter of growth. Now turning to\nnon-AI semiconductors in Q2. Revenue of $4 billion was down 5% year-on-\nyear. Non-AI semiconductor revenue is close to the bottom, has been\nrelatively slow to recover, but they had bright spots. In Q2, broadband,\nenterprise networking and server storage revenues were up sequentially.\nHowever, industrial was down and as expected, wireless was also down due to\nseasonality.\n\n\nIn Q3, we expect enterprise networking and broadband to continue to grow\nsequentially, but server storage, wireless and industrial are expected to\nbe largely flat. And overall, we forecast non-AI semiconductor revenue to\nstay around $4 billion. Now let me talk about our infrastructure software\nsegment. Q2 infrastructure software revenue of $6.6 billion was up 25% year-\non-year, above our outlook of $6.5 billion. As we have said before, this\ngrowth reflects our success in converting our enterprise customers from\nperpetual vSphere to the full VCF software stack subscription.\n\n\nCustomers are increasingly turning to VCF to create a modernized private\ncloud on-prem, which will enable them to repatriate workloads from public\nclouds while being able to run modern container-based applications and AI\napplications. Of our 10,000 largest customers, over 87% have now adopted\nVCF. The momentum from strong VCF sales over the past 18 months since the\nacquisition of VMware has created annual recurring revenue or otherwise\nknown as ARR growth of double digits in our core infrastructure software.\n\n\nIn Q3, we expect infrastructure software revenue to be approximately $6.7\nbillion, up 16% year-on-year. So in total, we are guiding Q3 consolidated\nrevenue to be approximately $15.8 billion, up 21% year-on-year. We expect\nQ3 adjusted EBITDA to be at least 66%.\n\n\nWith that, let me turn the call over to Kirsten.\n\n\nKirsten M. Spears\nCFO & Chief Accounting Officer\n\nThank you, Hock. Let me now provide additional detail on our Q2 financial\nperformance. Consolidated revenue was a record $15 billion for the quarter,\nup 20% from a year ago. Gross margin was 79.4% of revenue in the quarter,\nbetter than we originally guided on product mix. Consolidated operating\nexpenses were $2.1 billion, of which $1.5 billion was related to R&D. Q2\noperating income of $9.8 billion was up 37% from a year ago, with operating\nmargin at 65% of revenue. Adjusted EBITDA was $10 billion or 67% of\nrevenue, above our guidance of 66%. This figure excludes $142 million of\ndepreciation.\n\n\nNow a review of the P&L for our 2 segments. Starting with semiconductors.\nRevenue for our semiconductor solutions segment was $8.4 billion, with\ngrowth accelerating to 17% year-on-year, driven by AI. Semiconductor\nrevenue represented 56% of total revenue in the quarter. Gross margin for\nour semiconductor solutions segment was approximately 69%, up 140 basis\npoints year-on-year driven by product mix. Operating expenses increased 12%\nyear-on-year to $971 million on increased investment in R&D for leading\nedge AI semiconductors. Semiconductor operating margin of 57% was up 200\nbasis points year-on-year.\n\n\nNow moving on to infrastructure software. Revenue for infrastructure\nsoftware of $6.6 billion was up 25% year-on-year and represented 44% of\ntotal revenue. Gross margin for infrastructure software was 93% in the\nquarter compared to 88% a year ago. Operating expenses were $1.1 billion in\nthe quarter, resulting in infrastructure software operating margin of\napproximately 76%. This compares to operating margin of 60% a year ago.\nThis year-on-year improvement reflects our disciplined integration of\nVMware.\n\n\nMoving on to cash flow. Free cash flow in the quarter was $6.4 billion and\nrepresented 43% of revenue. Free cash flow as a percentage of revenue\ncontinues to be impacted by increased interest expense from debt related to\nthe VMware acquisition and increased cash taxes. We spent $144 million on\ncapital expenditures. Day sales outstanding were 34 days in the second\nquarter compared to 40 days a year ago. We ended the second quarter with\ninventory of $2 billion, up 6% sequentially in anticipation of revenue\ngrowth in future quarters. Our days of inventory on hand were 69 days in Q2\nas we continue to remain disciplined on how we manage inventory across the\necosystem.\n\n\nWe ended the second quarter with $9.5 billion of cash and $69.4 billion of\ngross principal debt. Subsequent to quarter end, we repaid $1.6 billion of\ndebt, resulting in gross principal debt of $67.8 billion. The weighted\naverage coupon rate and years to maturity of our $59.8 billion in fixed\nrate debt is 3.8% and 7 years, respectively. The weighted average interest\nrate and years to maturity of our $8 billion in floating rate debt is 5.3%\nand 2.6 years, respectively.\n\n\nTurning to capital allocation. In Q2, we paid stockholders $2.8 billion of\ncash dividends based on a quarterly common stock cash dividend of $0.59 per\nshare. In Q2, we repurchased $4.2 billion or approximately 25 million\nshares of common stock. In Q3, we expect the non-GAAP diluted share count\nto be approximately 4.97 billion shares, excluding the potential impact of\nany share repurchases.\n\n\nNow moving on to guidance. Our guidance for Q3 is for consolidated revenue\nof $15.8 billion, up 21% year-on-year. We forecast semiconductor revenue of\napproximately $9.1 billion, up 25% year-on-year. Within this, we expect Q3\nAI semiconductor revenue of $5.1 billion, up 60% year-on-year. We expect\ninfrastructure software revenue of approximately $6.7 billion, up 16% year-\non-year. For modeling purposes, we expect Q3 consolidated gross margin to\nbe down approximately 130 basis points sequentially, primarily reflecting a\nhigher mix of XPUs within AI revenue.\nAs a reminder, consolidated gross margins through the year will be impacted\nby the revenue mix of infrastructure software and semiconductors. We expect\nQ3 adjusted EBITDA to be at least 66%. We expect the non-GAAP tax rate for\nQ3 and fiscal year 2025 to remain at 14%. And with this, that concludes my\nprepared remarks. Operator, please open up the call for questions.\n\n\nQuestion and Answer\n\n\nOperator\n\n[Operator Instructions] And our first question will come from the line of\nRoss Seymore with Deutsche Bank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nHock, I wanted to jump on to the AI side and specifically some of the\ncommentary you had about next year. Can you just give a little bit more\ncolor on the inference commentary you gave? And is it more the XPU side,\nthe connectivity side or both that's given you the confidence to talk about\nthe growth rate that you have this year being matched next fiscal year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThank you, Ross. Good question. I think we're indicating that what we are\nseeing and what we have quite a bit of visibility increasingly is increased\ndeployment of XPUs next year, much more than we originally thought and hand-\nin-hand with it, of course, more and more networking. So it's a combination\nof both.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nAnd the inference side of things?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes, we're seeing much more inference now.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of\nHarlan Sur with JPMorgan.\n\n\nHarlan L.  Sur\nJPMorgan Chase & Co, Research Division\n\nGreat job on the quarterly execution. Hock, good to see the positive growth\ninflection quarter-over-quarter, year-over-year growth rates in your AI\nbusiness. As the team has mentioned, right, the quarters can be a bit\nlumpy. So if I smooth out kind of first 3 quarters of this fiscal year,\nyour AI business is up 60% year-over-year. It's kind of right in line with\nyour 3-year kind of SAM growth CAGR, right?\n\n\nGiven your prepared remarks and knowing that your lead times remain at 35\nweeks or better, do you see the Broadcom team sustaining the 60% year-over-\nyear growth rate exiting this year. And I assume that, that potentially\nimplies that you see your AI business sustaining the 60% year-over-year\ngrowth rate into fiscal '26, again, based on your prepared commentary,\nwhich again is in line with your SAM growth figure. Is that kind of a fair\nway to think about the trajectory this year and next year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nHarlan, that's a very insightful set of analysis here, and that's exactly\nwhat we're trying to do here because over 6 months ago, we gave you guys a\npoint, a year, 2027. As we come into the second half of 2025 and with\nimproved visibility and updates we are seeing in the way our hyperscale\npartners are deploying data centers, AI clusters, we are providing you some\nlevel of guidance visibility what we are seeing, how the trajectory of '26\nmight look like. I'm not giving you any update on '27. We're just still\nestablishing the update we have in '27 6 months ago. But what we're doing\nnow is giving you more visibility into where we're seeing '26 headed.\n\n\nHarlan L.  Sur\nJPMorgan Chase & Co, Research Division\n\nBut is the framework that you laid out for us like second half of last\nyear, which implies 60% kind of growth CAGR in your SAM opportunity, is\nthat kind of the right way to think about it as it relates to the profile\nof growth in your business this year and next year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Ben\nReitzes with Melius Research.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nHock, networking -- AI networking was really strong in the quarter, and it\nseemed like it must have beat expectations. I was wondering if you could\njust talk about the networking in particular, what caused that? And how\nmuch of that is your acceleration into next year? And when do you think you\nsee Tomahawk kicking in as part of that acceleration?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nWell, I think the AI networking, as you probably would know, goes pretty\nhand-in-hand with deployment of AI accelerator clusters. It isn't -- It\ndoesn't deploy on a timetable that's very different from the way the\naccelerators get deployed, whether they are XPUs or GPUs. It does happen.\nAnd they deployed a lot in scale-out where Ethernet, of course, is the\nchoice of protocol, but it's also increasingly moving into the space of\nwhat we all call scale up within those data centers, where you have much\nhigher, more than we originally thought consumption or density of switches\nthan you have in the scale-out scenario.\n\n\nIn fact, the increased density in scale up is 5 to 10x more than in scale\nout. And that's the part that kind of pleasantly surprised us and which is\nwhy this past quarter, Q2, the AI networking portion continues at about 40%\nfrom what we reported a quarter ago for Q1. And at that time, I said I\nexpect it to drop. It hasn't.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nAnd your thoughts on Tomahawk driving acceleration for next year and when\nit kicks in?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nTomahawk 6, yes, that's extremely strong interest. Now we're not shipping\nbig orders or any orders other than basic proof of concepts out to\ncustomers, but there is tremendous demand for this new 102 terabits per\nsecond Tomahawk switches.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of\nBlayne Curtis with Jefferies.\n\n\nBlayne Peter Curtis\nJefferies LLC, Research Division\n\nGreat results. I just wanted to ask maybe following up on the scale-out\nopportunity. So today, I guess your main customer is not really using kind\nof an NVLink switch style scale-up. I'm just kind of curious your\nvisibility or the timing in terms of when you might be shipping a switched\nEthernet scale-up network to your customers?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYou're talking scale up?\n\n\nBlayne Peter Curtis\nJefferies LLC, Research Division\n\nScale up.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes. Well, scale up is very rapidly converting to Ethernet now, very much\nso. For our fairly narrow band of hyperscale customers, scale up is very\nmuch Ethernet.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Stacy\nRasgon with Bernstein.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nHock, I still wanted to follow up on that AI 2026 question. I want to just\nput some numbers on it, just to make sure I got it right. So if you did 60%\nin the first 3 quarters of this year, if you grow 60% year-over-year in Q4,\nit put you at like, I don't know, $5.8 billion, something like $19 billion\nor $20 billion for the year. And then are you saying you're going to grow\n60% in 2026 would put you $30 billion plus in AI revenues for 2026? I'm\njust wondering, is that the math that you're trying to communicate to us\ndirectly?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI think you're doing the math. I'm giving you the trend. But I did answer\nthat question, I think Harlan asked earlier. The rate we are seeing now so\nfar in fiscal '25 and will presumably continue, we don't see any reason why\nit doesn't given lead time visibility in '25. What we are seeing today\nbased on what we have visibility on '26 is to be able to ramp up this AI\nrevenue in the same trajectory. Yes.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nSo is the SAM going up as well because now you have inference on top of\ntraining. So is the SAM still 60 to 90? Or is the SAM higher now as you see\nit?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI'm not playing a SAM game here. I'm just giving a trajectory towards where\nwe drew the line on '27 before. So I have no response to if the SAM going\nup or not. Stop talking about SAM now.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Vivek\nArya with Bank of America.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nI had a near and then a longer-term question on the XPU business. So Hock,\nfor near term, if your networking upsided in Q2 and overall AI was in line,\nit means XPU was perhaps not as strong. So I realize it's lumpy, but\nanything more to read into that, any product transition or anything else?\nSo just a clarification there.\n\n\nAnd then longer term, you have outlined a number of additional customers\nthat you're working with. What milestones should we look forward to? And\nwhat milestones are you watching to give you the confidence that you can\nnow start adding their addressable opportunity into your '27 or '28 or\nother numbers? Like how do we get the confidence that these projects are\ngoing to turn into revenue in some reasonable time frame from now?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nOkay. On the first part that you're asking, it's like you're trying to be --\n you're trying to count how many angels on a head of a pin here. I mean,\nwhether it's XPU or networking. Networking is hot, but that doesn't mean\nXPU is any soften. It's very much along the trajectory we expect it to be.\nAnd there's no lumpiness. There's no softening. It's pretty much what we\nexpect the trajectory to go so far and into next quarter as well and\nprobably beyond. So we have a -- it's a fairly, I guess, in our view, a\nfairly clear visibility on the short-term trajectory.\n\n\nIn terms of going on to '27, no, we are not updating any numbers here. We --\n 6 months ago, we drew a sense for the size of the SAM based on million GPU\nXPU clusters for 3 customers, and that's still very valid at that point,\nthat will be there. And we have not provided any further updates here nor\nare we intending to at this point. When we get a better visibility, clearer\nsense of where we are, and that probably won't happen until '26, we'll be\nhappy to give an update to the audience. But right now, though, in today's\nprepared remarks and answering a couple of questions, we have -- we are --\nas we are doing -- as we have done yet, we are intending to give you guys\nmore visibility what we are seeing the growth trajectory in '26.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of C.J.\nMuse with Cantor Fitzgerald.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI was hoping to follow up on Ross's question regarding inference\nopportunity. Can you discuss workloads that are optimal that you're seeing\nfor custom silicon? And that over time, what percentage of your XPU\nbusiness could be inference versus training?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI think there's no differentiation between training and inference in using\nmerchant accelerators versus custom accelerators. I think the whole premise\nbehind going towards custom accelerators continues, which is it's not a\nmatter of cost alone. It is that as custom accelerators get used and get\ndeveloped on a road map with any particular hyperscaler, there's a learning\ncurve, a learning curve on how they could optimize the way the algorithms\non their large language models gets written and tied to silicon.\n\n\nAnd that ability to do so is a huge value added in creating algorithms that\ncan drive their LLMs to higher and higher performance, much more than\nbasically a segregation approach between hardware and the software. It's\nthat you literally combine end-to-end hardware and software as they take\nthat journey. And it's a journey. They don't learn that in 1 year. Do it a\nfew cycles, get better and better at it. And there lies the value -- the\nfundamental value in creating your own hardware versus using a third-party\nmerchant silicon that you are able to optimize your software to the\nhardware and eventually achieve way high performance than you otherwise\ncould. And we see that happening.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Karl\nAckerman with BNP Paribas.\n\n\nKarl  Ackerman\nBNP Paribas Exane, Research Division\n\nHock, you spoke about the much higher content opportunity in scale-up\nnetworking. I was hoping you could discuss how important is demand adoption\nfor co-packaged optics in achieving this 5 to 10x higher content for scale-\nup networks? Or should we anticipate much of the scale-up opportunity will\nbe driven by Tomahawk and Thor NICs?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI'm trying to decipher this question of yours. So let me try to answer it\nperhaps in the way I think you want me to clarify. First and foremost, I\nthink most of what's scaling up, a lot of the scaling up that's going, as I\ncall it, which means a lot of XPU or GPU to GPU interconnects is done on\ncopper interconnects. And because the size of this scale-up cluster is\nstill not that huge yet that you can get away with copper -- using copper\ninterconnects. And they're still doing it. Mostly, they're doing it today.\n\n\nAt some point soon, I believe, when you start trying to go beyond maybe 72\nGPU to GPU interconnects, you may have to push towards a different protocol\nby protocol mode at a different medium from copper to optical. And when we\ndo that, yes, perhaps then things like exotic stuff like co-packaging might\nbe of silicon with optical might become relevant. But truly, what we really\nare talking about is that at some stage, as the clusters get larger and\nwhich means scale up becomes much bigger and you need to interconnect GPU\nor XPU to each other in scale up many more than just 72 or 100, maybe even\n128, you start going more and more.\n\n\nYou want to use optical interconnects simply because of distance. And\nthat's when optical will start replacing copper. And when that happens, the\nquestion is what's the best way to deliver on optical. And one way is co-\npackaged optics, but it's not the only way. You can just simply use --\ncontinue to use perhaps pluggable at low-cost optics. In which case, then\nyou can interconnect the bandwidth, the radix of a switch and our switch is\nnow 512 connections.\n\n\nSo you can now connect all these XPUs, GPUs, 512 for scale-up phenomenon.\nAnd that was huge, but that's when you go to optical. That's going to\nhappen within my view, a year or 2, and we'll be right at the forefront of\nit. And it may be co-packaged optics, which we are very much in\ndevelopment, but it's a lock-in co-package or it could just be as a first\nstep, pluggable optics. Whatever it is, I think the bigger question is when\ndoes it go for optical from copper connecting GPU to GPU to optical\nconnecting it. And the step in that move will be huge. And it's not\nnecessarily co-packaged optics. So that's definitely one path we are\npursuing.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nJoshua Buchalter with TD Cowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nI realize it's a bit nitpicky, but I wanted to ask about gross margins in\nthe guide. So your revenue implies sort of $800 million incremental\nincrease with gross profit up, I think, $400 million to $450 million, which\nis kind of pretty well below corporate average fall-through. I appreciate\nthat semis is dilutive and custom is probably dilutive within semis. But\nanything else going on with margins that we should be aware of? And how\nshould we think about the margin profile of custom longer term as that\nbusiness continues to scale and diversify?\n\n\nKirsten M. Spears\nCFO & Chief Accounting Officer\n\nYes. We've historically said that the XPU margins are slightly lower than\nthe rest of the business other than wireless. And so there's really nothing\nelse going on other than that. It's just exactly what I said, that the\nmajority of it quarter-over-quarter, the 130 basis point decline is being\ndriven by more XPUs.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThere are more moving parts here than your simple analysis proves here. And\nI think your simple analysis is totally wrong in that regard.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nTimothy Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nI also wanted to ask about scale up, Hock. So there's a lot of competing\necosystems. There's UALink, which, of course, you left. And now there's the\nbig GPU company opening up NVLink, and they're both trying to build\necosystems, and there's an argument that you're an ecosystem of one. What\nwould you say to that debate? Does opening up NVLink change the landscape?\nAnd sort of how do you view of your AI networking growth next year? Do you\nthink it's going to be primarily driven by scale up? Or will it still be\npretty scale-out heavy?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nIt's -- people do like to create platforms and new protocols and systems.\nThe fact of the matter is scale up can just be done easily, and it's\ncurrently available. It's open standards, open source, Ethernet. Just as\nwell, you don't need to create new systems for the sake of doing something\nthat you could easily be doing in networking in Ethernet. And so yes, I\nhear a lot of this interesting new protocols, standards that are trying to\nbe created. And most of them, by the way, are proprietary, much as they\nlike to call it otherwise. What is really open source and open standards is\nEthernet. And we believe Ethernet will prevail as it does before -- for the\nlast 20 years in traditional networking. There is no reason to create a new\nstandard for something that could be easily done in transferring bits and\nbytes of data.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nChristopher Rolland with Susquehanna.\n\n\nChristopher Adam Jackson Rolland\nSusquehanna Financial Group, LLLP, Research Division\n\nYes. My question is for you, Hock. It's kind of a bigger picture one here.\nAnd this kind of acceleration that we're seeing in AI demand, do you think\nthat this acceleration is because of a marked improvement in ASICs or XPUs\nclosing the gap on the software side at your customers? Do you think it's\nthese require tokenomics around inference, test time compute driving that,\nfor example. What do you think is actually driving the upside here? And do\nyou think it leads to a market share shift faster than we were expecting\ntowards XPU from GPU?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes. Interesting question, but none of the foregoing that you outlined.\nIt's very simple, why inference has come out very, very hot lately is --\nremember, we're only selling to a few customers, hyperscalers with\nplatforms and LLMs. That's it. There are not that many. And we have told\nyou how many we have, and we haven't increased any. But what is happening\nis these hyperscalers and those with LLMs need to justify all the spending\nthey're doing. Doing training makes your frontier models smarter. There's\nno question. It's almost like science, research and science. Make your\nfrontier models by creating very clever algorithms that consumes a lot of\ncompute for training smarter. Training makes it smarter. You want to\nmonetize inference. And that's what's driving it. Monetize, I indicated in\nmy prepared remarks, to drive to justify a return on investment and a lot\nof that investment is training and that return on investment is by creating\nuse cases, a lot of AI use cases, AI consumption out there through\navailability of a lot of inference. And that's what we are now starting to\nsee among our small group of customers.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nVijay Rakesh with Mizuho.\n\n\nVijay Raghavan Rakesh\nMizuho Securities USA LLC, Research Division\n\nHock, just going back on the AI server revenue side. I know you said fiscal\n'25 kind of tracking to that up 60%-ish growth. If you look at fiscal '26,\nyou have many new customers ramping [ Meta ] and probably you have the 4 of\nthe 6 hyperscalers that you have talked in the past. Would you expect that\ngrowth to accelerate into fiscal '26 about that kind of the 60% you talked\nabout?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nMy prepared remarks and which I clarified that the rate of growth we are\nseeing in '25 will sustain into '26 based on improved visibility and the\nfact that we're seeing inference coming in on top of the demand for\ntraining as the clusters get built up bigger and bigger, still stands. I\ndon't think we are getting very far by trying to pass through my words or\ndata here. It's just a -- it is and we see that going from '25 into '26 as\nthe best forecast we have at this point.\n\n\nVijay Raghavan Rakesh\nMizuho Securities USA LLC, Research Division\n\nGot it. And on the NVLink Fusion versus the scale up, do you expect that\nmarket to go the route of top of the rack where you've seen some move to\nthe Ethernet side in kind of the scale-out. Do you expect scale up to kind\nof go the same route?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nBroadcom do not participate in NVLink. So I'm really not qualified to\nanswer that question, I think.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Aaron\nRakers with Wells Fargo.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nI think all my questions on scale-up have been asked. But I guess, Hock,\ngiven the execution that you guys have been able to do with the VMware\nintegration, looking at the balance sheet, looking at the debt structure,\nI'm curious if you could give us your thoughts on how the company thinks\nabout capital return versus the thoughts on M&A and the strategy going\nforward.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nOkay. That's an interesting question. And I agree, not too untimely, I\nwould say, because, yes, we have done a lot of the integration of VMware\nnow, and you can see that in the level of free cash flow we're generating\nfrom operations. And as we said, the use of capital has always been --\nwe're very, I guess, measured and upfront with a return through dividends,\nwhich is half our free cash flow of the preceding year. And frankly, as\nKirsten has mentioned 3 months ago and 6 months ago during the last 2\nearnings call, the first choice typically of the other part of the free\ncash flow is to bring down our debt to a more -- to a level that we feel\ncloser to no more than 2 ratio of debt to EBITDA.\n\n\nAnd that doesn't mean that opportunistically, we may go out there and buy\nback our shares as we did last quarter, and indicated by Kirsten, when we\ndid $4.2 billion of stock buyback. Now part of it is used to basically when\nemployee RSUs vest basically use -- we basically buy back part of the\nshares used to be paying taxes on the vested RSU. But the other part of it,\nI do admit we used it opportunistically last quarter when we see an\nsituation when basically, we think that it's a good time to buy some shares\nback, and we do.\n\n\nBut having said all that, our use of cash outside of dividends would be, at\nthis stage, used towards reducing our debt. And I know you're going to ask\nwhat about M&A? Well, the kind of M&A we will do in our view would be\nsignificant, would be substantial enough that we need debt in any case. And\nit's a good use of our free cash flow to bring down debt to, in a way,\nexpand, if not preserve our borrowing capacity if we have to do another M&A\ndeal.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Srini\nPajjuri with Raymond James.\n\n\nSrinivas Reddy Pajjuri\nRaymond James & Associates, Inc., Research Division\n\nHock, a couple of clarifications. First, on your 2026 expectation, are you\nassuming any meaningful contribution from the 4 prospects that you talked\nabout?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNo comment. We don't talk about prospects. We only talk about customers.\n\n\nSrinivas Reddy Pajjuri\nRaymond James & Associates, Inc., Research Division\n\nOkay. Fair enough. And then my other clarification is that I think you\ntalked about networking being about 40% of the mix within AI. Is that the\nright kind of mix that you expect going forward? Or is that going to\nmaterially change as we, I guess, see XPUs ramping going forward?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNo. I've always said and I expect that to be the case going forward in '26\nas we grow that networking should be a ratio to XPU should be closer in the\nrange of less than 30%, not the 40%.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Joe\nMoore with Morgan Stanley.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nYou said you're not going to be impacted by export controls on AI. I know\nthere's been a number of changes since -- in the industry since the last\ntime you made the call. Is that still the case? And just can you give\npeople comfort that there's no impact from that down the road?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNobody can give anybody comfort in this environment, Joe. But rules are\nchanging quite dramatically as trade -- bilateral trade agreements continue\nto be negotiated in a very, very dynamic environment. So I'll be honest, I\ndon't know -- I know as little as probably -- you probably know more than I\ndo maybe, in which case then I know very little about this whole thing\nabout whether there's any export control, how the export control will take\nplace. We're guessing. So I'd rather not answer that because no, I don't\nknow whether it won't be.\n\n\nOperator\n\nAnd we do have time for one final question. And that will come from the\nline of William Stein with Truist Securities.\n\n\nWilliam  Stein\nTruist Securities, Inc., Research Division\n\nI wanted to ask about VMware. Can you comment as to how far along you are\nin the process of converting customers to the subscription model? Is that\nclose to complete? Or is there still a number of quarters that we should\nexpect that, that conversion continues?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThat's a good question. And so let me start off by saying a good way to\nmeasure it is most of our VMware contracts are about typically 3 years. And\nthat was what VMware did before we acquired them, and that's pretty much\nwhat we continue to do, 3 is very traditional. So based on that, the\nrenewals, we are like 2/3 of the way, almost to the halfway -- more than\nhalfway through the renewals. So we probably have at least another year\nplus, maybe 1.5 years to go.\n\n\nOperator\n\nAnd with that, I'd like to turn the call over to Ji Yoo for closing\nremarks.\n\n\nJi  Yoo\nDirector of Investor RelationsThank you, operator. Broadcom currently plans\nto report its earnings for the third quarter of fiscal year 2025 after\nclose of market on Thursday, September 4, 2025. A public webcast of\nBroadcom's earnings conference call will follow at 2:00 p.m. Pacific. That\nwill conclude our earnings call today. Thank you all for joining. Operator,\nyou may end the call.\nCopyright Â© 2025 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\nÂ© 2025 S&P Global Market Intelligence.\n\n",
  "presentation_text": "Operator\n\nWelcome to Broadcom Inc.'s Second Quarter Fiscal Year 2025 Financial\nResults Conference Call. At this time, for opening remarks and\nintroductions, I would like to turn the call over to Ji Yoo, Head of\nInvestor Relations of Broadcom Inc.\n\n\nJi  Yoo\nDirector of Investor Relations\n\nThank you, operator, and good afternoon, everyone. Joining me on today's\ncall are Hock Tan, President and CEO; Kirsten Spears, Chief Financial\nOfficer; and Charlie Kawwas, President, Semiconductor Solutions Group.\nBroadcom distributed a press release and financial tables after the market\nclosed, describing our financial performance for the second quarter of\nfiscal year 2025. If you did not receive a copy, you may obtain the\ninformation from the Investors section of the Broadcom's website at\nbroadcom.com.\n\n\nThis conference call is being webcast live, and an audio replay of the call\ncan be accessed for 1 year through the Investors section of Broadcom's\nwebsite. During the prepared comments, Hock and Kirsten will be providing\ndetails of our second quarter fiscal year 2025 results, guidance for our\nthird quarter of fiscal year 2025 as well as commentary regarding the\nbusiness environment. We'll take questions after the end of our prepared\ncomments.\n\n\nPlease refer to our press release today and our recent filings with the SEC\nfor information on the specific risk factors that could cause our actual\nresults to differ materially from the forward-looking statements made on\nthis call. In addition to U.S. GAAP reporting, Broadcom reports certain\nfinancial measures on a non-GAAP basis. A reconciliation between GAAP and\nnon-GAAP measures is included in the tables attached to today's press\nrelease. Comments made during today's call will primarily refer to our non-\nGAAP financial results.\n\n\nI will now turn the call over to Hock.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThank you, Ji, and thank you, everyone, for joining us today. In our fiscal\nQ2 2025, total revenue was a record $15 billion, up 20% year-on-year. This\n20% year-on-year growth was all organic as Q2 last year was the first full\nquarter with VMware. Now revenue was driven by continued strength in AI\nsemiconductors and the momentum we have achieved in VMware. Now reflecting\nexcellent operating leverage, Q2 consolidated adjusted EBITDA was $10\nbillion, up 35% year-on-year. Now let me provide more color. Q2\nsemiconductor revenue was $8.4 billion, with growth accelerating to 17%\nyear-on-year, up from 11% in Q1. And of course, driving this growth was AI\nsemiconductor revenue of over $4.4 billion, which is up 46% year-on-year\nand continues the trajectory of 9 consecutive quarters of strong growth.\n\n\nWithin this, custom AI accelerators grew double digits year-on-year, while\nAI networking grew over 170% year-on-year. AI networking, which is based on\nEthernet was robust and represented 40% of our AI revenue. As a standard-\nbased open protocol, Ethernet enables one single fabric for both scale out\nand scale up and remains the preferred choice by our hyperscale customers.\nOur networking portfolio of Tomahawk switches, Jericho routers and NICs is\nwhat's driving our success within AI clusters in hyperscalers.\n\n\nAnd the momentum continues with our breakthrough Tomahawk 6 switch just\nannounced this week. This represents the next-generation 102.4 terabits per\nsecond switch capacity. Tomahawk 6 enables clusters of more than 100,000 AI\naccelerators to be deployed in just 2 tiers instead of 3. This flattening\nof the AI cluster is huge because it enables much better performance in\ntraining next-generation frontier models through a lower latency, higher\nbandwidth and lower power.\n\n\nTurning to XPUs or custom accelerators. We continue to make excellent\nprogress on the multiyear journey of enabling our 3 customers and 4\nprospects to deploy custom AI accelerators. As we had articulated over 6\nmonths ago, we eventually expect at least 3 customers to each deploy 1\nmillion AI accelerated clusters in 2027, largely for training their\nfrontier models. And we forecast and continue to do so a significant\npercentage of these deployments to be custom XPUs. These partners are still\nunwavering in their plan to invest despite the certain economic\nenvironment.\n\n\nIn fact, what we've seen recently is that they are doubling down on\ninference in order to monetize their platforms. And reflecting this, we may\nactually see an acceleration of XPU demand into the back half of 2026 to\nmeet urgent demand for inference on top of the demand we have indicated\nfrom training. And accordingly, we do anticipate now our fiscal 2025 growth\nrate of AI semiconductor revenue to sustain into fiscal 2026.\n\n\nTurning to our Q3 outlook. As we continue our current trajectory of growth,\nwe forecast AI semiconductor revenue to be $5.1 billion, up 60% year-on-\nyear, which would be the 10th consecutive quarter of growth. Now turning to\nnon-AI semiconductors in Q2. Revenue of $4 billion was down 5% year-on-\nyear. Non-AI semiconductor revenue is close to the bottom, has been\nrelatively slow to recover, but they had bright spots. In Q2, broadband,\nenterprise networking and server storage revenues were up sequentially.\nHowever, industrial was down and as expected, wireless was also down due to\nseasonality.\n\n\nIn Q3, we expect enterprise networking and broadband to continue to grow\nsequentially, but server storage, wireless and industrial are expected to\nbe largely flat. And overall, we forecast non-AI semiconductor revenue to\nstay around $4 billion. Now let me talk about our infrastructure software\nsegment. Q2 infrastructure software revenue of $6.6 billion was up 25% year-\non-year, above our outlook of $6.5 billion. As we have said before, this\ngrowth reflects our success in converting our enterprise customers from\nperpetual vSphere to the full VCF software stack subscription.\n\n\nCustomers are increasingly turning to VCF to create a modernized private\ncloud on-prem, which will enable them to repatriate workloads from public\nclouds while being able to run modern container-based applications and AI\napplications. Of our 10,000 largest customers, over 87% have now adopted\nVCF. The momentum from strong VCF sales over the past 18 months since the\nacquisition of VMware has created annual recurring revenue or otherwise\nknown as ARR growth of double digits in our core infrastructure software.\n\n\nIn Q3, we expect infrastructure software revenue to be approximately $6.7\nbillion, up 16% year-on-year. So in total, we are guiding Q3 consolidated\nrevenue to be approximately $15.8 billion, up 21% year-on-year. We expect\nQ3 adjusted EBITDA to be at least 66%.\n\n\nWith that, let me turn the call over to Kirsten.\n\n\nKirsten M. Spears\nCFO & Chief Accounting Officer\n\nThank you, Hock. Let me now provide additional detail on our Q2 financial\nperformance. Consolidated revenue was a record $15 billion for the quarter,\nup 20% from a year ago. Gross margin was 79.4% of revenue in the quarter,\nbetter than we originally guided on product mix. Consolidated operating\nexpenses were $2.1 billion, of which $1.5 billion was related to R&D. Q2\noperating income of $9.8 billion was up 37% from a year ago, with operating\nmargin at 65% of revenue. Adjusted EBITDA was $10 billion or 67% of\nrevenue, above our guidance of 66%. This figure excludes $142 million of\ndepreciation.\n\n\nNow a review of the P&L for our 2 segments. Starting with semiconductors.\nRevenue for our semiconductor solutions segment was $8.4 billion, with\ngrowth accelerating to 17% year-on-year, driven by AI. Semiconductor\nrevenue represented 56% of total revenue in the quarter. Gross margin for\nour semiconductor solutions segment was approximately 69%, up 140 basis\npoints year-on-year driven by product mix. Operating expenses increased 12%\nyear-on-year to $971 million on increased investment in R&D for leading\nedge AI semiconductors. Semiconductor operating margin of 57% was up 200\nbasis points year-on-year.\n\n\nNow moving on to infrastructure software. Revenue for infrastructure\nsoftware of $6.6 billion was up 25% year-on-year and represented 44% of\ntotal revenue. Gross margin for infrastructure software was 93% in the\nquarter compared to 88% a year ago. Operating expenses were $1.1 billion in\nthe quarter, resulting in infrastructure software operating margin of\napproximately 76%. This compares to operating margin of 60% a year ago.\nThis year-on-year improvement reflects our disciplined integration of\nVMware.\n\n\nMoving on to cash flow. Free cash flow in the quarter was $6.4 billion and\nrepresented 43% of revenue. Free cash flow as a percentage of revenue\ncontinues to be impacted by increased interest expense from debt related to\nthe VMware acquisition and increased cash taxes. We spent $144 million on\ncapital expenditures. Day sales outstanding were 34 days in the second\nquarter compared to 40 days a year ago. We ended the second quarter with\ninventory of $2 billion, up 6% sequentially in anticipation of revenue\ngrowth in future quarters. Our days of inventory on hand were 69 days in Q2\nas we continue to remain disciplined on how we manage inventory across the\necosystem.\n\n\nWe ended the second quarter with $9.5 billion of cash and $69.4 billion of\ngross principal debt. Subsequent to quarter end, we repaid $1.6 billion of\ndebt, resulting in gross principal debt of $67.8 billion. The weighted\naverage coupon rate and years to maturity of our $59.8 billion in fixed\nrate debt is 3.8% and 7 years, respectively. The weighted average interest\nrate and years to maturity of our $8 billion in floating rate debt is 5.3%\nand 2.6 years, respectively.\n\n\nTurning to capital allocation. In Q2, we paid stockholders $2.8 billion of\ncash dividends based on a quarterly common stock cash dividend of $0.59 per\nshare. In Q2, we repurchased $4.2 billion or approximately 25 million\nshares of common stock. In Q3, we expect the non-GAAP diluted share count\nto be approximately 4.97 billion shares, excluding the potential impact of\nany share repurchases.\n\n\nNow moving on to guidance. Our guidance for Q3 is for consolidated revenue\nof $15.8 billion, up 21% year-on-year. We forecast semiconductor revenue of\napproximately $9.1 billion, up 25% year-on-year. Within this, we expect Q3\nAI semiconductor revenue of $5.1 billion, up 60% year-on-year. We expect\ninfrastructure software revenue of approximately $6.7 billion, up 16% year-\non-year. For modeling purposes, we expect Q3 consolidated gross margin to\nbe down approximately 130 basis points sequentially, primarily reflecting a\nhigher mix of XPUs within AI revenue.\nAs a reminder, consolidated gross margins through the year will be impacted\nby the revenue mix of infrastructure software and semiconductors. We expect\nQ3 adjusted EBITDA to be at least 66%. We expect the non-GAAP tax rate for\nQ3 and fiscal year 2025 to remain at 14%. And with this, that concludes my\nprepared remarks. Operator, please open up the call for questions.",
  "qa_text": "Operator\n\n[Operator Instructions] And our first question will come from the line of\nRoss Seymore with Deutsche Bank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nHock, I wanted to jump on to the AI side and specifically some of the\ncommentary you had about next year. Can you just give a little bit more\ncolor on the inference commentary you gave? And is it more the XPU side,\nthe connectivity side or both that's given you the confidence to talk about\nthe growth rate that you have this year being matched next fiscal year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThank you, Ross. Good question. I think we're indicating that what we are\nseeing and what we have quite a bit of visibility increasingly is increased\ndeployment of XPUs next year, much more than we originally thought and hand-\nin-hand with it, of course, more and more networking. So it's a combination\nof both.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nAnd the inference side of things?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes, we're seeing much more inference now.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of\nHarlan Sur with JPMorgan.\n\n\nHarlan L.  Sur\nJPMorgan Chase & Co, Research Division\n\nGreat job on the quarterly execution. Hock, good to see the positive growth\ninflection quarter-over-quarter, year-over-year growth rates in your AI\nbusiness. As the team has mentioned, right, the quarters can be a bit\nlumpy. So if I smooth out kind of first 3 quarters of this fiscal year,\nyour AI business is up 60% year-over-year. It's kind of right in line with\nyour 3-year kind of SAM growth CAGR, right?\n\n\nGiven your prepared remarks and knowing that your lead times remain at 35\nweeks or better, do you see the Broadcom team sustaining the 60% year-over-\nyear growth rate exiting this year. And I assume that, that potentially\nimplies that you see your AI business sustaining the 60% year-over-year\ngrowth rate into fiscal '26, again, based on your prepared commentary,\nwhich again is in line with your SAM growth figure. Is that kind of a fair\nway to think about the trajectory this year and next year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nHarlan, that's a very insightful set of analysis here, and that's exactly\nwhat we're trying to do here because over 6 months ago, we gave you guys a\npoint, a year, 2027. As we come into the second half of 2025 and with\nimproved visibility and updates we are seeing in the way our hyperscale\npartners are deploying data centers, AI clusters, we are providing you some\nlevel of guidance visibility what we are seeing, how the trajectory of '26\nmight look like. I'm not giving you any update on '27. We're just still\nestablishing the update we have in '27 6 months ago. But what we're doing\nnow is giving you more visibility into where we're seeing '26 headed.\n\n\nHarlan L.  Sur\nJPMorgan Chase & Co, Research Division\n\nBut is the framework that you laid out for us like second half of last\nyear, which implies 60% kind of growth CAGR in your SAM opportunity, is\nthat kind of the right way to think about it as it relates to the profile\nof growth in your business this year and next year?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Ben\nReitzes with Melius Research.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nHock, networking -- AI networking was really strong in the quarter, and it\nseemed like it must have beat expectations. I was wondering if you could\njust talk about the networking in particular, what caused that? And how\nmuch of that is your acceleration into next year? And when do you think you\nsee Tomahawk kicking in as part of that acceleration?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nWell, I think the AI networking, as you probably would know, goes pretty\nhand-in-hand with deployment of AI accelerator clusters. It isn't -- It\ndoesn't deploy on a timetable that's very different from the way the\naccelerators get deployed, whether they are XPUs or GPUs. It does happen.\nAnd they deployed a lot in scale-out where Ethernet, of course, is the\nchoice of protocol, but it's also increasingly moving into the space of\nwhat we all call scale up within those data centers, where you have much\nhigher, more than we originally thought consumption or density of switches\nthan you have in the scale-out scenario.\n\n\nIn fact, the increased density in scale up is 5 to 10x more than in scale\nout. And that's the part that kind of pleasantly surprised us and which is\nwhy this past quarter, Q2, the AI networking portion continues at about 40%\nfrom what we reported a quarter ago for Q1. And at that time, I said I\nexpect it to drop. It hasn't.\n\n\nBenjamin Alexander Reitzes\nMelius Research LLC\n\nAnd your thoughts on Tomahawk driving acceleration for next year and when\nit kicks in?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nTomahawk 6, yes, that's extremely strong interest. Now we're not shipping\nbig orders or any orders other than basic proof of concepts out to\ncustomers, but there is tremendous demand for this new 102 terabits per\nsecond Tomahawk switches.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of\nBlayne Curtis with Jefferies.\n\n\nBlayne Peter Curtis\nJefferies LLC, Research Division\n\nGreat results. I just wanted to ask maybe following up on the scale-out\nopportunity. So today, I guess your main customer is not really using kind\nof an NVLink switch style scale-up. I'm just kind of curious your\nvisibility or the timing in terms of when you might be shipping a switched\nEthernet scale-up network to your customers?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYou're talking scale up?\n\n\nBlayne Peter Curtis\nJefferies LLC, Research Division\n\nScale up.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes. Well, scale up is very rapidly converting to Ethernet now, very much\nso. For our fairly narrow band of hyperscale customers, scale up is very\nmuch Ethernet.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Stacy\nRasgon with Bernstein.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nHock, I still wanted to follow up on that AI 2026 question. I want to just\nput some numbers on it, just to make sure I got it right. So if you did 60%\nin the first 3 quarters of this year, if you grow 60% year-over-year in Q4,\nit put you at like, I don't know, $5.8 billion, something like $19 billion\nor $20 billion for the year. And then are you saying you're going to grow\n60% in 2026 would put you $30 billion plus in AI revenues for 2026? I'm\njust wondering, is that the math that you're trying to communicate to us\ndirectly?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI think you're doing the math. I'm giving you the trend. But I did answer\nthat question, I think Harlan asked earlier. The rate we are seeing now so\nfar in fiscal '25 and will presumably continue, we don't see any reason why\nit doesn't given lead time visibility in '25. What we are seeing today\nbased on what we have visibility on '26 is to be able to ramp up this AI\nrevenue in the same trajectory. Yes.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nSo is the SAM going up as well because now you have inference on top of\ntraining. So is the SAM still 60 to 90? Or is the SAM higher now as you see\nit?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI'm not playing a SAM game here. I'm just giving a trajectory towards where\nwe drew the line on '27 before. So I have no response to if the SAM going\nup or not. Stop talking about SAM now.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Vivek\nArya with Bank of America.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nI had a near and then a longer-term question on the XPU business. So Hock,\nfor near term, if your networking upsided in Q2 and overall AI was in line,\nit means XPU was perhaps not as strong. So I realize it's lumpy, but\nanything more to read into that, any product transition or anything else?\nSo just a clarification there.\n\n\nAnd then longer term, you have outlined a number of additional customers\nthat you're working with. What milestones should we look forward to? And\nwhat milestones are you watching to give you the confidence that you can\nnow start adding their addressable opportunity into your '27 or '28 or\nother numbers? Like how do we get the confidence that these projects are\ngoing to turn into revenue in some reasonable time frame from now?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nOkay. On the first part that you're asking, it's like you're trying to be --\n you're trying to count how many angels on a head of a pin here. I mean,\nwhether it's XPU or networking. Networking is hot, but that doesn't mean\nXPU is any soften. It's very much along the trajectory we expect it to be.\nAnd there's no lumpiness. There's no softening. It's pretty much what we\nexpect the trajectory to go so far and into next quarter as well and\nprobably beyond. So we have a -- it's a fairly, I guess, in our view, a\nfairly clear visibility on the short-term trajectory.\n\n\nIn terms of going on to '27, no, we are not updating any numbers here. We --\n 6 months ago, we drew a sense for the size of the SAM based on million GPU\nXPU clusters for 3 customers, and that's still very valid at that point,\nthat will be there. And we have not provided any further updates here nor\nare we intending to at this point. When we get a better visibility, clearer\nsense of where we are, and that probably won't happen until '26, we'll be\nhappy to give an update to the audience. But right now, though, in today's\nprepared remarks and answering a couple of questions, we have -- we are --\nas we are doing -- as we have done yet, we are intending to give you guys\nmore visibility what we are seeing the growth trajectory in '26.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of C.J.\nMuse with Cantor Fitzgerald.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI was hoping to follow up on Ross's question regarding inference\nopportunity. Can you discuss workloads that are optimal that you're seeing\nfor custom silicon? And that over time, what percentage of your XPU\nbusiness could be inference versus training?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI think there's no differentiation between training and inference in using\nmerchant accelerators versus custom accelerators. I think the whole premise\nbehind going towards custom accelerators continues, which is it's not a\nmatter of cost alone. It is that as custom accelerators get used and get\ndeveloped on a road map with any particular hyperscaler, there's a learning\ncurve, a learning curve on how they could optimize the way the algorithms\non their large language models gets written and tied to silicon.\n\n\nAnd that ability to do so is a huge value added in creating algorithms that\ncan drive their LLMs to higher and higher performance, much more than\nbasically a segregation approach between hardware and the software. It's\nthat you literally combine end-to-end hardware and software as they take\nthat journey. And it's a journey. They don't learn that in 1 year. Do it a\nfew cycles, get better and better at it. And there lies the value -- the\nfundamental value in creating your own hardware versus using a third-party\nmerchant silicon that you are able to optimize your software to the\nhardware and eventually achieve way high performance than you otherwise\ncould. And we see that happening.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Karl\nAckerman with BNP Paribas.\n\n\nKarl  Ackerman\nBNP Paribas Exane, Research Division\n\nHock, you spoke about the much higher content opportunity in scale-up\nnetworking. I was hoping you could discuss how important is demand adoption\nfor co-packaged optics in achieving this 5 to 10x higher content for scale-\nup networks? Or should we anticipate much of the scale-up opportunity will\nbe driven by Tomahawk and Thor NICs?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nI'm trying to decipher this question of yours. So let me try to answer it\nperhaps in the way I think you want me to clarify. First and foremost, I\nthink most of what's scaling up, a lot of the scaling up that's going, as I\ncall it, which means a lot of XPU or GPU to GPU interconnects is done on\ncopper interconnects. And because the size of this scale-up cluster is\nstill not that huge yet that you can get away with copper -- using copper\ninterconnects. And they're still doing it. Mostly, they're doing it today.\n\n\nAt some point soon, I believe, when you start trying to go beyond maybe 72\nGPU to GPU interconnects, you may have to push towards a different protocol\nby protocol mode at a different medium from copper to optical. And when we\ndo that, yes, perhaps then things like exotic stuff like co-packaging might\nbe of silicon with optical might become relevant. But truly, what we really\nare talking about is that at some stage, as the clusters get larger and\nwhich means scale up becomes much bigger and you need to interconnect GPU\nor XPU to each other in scale up many more than just 72 or 100, maybe even\n128, you start going more and more.\n\n\nYou want to use optical interconnects simply because of distance. And\nthat's when optical will start replacing copper. And when that happens, the\nquestion is what's the best way to deliver on optical. And one way is co-\npackaged optics, but it's not the only way. You can just simply use --\ncontinue to use perhaps pluggable at low-cost optics. In which case, then\nyou can interconnect the bandwidth, the radix of a switch and our switch is\nnow 512 connections.\n\n\nSo you can now connect all these XPUs, GPUs, 512 for scale-up phenomenon.\nAnd that was huge, but that's when you go to optical. That's going to\nhappen within my view, a year or 2, and we'll be right at the forefront of\nit. And it may be co-packaged optics, which we are very much in\ndevelopment, but it's a lock-in co-package or it could just be as a first\nstep, pluggable optics. Whatever it is, I think the bigger question is when\ndoes it go for optical from copper connecting GPU to GPU to optical\nconnecting it. And the step in that move will be huge. And it's not\nnecessarily co-packaged optics. So that's definitely one path we are\npursuing.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nJoshua Buchalter with TD Cowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nI realize it's a bit nitpicky, but I wanted to ask about gross margins in\nthe guide. So your revenue implies sort of $800 million incremental\nincrease with gross profit up, I think, $400 million to $450 million, which\nis kind of pretty well below corporate average fall-through. I appreciate\nthat semis is dilutive and custom is probably dilutive within semis. But\nanything else going on with margins that we should be aware of? And how\nshould we think about the margin profile of custom longer term as that\nbusiness continues to scale and diversify?\n\n\nKirsten M. Spears\nCFO & Chief Accounting Officer\n\nYes. We've historically said that the XPU margins are slightly lower than\nthe rest of the business other than wireless. And so there's really nothing\nelse going on other than that. It's just exactly what I said, that the\nmajority of it quarter-over-quarter, the 130 basis point decline is being\ndriven by more XPUs.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThere are more moving parts here than your simple analysis proves here. And\nI think your simple analysis is totally wrong in that regard.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nTimothy Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nI also wanted to ask about scale up, Hock. So there's a lot of competing\necosystems. There's UALink, which, of course, you left. And now there's the\nbig GPU company opening up NVLink, and they're both trying to build\necosystems, and there's an argument that you're an ecosystem of one. What\nwould you say to that debate? Does opening up NVLink change the landscape?\nAnd sort of how do you view of your AI networking growth next year? Do you\nthink it's going to be primarily driven by scale up? Or will it still be\npretty scale-out heavy?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nIt's -- people do like to create platforms and new protocols and systems.\nThe fact of the matter is scale up can just be done easily, and it's\ncurrently available. It's open standards, open source, Ethernet. Just as\nwell, you don't need to create new systems for the sake of doing something\nthat you could easily be doing in networking in Ethernet. And so yes, I\nhear a lot of this interesting new protocols, standards that are trying to\nbe created. And most of them, by the way, are proprietary, much as they\nlike to call it otherwise. What is really open source and open standards is\nEthernet. And we believe Ethernet will prevail as it does before -- for the\nlast 20 years in traditional networking. There is no reason to create a new\nstandard for something that could be easily done in transferring bits and\nbytes of data.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nChristopher Rolland with Susquehanna.\n\n\nChristopher Adam Jackson Rolland\nSusquehanna Financial Group, LLLP, Research Division\n\nYes. My question is for you, Hock. It's kind of a bigger picture one here.\nAnd this kind of acceleration that we're seeing in AI demand, do you think\nthat this acceleration is because of a marked improvement in ASICs or XPUs\nclosing the gap on the software side at your customers? Do you think it's\nthese require tokenomics around inference, test time compute driving that,\nfor example. What do you think is actually driving the upside here? And do\nyou think it leads to a market share shift faster than we were expecting\ntowards XPU from GPU?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nYes. Interesting question, but none of the foregoing that you outlined.\nIt's very simple, why inference has come out very, very hot lately is --\nremember, we're only selling to a few customers, hyperscalers with\nplatforms and LLMs. That's it. There are not that many. And we have told\nyou how many we have, and we haven't increased any. But what is happening\nis these hyperscalers and those with LLMs need to justify all the spending\nthey're doing. Doing training makes your frontier models smarter. There's\nno question. It's almost like science, research and science. Make your\nfrontier models by creating very clever algorithms that consumes a lot of\ncompute for training smarter. Training makes it smarter. You want to\nmonetize inference. And that's what's driving it. Monetize, I indicated in\nmy prepared remarks, to drive to justify a return on investment and a lot\nof that investment is training and that return on investment is by creating\nuse cases, a lot of AI use cases, AI consumption out there through\navailability of a lot of inference. And that's what we are now starting to\nsee among our small group of customers.\n\n\nOperator\n\nAnd one moment for our next question. And that will come from the line of\nVijay Rakesh with Mizuho.\n\n\nVijay Raghavan Rakesh\nMizuho Securities USA LLC, Research Division\n\nHock, just going back on the AI server revenue side. I know you said fiscal\n'25 kind of tracking to that up 60%-ish growth. If you look at fiscal '26,\nyou have many new customers ramping [ Meta ] and probably you have the 4 of\nthe 6 hyperscalers that you have talked in the past. Would you expect that\ngrowth to accelerate into fiscal '26 about that kind of the 60% you talked\nabout?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nMy prepared remarks and which I clarified that the rate of growth we are\nseeing in '25 will sustain into '26 based on improved visibility and the\nfact that we're seeing inference coming in on top of the demand for\ntraining as the clusters get built up bigger and bigger, still stands. I\ndon't think we are getting very far by trying to pass through my words or\ndata here. It's just a -- it is and we see that going from '25 into '26 as\nthe best forecast we have at this point.\n\n\nVijay Raghavan Rakesh\nMizuho Securities USA LLC, Research Division\n\nGot it. And on the NVLink Fusion versus the scale up, do you expect that\nmarket to go the route of top of the rack where you've seen some move to\nthe Ethernet side in kind of the scale-out. Do you expect scale up to kind\nof go the same route?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nBroadcom do not participate in NVLink. So I'm really not qualified to\nanswer that question, I think.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Aaron\nRakers with Wells Fargo.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nI think all my questions on scale-up have been asked. But I guess, Hock,\ngiven the execution that you guys have been able to do with the VMware\nintegration, looking at the balance sheet, looking at the debt structure,\nI'm curious if you could give us your thoughts on how the company thinks\nabout capital return versus the thoughts on M&A and the strategy going\nforward.\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nOkay. That's an interesting question. And I agree, not too untimely, I\nwould say, because, yes, we have done a lot of the integration of VMware\nnow, and you can see that in the level of free cash flow we're generating\nfrom operations. And as we said, the use of capital has always been --\nwe're very, I guess, measured and upfront with a return through dividends,\nwhich is half our free cash flow of the preceding year. And frankly, as\nKirsten has mentioned 3 months ago and 6 months ago during the last 2\nearnings call, the first choice typically of the other part of the free\ncash flow is to bring down our debt to a more -- to a level that we feel\ncloser to no more than 2 ratio of debt to EBITDA.\n\n\nAnd that doesn't mean that opportunistically, we may go out there and buy\nback our shares as we did last quarter, and indicated by Kirsten, when we\ndid $4.2 billion of stock buyback. Now part of it is used to basically when\nemployee RSUs vest basically use -- we basically buy back part of the\nshares used to be paying taxes on the vested RSU. But the other part of it,\nI do admit we used it opportunistically last quarter when we see an\nsituation when basically, we think that it's a good time to buy some shares\nback, and we do.\n\n\nBut having said all that, our use of cash outside of dividends would be, at\nthis stage, used towards reducing our debt. And I know you're going to ask\nwhat about M&A? Well, the kind of M&A we will do in our view would be\nsignificant, would be substantial enough that we need debt in any case. And\nit's a good use of our free cash flow to bring down debt to, in a way,\nexpand, if not preserve our borrowing capacity if we have to do another M&A\ndeal.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Srini\nPajjuri with Raymond James.\n\n\nSrinivas Reddy Pajjuri\nRaymond James & Associates, Inc., Research Division\n\nHock, a couple of clarifications. First, on your 2026 expectation, are you\nassuming any meaningful contribution from the 4 prospects that you talked\nabout?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNo comment. We don't talk about prospects. We only talk about customers.\n\n\nSrinivas Reddy Pajjuri\nRaymond James & Associates, Inc., Research Division\n\nOkay. Fair enough. And then my other clarification is that I think you\ntalked about networking being about 40% of the mix within AI. Is that the\nright kind of mix that you expect going forward? Or is that going to\nmaterially change as we, I guess, see XPUs ramping going forward?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNo. I've always said and I expect that to be the case going forward in '26\nas we grow that networking should be a ratio to XPU should be closer in the\nrange of less than 30%, not the 40%.\n\n\nOperator\n\nOne moment for our next question. And that will come from the line of Joe\nMoore with Morgan Stanley.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nYou said you're not going to be impacted by export controls on AI. I know\nthere's been a number of changes since -- in the industry since the last\ntime you made the call. Is that still the case? And just can you give\npeople comfort that there's no impact from that down the road?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nNobody can give anybody comfort in this environment, Joe. But rules are\nchanging quite dramatically as trade -- bilateral trade agreements continue\nto be negotiated in a very, very dynamic environment. So I'll be honest, I\ndon't know -- I know as little as probably -- you probably know more than I\ndo maybe, in which case then I know very little about this whole thing\nabout whether there's any export control, how the export control will take\nplace. We're guessing. So I'd rather not answer that because no, I don't\nknow whether it won't be.\n\n\nOperator\n\nAnd we do have time for one final question. And that will come from the\nline of William Stein with Truist Securities.\n\n\nWilliam  Stein\nTruist Securities, Inc., Research Division\n\nI wanted to ask about VMware. Can you comment as to how far along you are\nin the process of converting customers to the subscription model? Is that\nclose to complete? Or is there still a number of quarters that we should\nexpect that, that conversion continues?\n\n\nHock E. Tan\nPresident, CEO & Executive Director\n\nThat's a good question. And so let me start off by saying a good way to\nmeasure it is most of our VMware contracts are about typically 3 years. And\nthat was what VMware did before we acquired them, and that's pretty much\nwhat we continue to do, 3 is very traditional. So based on that, the\nrenewals, we are like 2/3 of the way, almost to the halfway -- more than\nhalfway through the renewals. So we probably have at least another year\nplus, maybe 1.5 years to go.\n\n\nOperator\n\nAnd with that, I'd like to turn the call over to Ji Yoo for closing\nremarks.\n\n\nJi  Yoo\nDirector of Investor RelationsThank you, operator. Broadcom currently plans\nto report its earnings for the third quarter of fiscal year 2025 after\nclose of market on Thursday, September 4, 2025. A public webcast of\nBroadcom's earnings conference call will follow at 2:00 p.m. Pacific. That\nwill conclude our earnings call today. Thank you all for joining. Operator,\nyou may end the call.\nCopyright Â© 2025 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\nÂ© 2025 S&P Global Market Intelligence.",
  "has_qa": 1,
  "speaker_turns": [
    {
      "speaker": "Unknown",
      "role": "",
      "text": "Broadcom Inc. NasdaqGS:AVGO FQ2 2025 Earnings Call Transcripts Thursday, June 5, 2025 9:00 PM GMT S&P Global Market Intelligence Estimates Presentation"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "Welcome to Broadcom Inc.'s Second Quarter Fiscal Year 2025 Financial Results Conference Call. At this time, for opening remarks and introductions, I would like to turn the call over to Ji Yoo, Head of Investor Relations of Broadcom Inc."
    },
    {
      "speaker": "Ji  Yoo",
      "role": "Director of Investor Relations",
      "text": "Director of Investor Relations Thank you, operator, and good afternoon, everyone. Joining me on today's call are Hock Tan, President and CEO; Kirsten Spears, Chief Financial Officer; and Charlie Kawwas, President, Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market closed, describing our financial performance for the second quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the Investors section of the Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for 1 year through the Investors section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details of our second quarter fiscal year 2025 results, guidance for our third quarter of fiscal year 2025 as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments. Please refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments made during today's call will primarily refer to our non- GAAP financial results. I will now turn the call over to Hock."
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Thank you, Ji, and thank you, everyone, for joining us today. In our fiscal Q2 2025, total revenue was a record $15 billion, up 20% year-on-year. This 20% year-on-year growth was all organic as Q2 last year was the first full quarter with VMware. Now revenue was driven by continued strength in AI semiconductors and the momentum we have achieved in VMware. Now reflecting excellent operating leverage, Q2 consolidated adjusted EBITDA was $10 billion, up 35% year-on-year. Now let me provide more color. Q2 semiconductor revenue was $8.4 billion, with growth accelerating to 17% year-on-year, up from 11% in Q1. And of course, driving this growth was AI semiconductor revenue of over $4.4 billion, which is up 46% year-on-year and continues the trajectory of 9 consecutive quarters of strong growth. Within this, custom AI accelerators grew double digits year-on-year, while AI networking grew over 170% year-on-year. AI networking, which is based on Ethernet was robust and represented 40% of our AI revenue. As a standard- based open protocol, Ethernet enables one single fabric for both scale out and scale up and remains the preferred choice by our hyperscale customers. Our networking portfolio of Tomahawk switches, Jericho routers and NICs is what's driving our success within AI clusters in hyperscalers. And the momentum continues with our breakthrough Tomahawk 6 switch just announced this week. This represents the next-generation 102.4 terabits per second switch capacity. Tomahawk 6 enables clusters of more than 100,000 AI accelerators to be deployed in just 2 tiers instead of 3. This flattening of the AI cluster is huge because it enables much better performance in training next-generation frontier models through a lower latency, higher bandwidth and lower power. Turning to XPUs or custom accelerators. We continue to make excellent progress on the multiyear journey of enabling our 3 customers and 4 prospects to deploy custom AI accelerators. As we had articulated over 6 months ago, we eventually expect at least 3 customers to each deploy 1 million AI accelerated clusters in 2027, largely for training their frontier models. And we forecast and continue to do so a significant percentage of these deployments to be custom XPUs. These partners are still unwavering in their plan to invest despite the certain economic environment. In fact, what we've seen recently is that they are doubling down on inference in order to monetize their platforms. And reflecting this, we may actually see an acceleration of XPU demand into the back half of 2026 to meet urgent demand for inference on top of the demand we have indicated from training. And accordingly, we do anticipate now our fiscal 2025 growth rate of AI semiconductor revenue to sustain into fiscal 2026. Turning to our Q3 outlook. As we continue our current trajectory of growth, we forecast AI semiconductor revenue to be $5.1 billion, up 60% year-on- year, which would be the 10th consecutive quarter of growth. Now turning to non-AI semiconductors in Q2. Revenue of $4 billion was down 5% year-on- year. Non-AI semiconductor revenue is close to the bottom, has been relatively slow to recover, but they had bright spots. In Q2, broadband, enterprise networking and server storage revenues were up sequentially. However, industrial was down and as expected, wireless was also down due to seasonality. In Q3, we expect enterprise networking and broadband to continue to grow sequentially, but server storage, wireless and industrial are expected to be largely flat. And overall, we forecast non-AI semiconductor revenue to stay around $4 billion. Now let me talk about our infrastructure software segment. Q2 infrastructure software revenue of $6.6 billion was up 25% year- on-year, above our outlook of $6.5 billion. As we have said before, this growth reflects our success in converting our enterprise customers from perpetual vSphere to the full VCF software stack subscription. Customers are increasingly turning to VCF to create a modernized private cloud on-prem, which will enable them to repatriate workloads from public clouds while being able to run modern container-based applications and AI applications. Of our 10,000 largest customers, over 87% have now adopted VCF. The momentum from strong VCF sales over the past 18 months since the acquisition of VMware has created annual recurring revenue or otherwise known as ARR growth of double digits in our core infrastructure software. In Q3, we expect infrastructure software revenue to be approximately $6.7 billion, up 16% year-on-year. So in total, we are guiding Q3 consolidated revenue to be approximately $15.8 billion, up 21% year-on-year. We expect Q3 adjusted EBITDA to be at least 66%. With that, let me turn the call over to Kirsten."
    },
    {
      "speaker": "Kirsten M. Spears",
      "role": "CFO & Chief Accounting Officer",
      "text": "CFO & Chief Accounting Officer Thank you, Hock. Let me now provide additional detail on our Q2 financial performance. Consolidated revenue was a record $15 billion for the quarter, up 20% from a year ago. Gross margin was 79.4% of revenue in the quarter, better than we originally guided on product mix. Consolidated operating expenses were $2.1 billion, of which $1.5 billion was related to R&D. Q2 operating income of $9.8 billion was up 37% from a year ago, with operating margin at 65% of revenue. Adjusted EBITDA was $10 billion or 67% of revenue, above our guidance of 66%. This figure excludes $142 million of depreciation. Now a review of the P&L for our 2 segments. Starting with semiconductors. Revenue for our semiconductor solutions segment was $8.4 billion, with growth accelerating to 17% year-on-year, driven by AI. Semiconductor revenue represented 56% of total revenue in the quarter. Gross margin for our semiconductor solutions segment was approximately 69%, up 140 basis points year-on-year driven by product mix. Operating expenses increased 12% year-on-year to $971 million on increased investment in R&D for leading edge AI semiconductors. Semiconductor operating margin of 57% was up 200 basis points year-on-year. Now moving on to infrastructure software. Revenue for infrastructure software of $6.6 billion was up 25% year-on-year and represented 44% of total revenue. Gross margin for infrastructure software was 93% in the quarter compared to 88% a year ago. Operating expenses were $1.1 billion in the quarter, resulting in infrastructure software operating margin of approximately 76%. This compares to operating margin of 60% a year ago. This year-on-year improvement reflects our disciplined integration of VMware. Moving on to cash flow. Free cash flow in the quarter was $6.4 billion and represented 43% of revenue. Free cash flow as a percentage of revenue continues to be impacted by increased interest expense from debt related to the VMware acquisition and increased cash taxes. We spent $144 million on capital expenditures. Day sales outstanding were 34 days in the second quarter compared to 40 days a year ago. We ended the second quarter with inventory of $2 billion, up 6% sequentially in anticipation of revenue growth in future quarters. Our days of inventory on hand were 69 days in Q2 as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the second quarter with $9.5 billion of cash and $69.4 billion of gross principal debt. Subsequent to quarter end, we repaid $1.6 billion of debt, resulting in gross principal debt of $67.8 billion. The weighted average coupon rate and years to maturity of our $59.8 billion in fixed rate debt is 3.8% and 7 years, respectively. The weighted average interest rate and years to maturity of our $8 billion in floating rate debt is 5.3% and 2.6 years, respectively. Turning to capital allocation. In Q2, we paid stockholders $2.8 billion of cash dividends based on a quarterly common stock cash dividend of $0.59 per share. In Q2, we repurchased $4.2 billion or approximately 25 million shares of common stock. In Q3, we expect the non-GAAP diluted share count to be approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now moving on to guidance. Our guidance for Q3 is for consolidated revenue of $15.8 billion, up 21% year-on-year. We forecast semiconductor revenue of approximately $9.1 billion, up 25% year-on-year. Within this, we expect Q3 AI semiconductor revenue of $5.1 billion, up 60% year-on-year. We expect infrastructure software revenue of approximately $6.7 billion, up 16% year- on-year. For modeling purposes, we expect Q3 consolidated gross margin to be down approximately 130 basis points sequentially, primarily reflecting a higher mix of XPUs within AI revenue. As a reminder, consolidated gross margins through the year will be impacted by the revenue mix of infrastructure software and semiconductors. We expect Q3 adjusted EBITDA to be at least 66%. We expect the non-GAAP tax rate for Q3 and fiscal year 2025 to remain at 14%. And with this, that concludes my prepared remarks. Operator, please open up the call for questions. Question and Answer"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "[Operator Instructions] And our first question will come from the line of Ross Seymore with Deutsche Bank."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division Hock, I wanted to jump on to the AI side and specifically some of the commentary you had about next year. Can you just give a little bit more color on the inference commentary you gave? And is it more the XPU side, the connectivity side or both that's given you the confidence to talk about the growth rate that you have this year being matched next fiscal year?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Thank you, Ross. Good question. I think we're indicating that what we are seeing and what we have quite a bit of visibility increasingly is increased deployment of XPUs next year, much more than we originally thought and hand- in-hand with it, of course, more and more networking. So it's a combination of both."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division And the inference side of things?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Yes, we're seeing much more inference now."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Harlan Sur with JPMorgan."
    },
    {
      "speaker": "Harlan L.  Sur",
      "role": "JPMorgan Chase & Co, Research Division",
      "text": "JPMorgan Chase & Co, Research Division Great job on the quarterly execution. Hock, good to see the positive growth inflection quarter-over-quarter, year-over-year growth rates in your AI business. As the team has mentioned, right, the quarters can be a bit lumpy. So if I smooth out kind of first 3 quarters of this fiscal year, your AI business is up 60% year-over-year. It's kind of right in line with your 3-year kind of SAM growth CAGR, right? Given your prepared remarks and knowing that your lead times remain at 35 weeks or better, do you see the Broadcom team sustaining the 60% year-over- year growth rate exiting this year. And I assume that, that potentially implies that you see your AI business sustaining the 60% year-over-year growth rate into fiscal '26, again, based on your prepared commentary, which again is in line with your SAM growth figure. Is that kind of a fair way to think about the trajectory this year and next year?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Harlan, that's a very insightful set of analysis here, and that's exactly what we're trying to do here because over 6 months ago, we gave you guys a point, a year, 2027. As we come into the second half of 2025 and with improved visibility and updates we are seeing in the way our hyperscale partners are deploying data centers, AI clusters, we are providing you some level of guidance visibility what we are seeing, how the trajectory of '26 might look like. I'm not giving you any update on '27. We're just still establishing the update we have in '27 6 months ago. But what we're doing now is giving you more visibility into where we're seeing '26 headed."
    },
    {
      "speaker": "Harlan L.  Sur",
      "role": "JPMorgan Chase & Co, Research Division",
      "text": "JPMorgan Chase & Co, Research Division But is the framework that you laid out for us like second half of last year, which implies 60% kind of growth CAGR in your SAM opportunity, is that kind of the right way to think about it as it relates to the profile of growth in your business this year and next year?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Yes."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Ben Reitzes with Melius Research."
    },
    {
      "speaker": "Benjamin Alexander Reitzes",
      "role": "Melius Research LLC",
      "text": "Melius Research LLC Hock, networking -- AI networking was really strong in the quarter, and it seemed like it must have beat expectations. I was wondering if you could just talk about the networking in particular, what caused that? And how much of that is your acceleration into next year? And when do you think you see Tomahawk kicking in as part of that acceleration?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Well, I think the AI networking, as you probably would know, goes pretty hand-in-hand with deployment of AI accelerator clusters. It isn't -- It doesn't deploy on a timetable that's very different from the way the accelerators get deployed, whether they are XPUs or GPUs. It does happen. And they deployed a lot in scale-out where Ethernet, of course, is the choice of protocol, but it's also increasingly moving into the space of what we all call scale up within those data centers, where you have much higher, more than we originally thought consumption or density of switches than you have in the scale-out scenario. In fact, the increased density in scale up is 5 to 10x more than in scale out. And that's the part that kind of pleasantly surprised us and which is why this past quarter, Q2, the AI networking portion continues at about 40% from what we reported a quarter ago for Q1. And at that time, I said I expect it to drop. It hasn't."
    },
    {
      "speaker": "Benjamin Alexander Reitzes",
      "role": "Melius Research LLC",
      "text": "Melius Research LLC And your thoughts on Tomahawk driving acceleration for next year and when it kicks in?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Tomahawk 6, yes, that's extremely strong interest. Now we're not shipping big orders or any orders other than basic proof of concepts out to customers, but there is tremendous demand for this new 102 terabits per second Tomahawk switches."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Blayne Curtis with Jefferies."
    },
    {
      "speaker": "Blayne Peter Curtis",
      "role": "Jefferies LLC, Research Division",
      "text": "Jefferies LLC, Research Division Great results. I just wanted to ask maybe following up on the scale-out opportunity. So today, I guess your main customer is not really using kind of an NVLink switch style scale-up. I'm just kind of curious your visibility or the timing in terms of when you might be shipping a switched Ethernet scale-up network to your customers?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director You're talking scale up?"
    },
    {
      "speaker": "Blayne Peter Curtis",
      "role": "Jefferies LLC, Research Division",
      "text": "Jefferies LLC, Research Division Scale up."
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Yes. Well, scale up is very rapidly converting to Ethernet now, very much so. For our fairly narrow band of hyperscale customers, scale up is very much Ethernet."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Stacy Rasgon with Bernstein."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division Hock, I still wanted to follow up on that AI 2026 question. I want to just put some numbers on it, just to make sure I got it right. So if you did 60% in the first 3 quarters of this year, if you grow 60% year-over-year in Q4, it put you at like, I don't know, $5.8 billion, something like $19 billion or $20 billion for the year. And then are you saying you're going to grow 60% in 2026 would put you $30 billion plus in AI revenues for 2026? I'm just wondering, is that the math that you're trying to communicate to us directly?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director I think you're doing the math. I'm giving you the trend. But I did answer that question, I think Harlan asked earlier. The rate we are seeing now so far in fiscal '25 and will presumably continue, we don't see any reason why it doesn't given lead time visibility in '25. What we are seeing today based on what we have visibility on '26 is to be able to ramp up this AI revenue in the same trajectory. Yes."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division So is the SAM going up as well because now you have inference on top of training. So is the SAM still 60 to 90? Or is the SAM higher now as you see it?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director I'm not playing a SAM game here. I'm just giving a trajectory towards where we drew the line on '27 before. So I have no response to if the SAM going up or not. Stop talking about SAM now."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Vivek Arya with Bank of America."
    },
    {
      "speaker": "Vivek  Arya",
      "role": "BofA Securities, Research Division",
      "text": "BofA Securities, Research Division I had a near and then a longer-term question on the XPU business. So Hock, for near term, if your networking upsided in Q2 and overall AI was in line, it means XPU was perhaps not as strong. So I realize it's lumpy, but anything more to read into that, any product transition or anything else? So just a clarification there. And then longer term, you have outlined a number of additional customers that you're working with. What milestones should we look forward to? And what milestones are you watching to give you the confidence that you can now start adding their addressable opportunity into your '27 or '28 or other numbers? Like how do we get the confidence that these projects are going to turn into revenue in some reasonable time frame from now?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Okay. On the first part that you're asking, it's like you're trying to be -- you're trying to count how many angels on a head of a pin here. I mean, whether it's XPU or networking. Networking is hot, but that doesn't mean XPU is any soften. It's very much along the trajectory we expect it to be. And there's no lumpiness. There's no softening. It's pretty much what we expect the trajectory to go so far and into next quarter as well and probably beyond. So we have a -- it's a fairly, I guess, in our view, a fairly clear visibility on the short-term trajectory. In terms of going on to '27, no, we are not updating any numbers here. We -- 6 months ago, we drew a sense for the size of the SAM based on million GPU XPU clusters for 3 customers, and that's still very valid at that point, that will be there. And we have not provided any further updates here nor are we intending to at this point. When we get a better visibility, clearer sense of where we are, and that probably won't happen until '26, we'll be happy to give an update to the audience. But right now, though, in today's prepared remarks and answering a couple of questions, we have -- we are -- as we are doing -- as we have done yet, we are intending to give you guys more visibility what we are seeing the growth trajectory in '26."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of C.J. Muse with Cantor Fitzgerald."
    },
    {
      "speaker": "Christopher James Muse",
      "role": "Cantor Fitzgerald & Co., Research Division",
      "text": "Cantor Fitzgerald & Co., Research Division I was hoping to follow up on Ross's question regarding inference opportunity. Can you discuss workloads that are optimal that you're seeing for custom silicon? And that over time, what percentage of your XPU business could be inference versus training?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director I think there's no differentiation between training and inference in using merchant accelerators versus custom accelerators. I think the whole premise behind going towards custom accelerators continues, which is it's not a matter of cost alone. It is that as custom accelerators get used and get developed on a road map with any particular hyperscaler, there's a learning curve, a learning curve on how they could optimize the way the algorithms on their large language models gets written and tied to silicon. And that ability to do so is a huge value added in creating algorithms that can drive their LLMs to higher and higher performance, much more than basically a segregation approach between hardware and the software. It's that you literally combine end-to-end hardware and software as they take that journey. And it's a journey. They don't learn that in 1 year. Do it a few cycles, get better and better at it. And there lies the value -- the fundamental value in creating your own hardware versus using a third-party merchant silicon that you are able to optimize your software to the hardware and eventually achieve way high performance than you otherwise could. And we see that happening."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Karl Ackerman with BNP Paribas."
    },
    {
      "speaker": "Karl  Ackerman",
      "role": "BNP Paribas Exane, Research Division",
      "text": "BNP Paribas Exane, Research Division Hock, you spoke about the much higher content opportunity in scale-up networking. I was hoping you could discuss how important is demand adoption for co-packaged optics in achieving this 5 to 10x higher content for scale- up networks? Or should we anticipate much of the scale-up opportunity will be driven by Tomahawk and Thor NICs?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director I'm trying to decipher this question of yours. So let me try to answer it perhaps in the way I think you want me to clarify. First and foremost, I think most of what's scaling up, a lot of the scaling up that's going, as I call it, which means a lot of XPU or GPU to GPU interconnects is done on copper interconnects. And because the size of this scale-up cluster is still not that huge yet that you can get away with copper -- using copper interconnects. And they're still doing it. Mostly, they're doing it today. At some point soon, I believe, when you start trying to go beyond maybe 72 GPU to GPU interconnects, you may have to push towards a different protocol by protocol mode at a different medium from copper to optical. And when we do that, yes, perhaps then things like exotic stuff like co-packaging might be of silicon with optical might become relevant. But truly, what we really are talking about is that at some stage, as the clusters get larger and which means scale up becomes much bigger and you need to interconnect GPU or XPU to each other in scale up many more than just 72 or 100, maybe even 128, you start going more and more. You want to use optical interconnects simply because of distance. And that's when optical will start replacing copper. And when that happens, the question is what's the best way to deliver on optical. And one way is co- packaged optics, but it's not the only way. You can just simply use -- continue to use perhaps pluggable at low-cost optics. In which case, then you can interconnect the bandwidth, the radix of a switch and our switch is now 512 connections. So you can now connect all these XPUs, GPUs, 512 for scale-up phenomenon. And that was huge, but that's when you go to optical. That's going to happen within my view, a year or 2, and we'll be right at the forefront of it. And it may be co-packaged optics, which we are very much in development, but it's a lock-in co-package or it could just be as a first step, pluggable optics. Whatever it is, I think the bigger question is when does it go for optical from copper connecting GPU to GPU to optical connecting it. And the step in that move will be huge. And it's not necessarily co-packaged optics. So that's definitely one path we are pursuing."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And one moment for our next question. And that will come from the line of Joshua Buchalter with TD Cowen."
    },
    {
      "speaker": "Joshua Louis Buchalter",
      "role": "TD Cowen, Research Division",
      "text": "TD Cowen, Research Division I realize it's a bit nitpicky, but I wanted to ask about gross margins in the guide. So your revenue implies sort of $800 million incremental increase with gross profit up, I think, $400 million to $450 million, which is kind of pretty well below corporate average fall-through. I appreciate that semis is dilutive and custom is probably dilutive within semis. But anything else going on with margins that we should be aware of? And how should we think about the margin profile of custom longer term as that business continues to scale and diversify?"
    },
    {
      "speaker": "Kirsten M. Spears",
      "role": "CFO & Chief Accounting Officer",
      "text": "CFO & Chief Accounting Officer Yes. We've historically said that the XPU margins are slightly lower than the rest of the business other than wireless. And so there's really nothing else going on other than that. It's just exactly what I said, that the majority of it quarter-over-quarter, the 130 basis point decline is being driven by more XPUs."
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director There are more moving parts here than your simple analysis proves here. And I think your simple analysis is totally wrong in that regard."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And one moment for our next question. And that will come from the line of Timothy Arcuri with UBS."
    },
    {
      "speaker": "Timothy Michael Arcuri",
      "role": "UBS Investment Bank, Research Division",
      "text": "UBS Investment Bank, Research Division I also wanted to ask about scale up, Hock. So there's a lot of competing ecosystems. There's UALink, which, of course, you left. And now there's the big GPU company opening up NVLink, and they're both trying to build ecosystems, and there's an argument that you're an ecosystem of one. What would you say to that debate? Does opening up NVLink change the landscape? And sort of how do you view of your AI networking growth next year? Do you think it's going to be primarily driven by scale up? Or will it still be pretty scale-out heavy?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director It's -- people do like to create platforms and new protocols and systems. The fact of the matter is scale up can just be done easily, and it's currently available. It's open standards, open source, Ethernet. Just as well, you don't need to create new systems for the sake of doing something that you could easily be doing in networking in Ethernet. And so yes, I hear a lot of this interesting new protocols, standards that are trying to be created. And most of them, by the way, are proprietary, much as they like to call it otherwise. What is really open source and open standards is Ethernet. And we believe Ethernet will prevail as it does before -- for the last 20 years in traditional networking. There is no reason to create a new standard for something that could be easily done in transferring bits and bytes of data."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And one moment for our next question. And that will come from the line of Christopher Rolland with Susquehanna."
    },
    {
      "speaker": "Christopher Adam Jackson Rolland",
      "role": "Susquehanna Financial Group, LLLP, Research Division",
      "text": "Susquehanna Financial Group, LLLP, Research Division Yes. My question is for you, Hock. It's kind of a bigger picture one here. And this kind of acceleration that we're seeing in AI demand, do you think that this acceleration is because of a marked improvement in ASICs or XPUs closing the gap on the software side at your customers? Do you think it's these require tokenomics around inference, test time compute driving that, for example. What do you think is actually driving the upside here? And do you think it leads to a market share shift faster than we were expecting towards XPU from GPU?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Yes. Interesting question, but none of the foregoing that you outlined. It's very simple, why inference has come out very, very hot lately is -- remember, we're only selling to a few customers, hyperscalers with platforms and LLMs. That's it. There are not that many. And we have told you how many we have, and we haven't increased any. But what is happening is these hyperscalers and those with LLMs need to justify all the spending they're doing. Doing training makes your frontier models smarter. There's no question. It's almost like science, research and science. Make your frontier models by creating very clever algorithms that consumes a lot of compute for training smarter. Training makes it smarter. You want to monetize inference. And that's what's driving it. Monetize, I indicated in my prepared remarks, to drive to justify a return on investment and a lot of that investment is training and that return on investment is by creating use cases, a lot of AI use cases, AI consumption out there through availability of a lot of inference. And that's what we are now starting to see among our small group of customers."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And one moment for our next question. And that will come from the line of Vijay Rakesh with Mizuho."
    },
    {
      "speaker": "Vijay Raghavan Rakesh",
      "role": "Mizuho Securities USA LLC, Research Division",
      "text": "Mizuho Securities USA LLC, Research Division Hock, just going back on the AI server revenue side. I know you said fiscal '25 kind of tracking to that up 60%-ish growth. If you look at fiscal '26, you have many new customers ramping [ Meta ] and probably you have the 4 of the 6 hyperscalers that you have talked in the past. Would you expect that growth to accelerate into fiscal '26 about that kind of the 60% you talked about?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director My prepared remarks and which I clarified that the rate of growth we are seeing in '25 will sustain into '26 based on improved visibility and the fact that we're seeing inference coming in on top of the demand for training as the clusters get built up bigger and bigger, still stands. I don't think we are getting very far by trying to pass through my words or data here. It's just a -- it is and we see that going from '25 into '26 as the best forecast we have at this point."
    },
    {
      "speaker": "Vijay Raghavan Rakesh",
      "role": "Mizuho Securities USA LLC, Research Division",
      "text": "Mizuho Securities USA LLC, Research Division Got it. And on the NVLink Fusion versus the scale up, do you expect that market to go the route of top of the rack where you've seen some move to the Ethernet side in kind of the scale-out. Do you expect scale up to kind of go the same route?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Broadcom do not participate in NVLink. So I'm really not qualified to answer that question, I think."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Aaron Rakers with Wells Fargo."
    },
    {
      "speaker": "Aaron Christopher Rakers",
      "role": "Wells Fargo Securities, LLC, Research Division",
      "text": "Wells Fargo Securities, LLC, Research Division I think all my questions on scale-up have been asked. But I guess, Hock, given the execution that you guys have been able to do with the VMware integration, looking at the balance sheet, looking at the debt structure, I'm curious if you could give us your thoughts on how the company thinks about capital return versus the thoughts on M&A and the strategy going forward."
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Okay. That's an interesting question. And I agree, not too untimely, I would say, because, yes, we have done a lot of the integration of VMware now, and you can see that in the level of free cash flow we're generating from operations. And as we said, the use of capital has always been -- we're very, I guess, measured and upfront with a return through dividends, which is half our free cash flow of the preceding year. And frankly, as Kirsten has mentioned 3 months ago and 6 months ago during the last 2 earnings call, the first choice typically of the other part of the free cash flow is to bring down our debt to a more -- to a level that we feel closer to no more than 2 ratio of debt to EBITDA. And that doesn't mean that opportunistically, we may go out there and buy back our shares as we did last quarter, and indicated by Kirsten, when we did $4.2 billion of stock buyback. Now part of it is used to basically when employee RSUs vest basically use -- we basically buy back part of the shares used to be paying taxes on the vested RSU. But the other part of it, I do admit we used it opportunistically last quarter when we see an situation when basically, we think that it's a good time to buy some shares back, and we do. But having said all that, our use of cash outside of dividends would be, at this stage, used towards reducing our debt. And I know you're going to ask what about M&A? Well, the kind of M&A we will do in our view would be significant, would be substantial enough that we need debt in any case. And it's a good use of our free cash flow to bring down debt to, in a way, expand, if not preserve our borrowing capacity if we have to do another M&A deal."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Srini Pajjuri with Raymond James."
    },
    {
      "speaker": "Srinivas Reddy Pajjuri",
      "role": "Raymond James & Associates, Inc., Research Division",
      "text": "Raymond James & Associates, Inc., Research Division Hock, a couple of clarifications. First, on your 2026 expectation, are you assuming any meaningful contribution from the 4 prospects that you talked about?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director No comment. We don't talk about prospects. We only talk about customers."
    },
    {
      "speaker": "Srinivas Reddy Pajjuri",
      "role": "Raymond James & Associates, Inc., Research Division",
      "text": "Raymond James & Associates, Inc., Research Division Okay. Fair enough. And then my other clarification is that I think you talked about networking being about 40% of the mix within AI. Is that the right kind of mix that you expect going forward? Or is that going to materially change as we, I guess, see XPUs ramping going forward?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director No. I've always said and I expect that to be the case going forward in '26 as we grow that networking should be a ratio to XPU should be closer in the range of less than 30%, not the 40%."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "One moment for our next question. And that will come from the line of Joe Moore with Morgan Stanley."
    },
    {
      "speaker": "Joseph Lawrence Moore",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division You said you're not going to be impacted by export controls on AI. I know there's been a number of changes since -- in the industry since the last time you made the call. Is that still the case? And just can you give people comfort that there's no impact from that down the road?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director Nobody can give anybody comfort in this environment, Joe. But rules are changing quite dramatically as trade -- bilateral trade agreements continue to be negotiated in a very, very dynamic environment. So I'll be honest, I don't know -- I know as little as probably -- you probably know more than I do maybe, in which case then I know very little about this whole thing about whether there's any export control, how the export control will take place. We're guessing. So I'd rather not answer that because no, I don't know whether it won't be."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And we do have time for one final question. And that will come from the line of William Stein with Truist Securities."
    },
    {
      "speaker": "William  Stein",
      "role": "Truist Securities, Inc., Research Division",
      "text": "Truist Securities, Inc., Research Division I wanted to ask about VMware. Can you comment as to how far along you are in the process of converting customers to the subscription model? Is that close to complete? Or is there still a number of quarters that we should expect that, that conversion continues?"
    },
    {
      "speaker": "Hock E. Tan",
      "role": "President, CEO & Executive Director",
      "text": "President, CEO & Executive Director That's a good question. And so let me start off by saying a good way to measure it is most of our VMware contracts are about typically 3 years. And that was what VMware did before we acquired them, and that's pretty much what we continue to do, 3 is very traditional. So based on that, the renewals, we are like 2/3 of the way, almost to the halfway -- more than halfway through the renewals. So we probably have at least another year plus, maybe 1.5 years to go."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And with that, I'd like to turn the call over to Ji Yoo for closing remarks."
    },
    {
      "speaker": "Ji  Yoo",
      "role": "Director of Investor RelationsThank you, operator. Broadcom currently plans",
      "text": "Director of Investor RelationsThank you, operator. Broadcom currently plans to report its earnings for the third quarter of fiscal year 2025 after close of market on Thursday, September 4, 2025. A public webcast of Broadcom's earnings conference call will follow at 2:00 p.m. Pacific. That will conclude our earnings call today. Thank you all for joining. Operator, you may end the call. Copyright Â© 2025 by S&P Global Market Intelligence, a division of S&P Global Inc. All rights reserved. These materials have been prepared solely for information purposes based upon information generally available to the public and from sources believed to be reliable. No content (including index data, ratings, credit- related analyses and data, research, model, software or other application or output therefrom) or any part thereof (Content) may be modified, reverse engineered, reproduced or distributed in any form by any means, or stored in a database or retrieval system, without the prior written permission of S&P Global Market Intelligence or its affiliates (collectively, S&P Global). The Content shall not be used for any unlawful or unauthorized purposes. S&P Global and any third-party providers, (collectively S&P Global Parties) do not guarantee the accuracy, completeness, timeliness or availability of the Content. S&P Global Parties are not responsible for any errors or omissions, regardless of the cause, for the results obtained from the use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P GLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR DEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE CONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no event shall S&P Global Parties be liable to any party for any direct, indirect, incidental, exemplary, compensatory, punitive, special or consequential damages, costs, expenses, legal fees, or losses (including, without limitation, lost income or lost profits and opportunity costs or losses caused by negligence) in connection with any use of the Content even if advised of the possibility of such damages. S&P Global Market Intelligence's opinions, quotes and credit-related and other analyses are statements of opinion as of the date they are expressed and not statements of fact or recommendations to purchase, hold, or sell any securities or to make any investment decisions, and do not address the suitability of any security. S&P Global Market Intelligence may provide index data. Direct investment in an index is not possible. Exposure to an asset class represented by an index is available through investable instruments based on that index. S&P Global Market Intelligence assumes no obligation to update the Content following publication in any form or format. The Content should not be relied on and is not a substitute for the skill, judgment and experience of the user, its management, employees, advisors and/or clients when making investment and other business decisions. S&P Global Market Intelligence does not act as a fiduciary or an investment advisor except where registered as such. S&P Global keeps certain activities of its divisions separate from each other in order to preserve the independence and objectivity of their respective activities. As a result, certain divisions of S&P Global may have information that is not available to other S&P Global divisions. S&P Global has established policies and procedures to maintain the confidentiality of certain nonpublic information received in connection with each analytical process. S&P Global may receive compensation for its ratings and certain analyses, normally from issuers or underwriters of securities or from obligors. S&P Global reserves the right to disseminate its opinions and analyses. S&P Global's public ratings and analyses are made available on its Web sites, www.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and www.globalcreditportal.com (subscription), and may be distributed through other means, including via S&P Global publications and third-party redistributors. Additional information about our ratings fees is available at www.standardandpoors.com/usratingsfees. Â© 2025 S&P Global Market Intelligence."
    }
  ],
  "source_file": "Broadcom Inc., Q2 2025 Earnings Call, Jun 05, 2025.rtf"
}