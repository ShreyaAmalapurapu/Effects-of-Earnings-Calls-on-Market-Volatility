{
  "event_id": "AMD_2025-11-04",
  "ticker": "AMD",
  "company": "Advanced Micro Devices, Inc.",
  "quarter": 3,
  "fiscal_year": 2025,
  "call_date": "2025-11-04",
  "call_start_ts": "2025-11-04 22:00:00+00:00",
  "raw_text": "\n|[pic]                     |\n\nAdvanced Micro Devices, Inc. NasdaqGS:AMD\nFQ3 2025 Earnings Call Transcripts\nTuesday, November 4, 2025 10:00 PM GMT\nS&P Global Market Intelligence Estimates\n|      |-FQ3 2025-           |-FQ4  |-FY   |-FY   |\n|      |                     |2025- |2025- |2026- |\n|                              |CONSENSUS      |ACTUAL         |SURPRISE       |\n|                   |CONSENSUS          |ACTUAL             |SURPRISE           |\n|FQ4 2024           |1.09               |1.09               |[pic]0.00 %        |\n|FQ1 2025           |0.93               |0.96               |[pic]3.23 %        |\n|FQ2 2025           |0.48               |0.48               |[pic]0.00 %        |\n|FQ3 2025           |1.17               |1.20               |[pic]2.56 %        |\n\n|Table of Contents                                     |   |\n|Call Participants          |..............................................|3      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Presentation               |..............................................|4      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|Question and Answer        |..............................................|9      |\n|                           |..............................................|       |\n|                           |..............................................|       |\n|                           |..............                                |       |\n|                                                                                  |\n|Call Participants                                                                 |\n|                           |                           |                           |\n|EXECUTIVES                 |                           |                           |\n|                           |Timothy Michael Arcuri     |                           |\n|                           |UBS Investment Bank,       |                           |\n|Jean X. Hu                 |Research Division          |                           |\n|Executive VP, CFO,         |                           |                           |\n|Treasurer & Interim Chief  |                           |                           |\n|Accounting Officer         |Vivek  Arya                |                           |\n|                           |BofA Securities, Research  |                           |\n|                           |Division                   |                           |\n|Lisa T. Su                 |                           |                           |\n|Chair, President & CEO     |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Matthew D. Ramsay          |                           |                           |\n|Vice President of Financial|                           |                           |\n|Strategy & Investor        |                           |                           |\n|Relations                  |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|ANALYSTS                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Aaron Christopher Rakers   |                           |                           |\n|Wells Fargo Securities,    |                           |                           |\n|LLC, Research Division     |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Antoine  Chkaiban          |                           |                           |\n|New Street Research LLP    |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Christopher James Muse     |                           |                           |\n|Cantor Fitzgerald & Co.,   |                           |                           |\n|Research Division          |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joseph Lawrence Moore      |                           |                           |\n|Morgan Stanley, Research   |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Joshua Louis Buchalter     |                           |                           |\n|TD Cowen, Research Division|                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Ross Clark Seymore         |                           |                           |\n|Deutsche Bank AG, Research |                           |                           |\n|Division                   |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Stacy Aaron Rasgon         |                           |                           |\n|Sanford C. Bernstein & Co.,|                           |                           |\n|LLC., Research Division    |                           |                           |\n|                           |                           |                           |\n|                           |                           |                           |\n|Thomas James O'Malley      |                           |                           |\n|Barclays Bank PLC, Research|                           |                           |\n|Division                   |                           |                           |\n|                                                                                  |\n\n\nPresentation\n\n\nOperator\n\nGreetings, and welcome to the AMD Third Quarter 2025 Conference Call.\n[Operator Instructions] As a reminder, this conference call is being\nrecorded.\n\n\nIt is now my pleasure to introduce to you Matt Ramsay, VP, Financial\nStrategy and Investor Relations. Thank you, Matt. You may begin.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nThank you, and welcome to AMD's Third Quarter 2025 Financial Results\nConference Call. By now, you should have had the opportunity to review a\ncopy of our earnings press release and the accompanying slides. If you have\nnot had the opportunity to review these materials, they can be found on the\nInvestor Relations page of amd.com.\n\n\nWe will refer primarily to non-GAAP financial measures during today's call.\nThe full non-GAAP to GAAP reconciliations are available in today's press\nrelease and the slides posted on our website. Participants in today's\nconference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our\nExecutive Vice President, CFO and Treasurer. This is a live call and will\nbe replayed via webcast on our website.\n\n\nBefore we begin the call, I would like to note that Dr. Lisa Su, along with\nmembers of AMD's executive team, will present our long-term financial\nstrategy at our Financial Analyst Day next Tuesday, November 11 in New\nYork. Dr. Lisa Su will present at the UBS Global Technology and AI\nConference on Wednesday, December 3. And finally, Jean Hu will present at\nthe 23rd Annual Barclays Global Technology Conference on Wednesday,\nDecember 10.\n\n\nToday's discussion contains forward-looking statements based on our current\nbeliefs, assumptions and expectations, speak only as of today and as such\ninvolve risks and uncertainties that could cause results to deliver -- to\ndiffer materially from our current expectations. Please refer to the\ncautionary statement in our press release for more information on these\nfactors that could cause actual results to differ materially.\n\n\nAnd with that, I will hand the call over to Lisa.\n\n\nLisa T. Su\nChair, President & CEO\n\nThank you, Matt, and good afternoon to all those listening today. We\ndelivered an outstanding quarter with record revenue and profitability,\nreflecting broad-based demand across our data center AI, server and PC\nbusinesses. Revenue grew 36% year-over-year to $9.2 billion. Net income\nrose 31%, and free cash flow more than tripled led by record EPYC, Ryzen\nand Instinct processor sales. Our record third quarter performance marks a\nclear step-up in our growth trajectory as the combination of our expanding\ncompute franchise and rapidly scaling data center AI business drives\nsignificant revenue and earnings growth.\n\n\nTurning to our segments. Data center segment revenue increased 22% year-\nover-year to a record $4.3 billion led by the ramp of our Instinct MI350\nSeries GPUs and server share gains. Server CPU revenue reached an all-time\nhigh as adoption of 5th Gen EPYC Turin processors accelerated rapidly,\naccounting for nearly half of overall EPYC revenue in the quarter. Sales of\nour prior generation EPYC processors were also very robust in the quarter\nreflecting their strong competitive positioning across a wide range of\nworkloads.\n\n\nIn cloud, we had record sales as hyperscalers expanded EPYC CPU deployments\nto power both their own first-party services and public cloud offerings.\nHyperscalers launched more than 160 EPYC-powered instances in the quarter,\nincluding new Turin offerings from Google, Microsoft Azure, Alibaba and\nothers that deliver unmatched performance and price performance across a\nwide range of workloads. There are now more than 1,350 public EPYC cloud\ninstances available globally, a nearly 50% increase from a year ago.\n\n\nAdoption of EPYC in the cloud by large businesses more than tripled year-\nover-year as our on-prem share gains are driving increased demand from\nenterprise customers for AMD cloud instances to support hybrid compute. We\nexpect cloud demand to remain very strong as hyperscalers are significantly\nincreasing their general-purpose compute capacity as they scale their AI\nworkloads. Many customers are now planning substantially larger CPU build-\nouts over the coming quarters to support increased demands from AI serving\nas a powerful new catalyst for our server business.\n\n\nTurning to enterprise adoption. EPYC server sell-through increased sharply\nyear-over-year and sequentially reflecting accelerating enterprise\nadoption. More than 170 5th Gen EPYC platforms are in market from HPE,\nDell, Lenovo, Super Micro and others, our broadest portfolio to date with\nsolutions optimized for virtually every enterprise workload. We closed\nlarge new wins in the quarter with leading Fortune 500 technology, telecom,\nfinancial services, retail, streaming, social and automotive companies as\nwe expand our footprint across major verticals. The performance and TCO\nadvantages of our EPYC portfolio combined with our increased go-to-market\ninvestments and the expanded breadth of offerings from the leading server\nand solutions providers position us well for continued enterprise share\ngains.\n\n\nLooking ahead, we remain on track to launch our next-generation 2-nanometer\nVenice processors in 2026. Venice silicon is in the labs and performing\nvery well, delivering substantial gains in performance, efficiency and\ncompute density. Customer pull and engagement for Venice are the strongest\nwe have seen reflecting our competitive positioning and the growing demand\nfor more data center compute. Multiple cloud OEM partners have already\nbrought their first Venice platforms online, setting the stage for broad\nsolution availability and cloud deployments at launch.\n\n\nTurning to data center AI. Our Instinct GPU business continues to\naccelerate. Revenue grew year-over-year driven by the sharp ramp of MI350\nSeries GPU sales and broader MI MI300 Series deployments. Multiple MI350\nSeries deployments are underway with large cloud and AI providers, with\nadditional large-scale rollouts on track to ramp over the coming quarters.\n\n\nOracle became the first hyperscaler to publicly offer MI355X instances,\ndelivering significantly higher performance for real-time inference and\nmultimodal training workloads on OCI zettascale supercluster. Neocloud\nproviders Crusoe, DigitalOcean, TensorWave, Vultr and others also began\nramping availability of their MI350 Series public cloud offerings in the\nquarter. MI300 Series GPU deployments with AI developers also broadened in\nthe quarter. IBM and Zyphra will train multiple generations of future\nmultimodal models on a large-scale MI300X cluster. And Cohere is now using\nMI300X at OCI to train its Command family of models. For inference, a\nnumber of new partners, including Character.AI and Luma AI, are now running\nproduction workloads on MI300 Series demonstrating the performance and TCO\nadvantages of our architecture for real-time AI applications.\n\n\nWe also made significant progress on the software front in the quarter. We\nlaunched ROCm 7, our most advanced and feature-rich release to date,\ndelivering up to 4.6x higher inference and 3x higher training performance\ncompared to ROCm 6. ROCm 7 also introduces seamless distributed inference,\nenhanced code portability across hardware and new enterprise tools that\nsimplify the deployment and management of Instinct solutions. Importantly,\nour open software strategy is resonating with developers. Hugging Face,\nvLLM, SGLang and others contributed directly to ROCm 7 as we make ROCm the\nopen platform for AI development at scale.\n\n\nLooking ahead, our data center AI business is entering its next phase of\ngrowth with customer momentum building rapidly ahead of the launch of our\nnext-gen MI400 Series accelerators and Helios rack-scale solutions in 2026.\nThe MI400 Series combines a new compute engine with industry-leading memory\ncapacity and advanced networking capabilities to deliver a major leap in\nperformance for the most demanding AI training and inference workloads. The\nMI400 Series brings together our silicon, software and systems expertise to\npower Helios, our rack-scale AI platform designed to redefine performance\nand efficiency at data center scale.\n\n\nHelios integrates our Instinct MI400 Series GPUs, Venice EPYC CPUs and\nPensando NICs in a double-wide rack solution optimized for the performance,\npower, cooling and serviceability required for the next generation of AI\ninfrastructure and supports Meta's new open rack wide standard. Development\nof both our MI400 Series GPUs and Helios rack is progressing rapidly,\nsupported by deep technical engagements across a growing set of\nhyperscalers, AI companies and OEM and ODM partners to enable large-scale\ndeployments next year.\n\n\nThe ZT Systems team we acquired last year is playing a critical role in\nHelios development, leveraging their decades of experience building\ninfrastructure for the world's largest cloud providers to ensure customers\ncan deploy and scale Helios quickly within their environments. In addition,\nlast week, we completed the sale of the ZT manufacturing business to\nSanmina and entered a strategic partnership that makes them our lead\nmanufacturing partner for Helios. This collaboration will accelerate large\ncustomer deployments of our rack-scale AI solutions.\n\n\nOn the customer front, we announced a comprehensive multiyear agreement\nwith OpenAI to deploy 6 gigawatts of Instinct GPUs with the first gigawatt\nof MI450 Series accelerators scheduled to start coming online in the second\nhalf of 2026. The partnership establishes AMD as a core compute provider\nfor OpenAI and underscores the strength of our hardware, software and full\nstack solution strategy. Moving forward, AMD and OpenAI will work even more\nclosely on future hardware, software, networking and system-level road maps\nand technologies.\n\n\nOpenAI's decision to use AMD Instinct platforms for its most sophisticated\nand complex AI workloads sends a clear signal that our Instinct GPUs and\nROCm open software stack deliver the performance and TCO required for the\nmost demanding deployments. We expect this partnership will significantly\naccelerate our data center AI business with the potential to generate well\nover $100 billion in revenue over the next few years. Oracle announced they\nwill also be a lead launch partner for the MI450 Series, deploying tens of\nthousands of MI450 GPUs across Oracle Cloud Infrastructure beginning in\n2026 and expanding through 2027 and beyond.\n\n\nOur Instinct platforms are also gaining traction with sovereign AI and\nnational supercomputing programs. In the UAE, Cisco and G42 will deploy a\nlarge-scale AI cluster powered by Instinct MI350X GPUs to support the\nnation's most advanced AI workloads. In the U.S., we are partnering with\nthe Department of Energy and Oak Ridge National Labs to build Lux AI, the\nfirst AI factory dedicated to scientific discovery together with our\nindustrial partners, OCI and HPE. Powered by our Instinct MI350 series\nGPUs, EPYC CPUs and Pensando networking, Lux AI will provide a secure open\nplatform for large-scale training and distributed inference when it comes\nonline in early 2026.\n\n\nThe U.S. Department of Energy also selected our upcoming MI430X GPUs and\nEPYC Venice CPUs to power Discovery, the next flagship supercomputer at Oak\nRidge designed to set the standard for AI-driven scientific computing and\nextend U.S. high-performance computing leadership. Our MI430X GPUs are\ndesigned specifically to power nation-scale AI and supercomputing programs,\nextending our leadership, powering the world's most powerful computers to\nenable the next generation of scientific breakthroughs.\n\n\nIn summary, our AI business is entering a new phase of growth and is on a\nclear trajectory towards tens of billions in annual revenue in 2027 driven\nby our leadership rack-scale solutions, expanding customer adoption and an\nincreasing number of large-scale global deployments. I look forward to\nproviding more details on our data center AI growth plans at our Financial\nAnalyst Day next week.\n\n\nIn client and gaming, segment revenue increased 73% year-over-year to $4\nbillion. Our PC processor business is performing exceptionally well with\nrecord quarterly sales as the strong demand environment and breadth of our\nleadership Ryzen portfolio accelerates growth. Desktop CPU sales reached an\nall-time high with record channel sell-in and sell-out led by robust demand\nfor our Ryzen 9000 processors which deliver unmatched performance across\ngaming, productivity and content creation applications. OEM sell-through of\nRyzen-powered notebooks also increased sharply in the quarter reflecting\nsustained end customer pull for premium gaming and commercial AMD PCs.\n\n\nCommercial momentum accelerated in the quarter with Ryzen PC sell-through\nup more than 30% year-over-year as enterprise adoption grew sharply driven\nby large wins with Fortune 500 companies across health care, financial\nservices, manufacturing, automotive and pharmaceuticals. Looking ahead, we\nsee significant opportunity to continue growing our client business faster\nthan the overall PC market based on the strength of our Ryzen portfolio,\nbroader platform coverage and expanded go-to-market investments.\n\n\nIn gaming, revenue increased 181% year-over-year to $1.3 billion. Semi-\ncustom revenue increased as Sony and Microsoft prepare for the upcoming\nholiday sales period. In gaming graphics, revenue and channel sell-out grew\nsignificantly driven by the performance per dollar leadership of our Radeon\n9000 family. FSR 4, our machine learning upscaling technology that boosts\nframe rates and creates more immersive visuals saw rapid adoption this\nquarter with the number of supported games doubling since launch to more\nthan 85.\n\n\nTurning to our embedded segment. Revenue decreased 8% year-over-year to\n$857 million. Sequentially, revenue and sell-through increased as the\ndemand environment strengthened across multiple markets led by test and\nemulation, aerospace and defense, and industrial, vision and health care.\nWe expanded our embedded product portfolio with new solutions that extend\nour leadership across adaptive and x86 computing. We began shipping\nindustry-leading Versal Prime Series Gen 2 adaptive SoCs to lead customers,\ndelivered our first Versal RF development platforms to support several next-\ngeneration design wins and introduced the Ryzen Embedded 9000 Series with\nindustry-leading performance per watt and latency for robotics, edge\ncomputing and smart factory applications.\n\n\nThe design momentum remains very strong across our embedded portfolio. We\nare on track for a second straight year of record design wins already\ntotaling more than $14 billion year-to-date, reflecting the growing\nadoption of our leadership products across a broad range of markets and\nexpanding set of applications. In summary, our record third quarter results\nand strong fourth quarter outlook reflect the significant momentum building\nacross our business driven by sustained product leadership and disciplined\nexecution. Our data center AI, server and PC businesses are each entering\nperiods of strong growth led by an expanding TAM, accelerating adoption of\nour Instinct platforms and EPYC and Ryzen CPU share gains.\n\n\nThe demand for compute has never been greater as every major breakthrough\nin business, science and society now relies on access to more powerful,\nefficient and intelligent computing. These trends are driving unprecedented\ngrowth opportunities for AMD. I look forward to sharing more on our\nstrategy, road maps and long-range financial targets at our financial\nanalyst meeting next week.\n\n\nNow I'll turn the call over to Jean to provide additional color on our\nthird quarter results. Jean?\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of\nour financial results and then provide our outlook for the fourth quarter\nof fiscal 2025. We are pleased with our strong third quarter financial\nresults. We delivered a record revenue of $9.2 billion, up 36% year-over-\nyear, exceeding the high end of our guidance, reflecting strong momentum\nacross our business. Our third quarter results do not include any revenue\nfrom shipments of the MI308 GPU products to China. Revenue increased 20%\nsequentially driven by strong growth in the data center, and client and\ngaming segment and modest growth in the embedded segment.\n\n\nGross margin was 54%, up 40 basis points year-over-year primarily driven by\nproduct mix. Operating expenses were approximately $2.8 billion, an\nincrease of 42% year-over-year as we continue to invest aggressively in R&D\nto capitalize on significant AI opportunities and go-to-market activities\nfor revenue growth. Operating income was $2.2 billion, representing a 24%\noperating margin. Taxes, interest expense and other totaled $273 million.\nFor the third quarter of 2025, diluted earnings per share were $1.20\ncompared to $0.92 a year ago, an increase of 30% year-over-year.\n\n\nNow turning to our reportable segments, starting with data center. Data\ncenter segment revenue was a record of $4.3 billion, up 22% year-over-year\nprimarily driven by the strong demand for 5th Generation EPYC processors\nand Instinct MI350 Series GPUs. On a sequential basis, data center revenue\nincreased 34%, primarily driven by strong ramp of our AMD Instinct MI350\nSeries GPUs. The data center segment operating income was $1.1 billion or\n25% of revenue compared to $1 billion a year ago or 29% of revenue driven\nby higher revenue partially offset by higher R&D investment to capitalize\non significant AI opportunities.\n\n\nClient and gaming segment revenue was a record of $4 billion, up 73% year-\nover-year and 12% sequentially driven by strong demand for the latest\ngeneration of client and graphic processors and stronger sales of console\ngaming products. In the client business, revenue was a record $2.8 billion,\nup 46% year-over-year and 10% sequentially driven by record sales of our\nRyzen processors and a richer product mix. Gaming revenue rose to $1.3\nbillion, up 181% year-over-year and 16% sequentially, reflecting higher\nsemi-custom revenue and strong demand for our Radeon GPUs. Client and\ngaming segment operating income was $867 million or 21% of revenue compared\nto $288 million or 12% a year ago, driven by higher revenue partially\noffset by increase in go-to-market investment to support our revenue\ngrowth.\n\n\nEmbedded segment revenue was $857 million, down 8% year-over-year. Embedded\nwas up 4% sequentially as we saw certain end market demand strengthen.\nEmbedded segment operating income was $283 million or 33% of revenue\ncompared to $372 million or 40% a year ago. The decline in operating income\nwas primarily due to lower revenue and end market mix. Before I review the\nbalance sheet and the cash flow, as a reminder, we closed the sale of ZT\nSystem manufacturing business to Sanmina last week. The third quarter\nfinancial results of the ZT manufacturing business are reported separately\nin our financial statements as discontinued operations and are excluded\nfrom our non-GAAP financials.\n\n\nTurning to the balance sheet and cash flow. During the quarter, we\ngenerated $1.8 billion in cash from operating activities of continuing\noperations, and the free cash flow was a record of $1.5 billion. We\nreturned $89 million to shareholders through share repurchases resulting in\n$1.3 billion in share repurchases for the first 3 quarters of 2025. Exiting\nthe quarter, we have $9.4 billion authorization remaining under our share\nrepurchase program. At the end of the quarter, cash, cash equivalent and\nshort-term investment were $7.2 billion. Our total debt was $3.2 billion.\n\n\nNow turning to our fourth quarter 2025 outlook. Please note that our fourth\nquarter outlook does not include any revenue from AMD Instinct MI308\nshipment to China. For the fourth quarter of 2025, we expect revenue to be\napproximately $9.6 billion, plus or minus $300 million. The midpoint of our\nguidance represents approximately 25% year-over-year revenue growth driven\nby strong double-digit growth in our data center, and client and gaming\nsegment and a return to growth in our embedded segment.\n\n\nSequentially, we expect revenue to grow by approximately 4% driven by\ndouble-digit growth in the data center segment with strong growth in server\nand continued ramp of our MI350 Series GPUs, a decline in our client and\ngaming segment with client revenue increasing and the gaming revenue down\nstrong double digits, and double-digit growth in our embedded segment. In\naddition, we expect fourth quarter non-GAAP gross margin to be\napproximately 54.5%, and we expect non-GAAP operating expenses to be\napproximately $2.8 billion. We expect net interest and other expenses to be\na gain of approximately $37 million. We expect our non-GAAP effective tax\nrate to be 13%, and diluted share count is expected to be approximately\n1.65 billion shares.\n\n\nIn closing, we executed very well, delivering record revenue for the first\n3 quarters of the year. The strategic investment we are making position us\nwell to capitalize on expanding AI opportunities across all our end\nmarkets, driving sustainable long-term revenue growth and earnings\nexpansion for compelling shareholder value creation.\n\n\nWith that, I'll turn it back to Matt for the Q&A session.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor RelationsThank you very\nmuch, Jean. John, we can go ahead and poll the audience for questions now.\nThank you.\n\n\nQuestion and Answer\n\n\nOperator\n\n[Operator Instructions] And the first question comes from the line of Vivek\nArya with Bank of America Securities.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nI had a near-term and a medium-term question. For the near term, Lisa, I\nwas hoping if you could give us some sense of the CPU, GPU mix in Q3 and\nQ4. And just tactically, how are you managing this transition from your\nMI355 towards MI400 in the second half of next year? Can you continue to\ngrow in the first half of next year from these Q4 levels? Or should we\nexpect some kind of pause or digestion before customers get onboard the\nMI400 Series?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Vivek. Thanks for the question. So couple comments, we had a very\nstrong Q3 for the data center business. I think we saw strong\noutperformance in both the server as well as the data center AI business.\nAnd a reminder that, that was without any MI308 sales. The MI355 has ramped\nreally nicely. We expected a sharp ramp into the third quarter and that\nproceeded well. And as I mentioned, we've also seen some strengthening of\nthe server CPU sales and not just, let's call it, near term, but we're\nseeing our customers are giving us some visibility in the next few quarters\nthat they see elevated demand, which is positive.\n\n\nGoing into the fourth quarter, again, strong data center performance, up\ndouble digits sequentially and up in both server and data center AI, again,\non the strength of those businesses. And to your question, I mean, we're\nnot guiding into 2026 yet obviously, but given what we see today, we see a\nvery good demand environment into 2026. So we would expect that MI355\ncontinue to ramp in the first half of '26 and then, as we mentioned, MI450\nSeries comes online in the second half of 2026, and we would expect a\nsharper ramp as we go into the second half of 2026 of our data center AI\nbusiness.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nAnd for my follow-up, there is some industry debate, Lisa, about OpenAI's\nability to kind of simultaneously engage with all 3 merchants and the ASIC\nsuppliers, just given the constraints around power and CapEx and their\nexisting kind of CSP partners and so forth. So how are you thinking about\nthat? Like what is your level of visibility in the initial engagement and\nthen more importantly how it kind of broadens out into '27? Is there a way\nthat one can model what the allocation would be? Or just how should we\nthink about the level of visibility in this very important customer?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, absolutely, Vivek. Look, we're very -- obviously, very excited about\nour relationship with OpenAI. It's a very significant relationship. Think\nabout it as it's a pretty unique time for AI right now. There's just so\nmuch compute demand across all of the workloads. I think in our work with\nOpenAI we are planning multiple quarters out, ensuring that the power is\navailable, that the supply chain is available.\n\n\nThe key point is the first gigawatt, we will start deploying in the second\nhalf of '26 and that work is well underway. And we continue -- just given\nwhere lead times are and things like that, we are planning very closely\nwith OpenAI as well as the CSP partners to ensure that we're all prepared\nwith Helios so that we can deploy the technology as we stated. So I think,\noverall, we're working very closely together. I think we have good\nvisibility into the MI450 ramp, and things are progressing very well.\n\n\nOperator\n\nAnd the next question comes from the line of Thomas O'Malley with Barclays.\n\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nCongrats on the good results. I had a first question on Helios. Obviously,\nwith the announcement at OCP, customer interaction has to be growing. Could\nyou talk about into next year what your view is on discrete sales versus\nsystem sales? When do you see that crossover kind of happening? And just\nwhat initial responses have been from customers after getting a better look\nat it at the shelf?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, sure. Tom, thanks for the question. There's a lot of excitement around\nMI450 and Helios. I think the OCP reception was phenomenal. We had numerous\ncustomers and frankly bringing their engineering teams to understand more\nabout the system, more about how it's built. There's always been some\ndiscussion about just how complex these rack-scale systems are, and they\ncertainly are, and we are very proud of the Helios design. I think it has\nall the features, functions, reliability, performance, power performance\nthat you would expect.\n\n\nI think the interest in MI450 and Helios has just expanded over the last\nnumber of weeks, certainly with some of the announcements that we've made\nwith OpenAI and OCI as well as the OCP show with Meta. I think, overall,\nfrom our perspective, I think things are going really well in both the\ndevelopment as well as the customer engagements there. So in terms of rack-\nscale solutions, we would expect that the early customers for MI450 will\nreally be around the rack-scale solutions. We will have other form factors\nas well for the MI450 Series, but there's a lot of interest in the full\nrack-scale solution.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nSuper helpful. And then as my follow-up, it's a broader question as well\nand similar to kind of what Vivek asked. But if you look at the power\nrequirements that are out there for some of the early announcements into\nnext year, they're pretty substantial. And then you also have component\nissues that you're seeing across interconnected memory. Just from your\nperspective as an industry leader, where do you think that the constraint\nwill be? Will it come first with components not being available? Or do you\nthink that both data center footprint in terms of infrastructure and/or\npower is the gating factor to some of these deployments into next year just\nas we really see some larger number starts get deployed.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Tom. I think what you're pointing out is what we, as an\nindustry, have to do together. The entire ecosystem has to plan together\nand that is exactly what we're doing. So we're working with our customers\non their power plans over the next, actually, I would say, 2 years from a\nsilicon and a memory and a packaging and a component supply chain. We're\nworking with our supply chain partners to make sure all of that capacity is\navailable.\n\n\nI can tell you from our visibility, we feel very good that we have a strong\nsupply chain that is prepared to deliver sort of these very significant\ngrowth rates and large amount of compute that is out there. And I think all\nof this is going to be tight. I think there is a -- you can see from some\nof the CapEx spending that there's a desire to put on more compute, and\nwe're working closely together.\n\n\nI will say that the ecosystem is very -- I would say, works very hard when\nthere are these types of, let's call it, tightness out there. And so we\nalso see things open up as we're working, getting more power, getting more\nsupply, all of those things. So the net-net is, I think, we are well\npositioned to grow significantly as we transition into the second half of\n'26 into '27 with the MI450 and Helios.\n\n\nOperator\n\nAnd the next question comes from the line of Joshua Buchalter with TD\nCowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nActually, wanted to start on the CPU side. So you and your largest\ncompetitor in that space have talked about near-term strength, supporting\nAI workloads on general purpose servers from agentic. Maybe you could speak\nto the sustainability of these trends. And they called out supply\nconstraints. Are you seeing any of those in your supply chain? And like are\nwe in a period where we should think about the CPU business on the data\ncenter side as being a seasonal or should we expect normal seasonality in\nthe first half of next year?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Josh. A couple comments on the CPU server side. I think we've been\nwatching this trend for the last couple of quarters and we started seeing,\nlet's call it, some positive signs in CPU demand actually a couple quarters\nago. And what's happened as we've gone through 2025 is now we see sort of a\nbroadening of that CPU demand. So we have -- a number of our large\nhyperscale clients are now forecasting significant CPU build into 2026. And\nso from that standpoint, I think it's a positive demand environment, and it\nis because AI is requiring quite a bit of general-purpose compute. And\nthat's great. It catches our cycle as we're ramping Turin. So the Turin\nramp has gone extremely fast, and we see good pull for that product as well\nas consistent strong demand for our Genoa product line as well.\n\n\nSo back to seasonality as we go into 2026, I think we expect that the CPU\ndemand environment into 2026 is going to be, let's call it, positive. And\nso we'll guide more as we get into the end of the year, but I would expect\na positive demand environment for CPUs as we see this demand. I do feel\nlike it's durable. It is not a short-term thing. I think it is a multi-\nquarter phenomenon as we're seeing just much more demand as these AI\nworkloads really turn into -- you have to do real work.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nSo Josh, on the supply side, we have supplies to support our growth and\nespecially in 2026, we're prepared for the ramp.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nGot it. And for my follow-up, Lisa, in your prepared remarks, you\nhighlighted progress you guys have made on ROCm 7. I know this has been an\narea of focus. And can you maybe spend a minute or 2 talking about where\nyou feel you're at competitively with ROCm? How wide is the breadth of\nsupport you're able to offer to the developer community? And what areas do\nyou still have work to do to close any potential competitive gap?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Josh, thanks for the question. Look, we've made great progress with\nROCm. ROCm 7 is a significant step forward in terms of performance and sort\nof all the frameworks that we support. It's been really, really important\nfor us to get sort of day zero support of all the newest models and native\nsupport for all the newest frameworks. I would say most customers who are\nstarting with AMD now have a very smooth experience as they're bringing on\ntheir workload to AMD. There's obviously always more work to do.\n\n\nWe're continuing to augment the libraries and the overall environment that\nwe have, especially as we go to some of the newer workloads where you see\ntraining and inference really coming together with reinforcement learning.\nBut overall, I think very strong progress with ROCm. And by the way, we're\ngoing to continue to invest in this area because it's so important to\nreally make our customer development experience as smooth as we can.\n\n\nOperator\n\nAnd the next question comes from the line of C.J. Muse with Cantor\nFitzgerald.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI guess first question, as you think about the 355 to 400 transition and\nmoving to full rack scale, is there a framework that we should be thinking\nabout for gross margins throughout calendar '26?\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nYes, C.J., thanks for the question. I think in general, as we said in the\npast for our data center GPU business, the gross margin continue to improve\nwhen we ramp a new generation of product. Typically at the beginning of the\nramp you go through a transition period, then you will normalize the gross\nmargin. We're not guiding 2026, but our priority in data center GPU\nbusiness is to really expand the top line revenue growth and the gross\nmargin dollars, and of course, at the same time, we'll continue to drive\nthe gross margin percentage up, too.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nVery helpful. And I guess maybe, Lisa, to kind of probe kind of your growth\nexpectations through '26 and beyond, and you talked about tens of billions\nof dollars in '27, can you kind of speak at a high level how you're\nthinking about OpenAI and other large customers and how we should be\nthinking about the breadth of your customer kind of penetration throughout\ncalendar '26, '27? Any help on that would be super.\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, C.J. And we'll certainly address this topic in more detail at our\nAnalyst Day next week. But let me give you some maybe higher-level points.\nLook, I think we're really excited about our road map. I think we have seen\ngreat traction amongst the largest customers. The OpenAI relationship is\nextremely important to us, and it's great to be able to talk at the multi-\ngigawatt scale because I think that really is what we believe we can\ndeliver to the marketplace.\n\n\nBut there are numerous other customers that we are in deep engagements\nwith. We talked about OCI. We also announced a couple of systems with the\nDepartment of Energy that are significant systems, and we have many other\nengagements. So the way you should think about it is there are multiple\ncustomers that we would expect to have, let's call it, very significant\nscale in the MI450 generation. And that's sort of the breadth of the\ncustomer engagements that we've built, and it's also how we're dimensioning\nthe supply chain to ensure that we can supply certainly our OpenAI\npartnership as well as the numerous other partnerships that are well\nunderway.\n\n\nOperator\n\nAnd the next question comes from the line of Stacy Rasgon with Bernstein\nResearch.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nMy first one, for data center in the quarter, what grew more year-over-year\non a dollar to percentage basis, the servers or the GPUs?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Stacy, I think our commentary was data center grew nicely year-over-\nyear in both of the areas, both for servers as well as data center AI.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nYes. But could you -- I mean, just directionally, did one -- which one grew\nmore than the other? I'm not even asking for numbers, just directionally.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nDirectionally, they are similar, but server is a little bit better.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nServer is a little bit better. Okay. And then on the guidance, so you said\nthat servers -- I mean, data center overall up double digits. You said\nserver is up strong double digits. What does that mean? Is that like more\nthan 20%? Or like how do I think about what you mean by strong double\ndigits? Because, again, I'm trying to -- like I mean, for the GPUs for the\nyear, like do you think you're -- you were saying roughly like $6.5 billion\nor something last quarter for the year, do you think it's still in that\nrange? It kind of feels like you're still there.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nStacy, here is what we guided. We guided sequentially data center will be\nup double digits, and we said server will go up strongly. And at the same\ntime, we also said that MI350 also going to ramp. So we did not -- I don't\nthink what you just mentioned was what we guided.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nOkay. So I mean if you say servers are up strongly, does that mean they're\nup more than the Instinct because you didn't really make that commentary on\nInstinct?\n\n\nLisa T. Su\nChair, President & CEO\n\nNo. Look, Stacy, let me say it. So data center [ up ] sequentially double-\ndigit percentage, both server and data center AI are going to be up as\nwell. And from the standpoint of where they are, I think we're pleased with\nhow both of them are performing. The strong double-digit percentage comment\nperhaps was applying to the year-over-year commentary.\n\n\nOperator\n\nAnd the next question comes from the line of Timothy Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nLisa, I know it's only been a month since you announced this idea with\nOpenAI, but can you give us maybe some anecdotes of how this has influenced\nyour position in the market with other customers? Like are you engaged with\ncustomers that you wouldn't have been engaged with if you hadn't done this\ndeal? That's the first part of the question. And then the second part\nrelates to a prior question, which is that it looks like they could be\nsomething like half of your data center GPU revenue in the 2027, 2028 time\nframe. So how much risk, in your mind, is there around that single customer\nfor you?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Tim. So let me say a couple things. First of all, the OpenAI deal has\nbeen in the works for quite some time. We're happy to be able to talk about\nit broadly and also talk about the scale of the deployments and the scale\nof the engagement being multiyear, multi-gigawatt. I think all those things\nwere very positive. We've had a number of other engagements as well. I\nthink over the last -- if you were to ask specifically over the last month,\nI would say that it's been a number of factors. I think the OpenAI deal was\none of them.\n\n\nI think having -- being able to show the Helios rack in full force at Open\nCompute was also a very important milestone because people could see the\nengineering and sort of the capabilities of the Helios rack. And if you're\nasking whether we've seen an increase of interest or an acceleration of\ninterest, I think the answer is yes. I think customers are broadly engaged\nand perhaps broadly engaged at higher scale, which is a good thing.\n\n\nAnd then from the standpoint of customer concentration, I think a very key\nfoundation for us in this business is to have a broad set of customers.\nWe've always been engaged with a number of customers. I think we're\ndimensioning the supply chain in such a way that we would have ample supply\nto have multiple customers at similar scale as we go into the '27, '28 time\nframe, and that's certainly the goal.\n\n\nOperator\n\nAnd the next question comes from the line of Aaron Rakers with Wells Fargo.\n\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nI'm curious on the server strength that you're seeing, if there's a way to\nunpack how we think about unit growth versus ASP expansion as we move\nthrough the Turin product cycle. And how do you guys just kind of think\nabout that going forward?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. So Aaron, on the server CPU side, Turin certainly is more content, so\nwe see ASPs grow as Turin ramps. But I also mentioned in the prepared\nremarks that we're actually seeing a very good mix of Genoa still there. So\nTurin is ramping very quickly, but we are also seeing Genoa demand continue\nwell as the hyperscalers are not able to move everything to the latest\ngeneration immediately.\n\n\nSo from our standpoint, I think it's broad-based CPU demand across a number\nof different workloads. This is -- a little bit of this is, let's call it,\nserver refresh, but it seems like from our customer conversations, the\nworkloads are broadly due to the fact that AI workloads are spawning more\ntraditional compute, so more build-out is necessary.\n\n\nI think going forward, one of the things that we see is there is more of a\ndesire for the latest generation. And so as much as we're happy with how\nTurin is ramping, we're seeing actually a strong pull on Venice and a lot\nof early engagement in Venice, which kind of says a lot about kind of the\nimportance of general-purpose compute at this point in time.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nAs a quick follow-up, I'm curious and not to steal maybe the discussion\nfrom next week, but Lisa, you've been very consistent, like $500 billion of\ntotal AI silicon TAM opportunity and obviously progressing above that. I'm\ncurious, as we think about these large megawatt kind of deployments, how\nyou think about the updated views on that AI silicon TAM as we look\nforward.\n\n\nLisa T. Su\nChair, President & CEO\n\nWell, Aaron, as you said, not to take too much away from what we're going\nto talk about next week, look, we're going to give you a full picture of\nhow we see the market next week. But suffice it to say, from everything\nthat we see, we see the AI compute TAM just going up. So we'll have some\nupdated numbers for you, but the view is, whereas $500 billion sounded like\na lot when we first talked about it, we think there is a larger opportunity\nfor us over the next few years, and that's pretty exciting.\n\n\nOperator\n\nThe next question comes from Antoine Chkaiban with New Street Research.\n\n\nAntoine  Chkaiban\nNew Street Research LLP\n\nSo I'd like to ask about whether the developing relationship with OpenAI\ncould be a tailwind to the development of your software stack. Can you\nmaybe tell us about how the collaboration works in practice and whether the\npartnership contributed in making ROCm more robust?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Antoine, thanks for the question. I think the answer is yes. I think\nall of our large customers contribute to, let's call it, a broadening and\ndeepening of our software stack overall. I think the relationship with\nOpenAI is certainly one where our plans are to work deeply together on\nhardware as well as software as well as systems and future road map. And\nfrom that standpoint, the work that we're doing together with them on\nTriton is certainly very valuable.\n\n\nBut I will say beyond OpenAI, the work that we do with all of our largest\ncustomers are super helpful to strengthen the software stack. And we have\nput significant new resources into not just the largest customers, but we\nare working with a broad set of AI-native companies who are actively\ndeveloping on the ROCm stack. We get lots of feedback. I think we've made\nsignificant progress in the training and inference stack, and we're going\nto continue to double down and triple down in this area. So more customers\nthat use AMD, I think all of that goes to enhancing the ROCm stack. And\nwe're actually -- we'll talk a little bit more about this next week, but\nwe're also using AI to help us accelerate the rate and pace of some of the\nROCm kernel development and just the overall ecosystem.\n\n\nAntoine  Chkaiban\nNew Street Research LLP\n\nMaybe as a quick follow-up, could you tell us about the useful lives of\nGPUs? I know that most CSPs depreciate them over 5, 6 years. But in your\nconversations with them, I'm just wondering if you see or hear any early\nindication that, in practice, they may be planning to sweat those GPUs for\nlonger than that.\n\n\nLisa T. Su\nChair, President & CEO\n\nI think we have seen some early indications of that, Antoine. I think the\nkey point being, clearly, there's a desire to get on the latest and\ngreatest GPUs when you're building new data center infrastructure. And\ncertainly, when we're looking at MI355s, they're often going into new\nliquid-cooled facilities, MI450 Series as well. But then we're also seeing\nthe other trend, which is there's just a need for more AI compute. And from\nthat standpoint, some of the older generation -- MI300X is still doing\nquite well in terms of just where we see people deploying and using\nespecially for inference. And from that standpoint, I think you see a\nlittle bit of both.\n\n\nOperator\n\nAnd the next question comes from the line of Joe Moore with Morgan Stanley.\n\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nYou mentioned MI308, I guess what's your posture there to the extent that\nif there is some relief that you're able to ship, do you have readiness to\ndo that? Can you give us a sense for how much of a swing factor that could\nbe?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Joe. So look, it's still a pretty dynamic situation with MI308. So\nthat's the reason that we did not include any MI308 revenue in the Q4\nguide. We have received some licenses for MI308, so we're appreciative of\nthe administration supporting some licenses for MI308. We're still working\nwith our customers on the demand environment and sort of what the overall\nopportunity is. And so we'll be able to update that more in the next couple\nof months.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOkay. But you do have product to support that market if it does open up? Or\ndoes -- are you going to have to start to kind of rebuild inventory for\nthat?\n\n\nLisa T. Su\nChair, President & CEO\n\nWe've had some work in process. I think we continue to have that work in\nprocess, but we'll have to see sort of how the demand environment shapes\nup.\n\n\nOperator\n\nAnd the final question comes from the line of Ross Seymore with Deutsche\nBank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nLisa, this might take longer than the amount of time we have left before\nthe top of the hour, but there's been so many of these multi-gigawatt\nannouncements from OpenAI. How does AMD truly differentiate in there? When\nyou see that big customer signing deals with other GPU vendors and ASIC\nvendors, et cetera, how do you attack that market differently than those\ncompetitors to not only get the 6 gigawatt initially but hopefully more\nafter that?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Ross. Well, look, what I see is actually this environment where the\nworld needs more AI compute. And from that standpoint, I think OpenAI has\nkind of led in the quest for more AI compute, but they're not alone. I\nthink when you look across the large customers, there is really a demand\nfor more AI compute as you go forward over the next couple of years. I\nthink we each have our advantages in terms of how we are positioning our\nproducts. I think MI450 Series, in particular, I think, is an extremely\nstrong product, rack-scale solution. Overall, when we look at compute\nperformance, when we look at memory performance, we think it's extremely\nwell positioned for both inference as well as training.\n\n\nI think the key here is time to market, it's total cost of ownership, it's\ndeep partnership and thinking about not just MI450 Series, but what happens\nafter that. So we're deep in conversations on MI500 and beyond. And we\ncertainly think we're well positioned to not only participate but\nparticipate in a very meaningful way across the sort of the demand\nenvironment here. And I think we have certainly learned a ton over the last\ncouple of years with our AI road map. We've made significant inroads in\nterms of just what the largest customer needs from a workload standpoint.\nSo I'm pretty optimistic about our ability to capture a significant piece\nof this market going forward.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nGreat. And I guess as my follow-up, it'll be a direct follow-on to that.\nYou did a unique structure by granting some warrants with this deal, and I\nknow they're -- they vest according to a price that would be very accretive\nand make everybody happy. Do you think that was a relatively unique\nagreement or given that the world needs more processing power that AMD is\nopen to somewhat similar, conceptually similar creative ways to address\nthat demand over time with other equity vehicles, et cetera?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Ross. So I would say it was a unique agreement from the standpoint\nthat unique time in AI, what we wanted, what we prioritized was really deep\npartnership and multiyear, multigeneration, significant scale. And I think\nwe got that. We got a structure that has extremely aligned incentives.\nEverybody wins, right? We win. OpenAI wins, and our shareholder win -- sort\nof benefits from this. And all of that accrues to the overall road map.\n\n\nI think as we look forward, I think we have a lot of very interesting\npartnerships that are developing, whether they're with the largest AI users\nor you think about sovereign AI opportunities. And we look at each one of\nthese as a unique opportunity where we're bringing sort of the whole of\nAMD, both technically as well as all the rest of our capabilities to the\nparty. So I would say OpenAI was pretty unique, but I would imagine that\nthere are lots of other opportunities for us to bring our capabilities into\nthe ecosystem and participate in a significant way.\n\n\nOperatorLadies and gentlemen, that does conclude the question-and-answer\nsession and that also concludes today's teleconference. We thank you for\nyour participation. You may disconnect your lines at this time.\nCopyright  2025 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2025 S&P Global Market Intelligence.\n\n",
  "presentation_text": "Operator\n\nGreetings, and welcome to the AMD Third Quarter 2025 Conference Call.\n[Operator Instructions] As a reminder, this conference call is being\nrecorded.\n\n\nIt is now my pleasure to introduce to you Matt Ramsay, VP, Financial\nStrategy and Investor Relations. Thank you, Matt. You may begin.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor Relations\n\nThank you, and welcome to AMD's Third Quarter 2025 Financial Results\nConference Call. By now, you should have had the opportunity to review a\ncopy of our earnings press release and the accompanying slides. If you have\nnot had the opportunity to review these materials, they can be found on the\nInvestor Relations page of amd.com.\n\n\nWe will refer primarily to non-GAAP financial measures during today's call.\nThe full non-GAAP to GAAP reconciliations are available in today's press\nrelease and the slides posted on our website. Participants in today's\nconference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our\nExecutive Vice President, CFO and Treasurer. This is a live call and will\nbe replayed via webcast on our website.\n\n\nBefore we begin the call, I would like to note that Dr. Lisa Su, along with\nmembers of AMD's executive team, will present our long-term financial\nstrategy at our Financial Analyst Day next Tuesday, November 11 in New\nYork. Dr. Lisa Su will present at the UBS Global Technology and AI\nConference on Wednesday, December 3. And finally, Jean Hu will present at\nthe 23rd Annual Barclays Global Technology Conference on Wednesday,\nDecember 10.\n\n\nToday's discussion contains forward-looking statements based on our current\nbeliefs, assumptions and expectations, speak only as of today and as such\ninvolve risks and uncertainties that could cause results to deliver -- to\ndiffer materially from our current expectations. Please refer to the\ncautionary statement in our press release for more information on these\nfactors that could cause actual results to differ materially.\n\n\nAnd with that, I will hand the call over to Lisa.\n\n\nLisa T. Su\nChair, President & CEO\n\nThank you, Matt, and good afternoon to all those listening today. We\ndelivered an outstanding quarter with record revenue and profitability,\nreflecting broad-based demand across our data center AI, server and PC\nbusinesses. Revenue grew 36% year-over-year to $9.2 billion. Net income\nrose 31%, and free cash flow more than tripled led by record EPYC, Ryzen\nand Instinct processor sales. Our record third quarter performance marks a\nclear step-up in our growth trajectory as the combination of our expanding\ncompute franchise and rapidly scaling data center AI business drives\nsignificant revenue and earnings growth.\n\n\nTurning to our segments. Data center segment revenue increased 22% year-\nover-year to a record $4.3 billion led by the ramp of our Instinct MI350\nSeries GPUs and server share gains. Server CPU revenue reached an all-time\nhigh as adoption of 5th Gen EPYC Turin processors accelerated rapidly,\naccounting for nearly half of overall EPYC revenue in the quarter. Sales of\nour prior generation EPYC processors were also very robust in the quarter\nreflecting their strong competitive positioning across a wide range of\nworkloads.\n\n\nIn cloud, we had record sales as hyperscalers expanded EPYC CPU deployments\nto power both their own first-party services and public cloud offerings.\nHyperscalers launched more than 160 EPYC-powered instances in the quarter,\nincluding new Turin offerings from Google, Microsoft Azure, Alibaba and\nothers that deliver unmatched performance and price performance across a\nwide range of workloads. There are now more than 1,350 public EPYC cloud\ninstances available globally, a nearly 50% increase from a year ago.\n\n\nAdoption of EPYC in the cloud by large businesses more than tripled year-\nover-year as our on-prem share gains are driving increased demand from\nenterprise customers for AMD cloud instances to support hybrid compute. We\nexpect cloud demand to remain very strong as hyperscalers are significantly\nincreasing their general-purpose compute capacity as they scale their AI\nworkloads. Many customers are now planning substantially larger CPU build-\nouts over the coming quarters to support increased demands from AI serving\nas a powerful new catalyst for our server business.\n\n\nTurning to enterprise adoption. EPYC server sell-through increased sharply\nyear-over-year and sequentially reflecting accelerating enterprise\nadoption. More than 170 5th Gen EPYC platforms are in market from HPE,\nDell, Lenovo, Super Micro and others, our broadest portfolio to date with\nsolutions optimized for virtually every enterprise workload. We closed\nlarge new wins in the quarter with leading Fortune 500 technology, telecom,\nfinancial services, retail, streaming, social and automotive companies as\nwe expand our footprint across major verticals. The performance and TCO\nadvantages of our EPYC portfolio combined with our increased go-to-market\ninvestments and the expanded breadth of offerings from the leading server\nand solutions providers position us well for continued enterprise share\ngains.\n\n\nLooking ahead, we remain on track to launch our next-generation 2-nanometer\nVenice processors in 2026. Venice silicon is in the labs and performing\nvery well, delivering substantial gains in performance, efficiency and\ncompute density. Customer pull and engagement for Venice are the strongest\nwe have seen reflecting our competitive positioning and the growing demand\nfor more data center compute. Multiple cloud OEM partners have already\nbrought their first Venice platforms online, setting the stage for broad\nsolution availability and cloud deployments at launch.\n\n\nTurning to data center AI. Our Instinct GPU business continues to\naccelerate. Revenue grew year-over-year driven by the sharp ramp of MI350\nSeries GPU sales and broader MI MI300 Series deployments. Multiple MI350\nSeries deployments are underway with large cloud and AI providers, with\nadditional large-scale rollouts on track to ramp over the coming quarters.\n\n\nOracle became the first hyperscaler to publicly offer MI355X instances,\ndelivering significantly higher performance for real-time inference and\nmultimodal training workloads on OCI zettascale supercluster. Neocloud\nproviders Crusoe, DigitalOcean, TensorWave, Vultr and others also began\nramping availability of their MI350 Series public cloud offerings in the\nquarter. MI300 Series GPU deployments with AI developers also broadened in\nthe quarter. IBM and Zyphra will train multiple generations of future\nmultimodal models on a large-scale MI300X cluster. And Cohere is now using\nMI300X at OCI to train its Command family of models. For inference, a\nnumber of new partners, including Character.AI and Luma AI, are now running\nproduction workloads on MI300 Series demonstrating the performance and TCO\nadvantages of our architecture for real-time AI applications.\n\n\nWe also made significant progress on the software front in the quarter. We\nlaunched ROCm 7, our most advanced and feature-rich release to date,\ndelivering up to 4.6x higher inference and 3x higher training performance\ncompared to ROCm 6. ROCm 7 also introduces seamless distributed inference,\nenhanced code portability across hardware and new enterprise tools that\nsimplify the deployment and management of Instinct solutions. Importantly,\nour open software strategy is resonating with developers. Hugging Face,\nvLLM, SGLang and others contributed directly to ROCm 7 as we make ROCm the\nopen platform for AI development at scale.\n\n\nLooking ahead, our data center AI business is entering its next phase of\ngrowth with customer momentum building rapidly ahead of the launch of our\nnext-gen MI400 Series accelerators and Helios rack-scale solutions in 2026.\nThe MI400 Series combines a new compute engine with industry-leading memory\ncapacity and advanced networking capabilities to deliver a major leap in\nperformance for the most demanding AI training and inference workloads. The\nMI400 Series brings together our silicon, software and systems expertise to\npower Helios, our rack-scale AI platform designed to redefine performance\nand efficiency at data center scale.\n\n\nHelios integrates our Instinct MI400 Series GPUs, Venice EPYC CPUs and\nPensando NICs in a double-wide rack solution optimized for the performance,\npower, cooling and serviceability required for the next generation of AI\ninfrastructure and supports Meta's new open rack wide standard. Development\nof both our MI400 Series GPUs and Helios rack is progressing rapidly,\nsupported by deep technical engagements across a growing set of\nhyperscalers, AI companies and OEM and ODM partners to enable large-scale\ndeployments next year.\n\n\nThe ZT Systems team we acquired last year is playing a critical role in\nHelios development, leveraging their decades of experience building\ninfrastructure for the world's largest cloud providers to ensure customers\ncan deploy and scale Helios quickly within their environments. In addition,\nlast week, we completed the sale of the ZT manufacturing business to\nSanmina and entered a strategic partnership that makes them our lead\nmanufacturing partner for Helios. This collaboration will accelerate large\ncustomer deployments of our rack-scale AI solutions.\n\n\nOn the customer front, we announced a comprehensive multiyear agreement\nwith OpenAI to deploy 6 gigawatts of Instinct GPUs with the first gigawatt\nof MI450 Series accelerators scheduled to start coming online in the second\nhalf of 2026. The partnership establishes AMD as a core compute provider\nfor OpenAI and underscores the strength of our hardware, software and full\nstack solution strategy. Moving forward, AMD and OpenAI will work even more\nclosely on future hardware, software, networking and system-level road maps\nand technologies.\n\n\nOpenAI's decision to use AMD Instinct platforms for its most sophisticated\nand complex AI workloads sends a clear signal that our Instinct GPUs and\nROCm open software stack deliver the performance and TCO required for the\nmost demanding deployments. We expect this partnership will significantly\naccelerate our data center AI business with the potential to generate well\nover $100 billion in revenue over the next few years. Oracle announced they\nwill also be a lead launch partner for the MI450 Series, deploying tens of\nthousands of MI450 GPUs across Oracle Cloud Infrastructure beginning in\n2026 and expanding through 2027 and beyond.\n\n\nOur Instinct platforms are also gaining traction with sovereign AI and\nnational supercomputing programs. In the UAE, Cisco and G42 will deploy a\nlarge-scale AI cluster powered by Instinct MI350X GPUs to support the\nnation's most advanced AI workloads. In the U.S., we are partnering with\nthe Department of Energy and Oak Ridge National Labs to build Lux AI, the\nfirst AI factory dedicated to scientific discovery together with our\nindustrial partners, OCI and HPE. Powered by our Instinct MI350 series\nGPUs, EPYC CPUs and Pensando networking, Lux AI will provide a secure open\nplatform for large-scale training and distributed inference when it comes\nonline in early 2026.\n\n\nThe U.S. Department of Energy also selected our upcoming MI430X GPUs and\nEPYC Venice CPUs to power Discovery, the next flagship supercomputer at Oak\nRidge designed to set the standard for AI-driven scientific computing and\nextend U.S. high-performance computing leadership. Our MI430X GPUs are\ndesigned specifically to power nation-scale AI and supercomputing programs,\nextending our leadership, powering the world's most powerful computers to\nenable the next generation of scientific breakthroughs.\n\n\nIn summary, our AI business is entering a new phase of growth and is on a\nclear trajectory towards tens of billions in annual revenue in 2027 driven\nby our leadership rack-scale solutions, expanding customer adoption and an\nincreasing number of large-scale global deployments. I look forward to\nproviding more details on our data center AI growth plans at our Financial\nAnalyst Day next week.\n\n\nIn client and gaming, segment revenue increased 73% year-over-year to $4\nbillion. Our PC processor business is performing exceptionally well with\nrecord quarterly sales as the strong demand environment and breadth of our\nleadership Ryzen portfolio accelerates growth. Desktop CPU sales reached an\nall-time high with record channel sell-in and sell-out led by robust demand\nfor our Ryzen 9000 processors which deliver unmatched performance across\ngaming, productivity and content creation applications. OEM sell-through of\nRyzen-powered notebooks also increased sharply in the quarter reflecting\nsustained end customer pull for premium gaming and commercial AMD PCs.\n\n\nCommercial momentum accelerated in the quarter with Ryzen PC sell-through\nup more than 30% year-over-year as enterprise adoption grew sharply driven\nby large wins with Fortune 500 companies across health care, financial\nservices, manufacturing, automotive and pharmaceuticals. Looking ahead, we\nsee significant opportunity to continue growing our client business faster\nthan the overall PC market based on the strength of our Ryzen portfolio,\nbroader platform coverage and expanded go-to-market investments.\n\n\nIn gaming, revenue increased 181% year-over-year to $1.3 billion. Semi-\ncustom revenue increased as Sony and Microsoft prepare for the upcoming\nholiday sales period. In gaming graphics, revenue and channel sell-out grew\nsignificantly driven by the performance per dollar leadership of our Radeon\n9000 family. FSR 4, our machine learning upscaling technology that boosts\nframe rates and creates more immersive visuals saw rapid adoption this\nquarter with the number of supported games doubling since launch to more\nthan 85.\n\n\nTurning to our embedded segment. Revenue decreased 8% year-over-year to\n$857 million. Sequentially, revenue and sell-through increased as the\ndemand environment strengthened across multiple markets led by test and\nemulation, aerospace and defense, and industrial, vision and health care.\nWe expanded our embedded product portfolio with new solutions that extend\nour leadership across adaptive and x86 computing. We began shipping\nindustry-leading Versal Prime Series Gen 2 adaptive SoCs to lead customers,\ndelivered our first Versal RF development platforms to support several next-\ngeneration design wins and introduced the Ryzen Embedded 9000 Series with\nindustry-leading performance per watt and latency for robotics, edge\ncomputing and smart factory applications.\n\n\nThe design momentum remains very strong across our embedded portfolio. We\nare on track for a second straight year of record design wins already\ntotaling more than $14 billion year-to-date, reflecting the growing\nadoption of our leadership products across a broad range of markets and\nexpanding set of applications. In summary, our record third quarter results\nand strong fourth quarter outlook reflect the significant momentum building\nacross our business driven by sustained product leadership and disciplined\nexecution. Our data center AI, server and PC businesses are each entering\nperiods of strong growth led by an expanding TAM, accelerating adoption of\nour Instinct platforms and EPYC and Ryzen CPU share gains.\n\n\nThe demand for compute has never been greater as every major breakthrough\nin business, science and society now relies on access to more powerful,\nefficient and intelligent computing. These trends are driving unprecedented\ngrowth opportunities for AMD. I look forward to sharing more on our\nstrategy, road maps and long-range financial targets at our financial\nanalyst meeting next week.\n\n\nNow I'll turn the call over to Jean to provide additional color on our\nthird quarter results. Jean?\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of\nour financial results and then provide our outlook for the fourth quarter\nof fiscal 2025. We are pleased with our strong third quarter financial\nresults. We delivered a record revenue of $9.2 billion, up 36% year-over-\nyear, exceeding the high end of our guidance, reflecting strong momentum\nacross our business. Our third quarter results do not include any revenue\nfrom shipments of the MI308 GPU products to China. Revenue increased 20%\nsequentially driven by strong growth in the data center, and client and\ngaming segment and modest growth in the embedded segment.\n\n\nGross margin was 54%, up 40 basis points year-over-year primarily driven by\nproduct mix. Operating expenses were approximately $2.8 billion, an\nincrease of 42% year-over-year as we continue to invest aggressively in R&D\nto capitalize on significant AI opportunities and go-to-market activities\nfor revenue growth. Operating income was $2.2 billion, representing a 24%\noperating margin. Taxes, interest expense and other totaled $273 million.\nFor the third quarter of 2025, diluted earnings per share were $1.20\ncompared to $0.92 a year ago, an increase of 30% year-over-year.\n\n\nNow turning to our reportable segments, starting with data center. Data\ncenter segment revenue was a record of $4.3 billion, up 22% year-over-year\nprimarily driven by the strong demand for 5th Generation EPYC processors\nand Instinct MI350 Series GPUs. On a sequential basis, data center revenue\nincreased 34%, primarily driven by strong ramp of our AMD Instinct MI350\nSeries GPUs. The data center segment operating income was $1.1 billion or\n25% of revenue compared to $1 billion a year ago or 29% of revenue driven\nby higher revenue partially offset by higher R&D investment to capitalize\non significant AI opportunities.\n\n\nClient and gaming segment revenue was a record of $4 billion, up 73% year-\nover-year and 12% sequentially driven by strong demand for the latest\ngeneration of client and graphic processors and stronger sales of console\ngaming products. In the client business, revenue was a record $2.8 billion,\nup 46% year-over-year and 10% sequentially driven by record sales of our\nRyzen processors and a richer product mix. Gaming revenue rose to $1.3\nbillion, up 181% year-over-year and 16% sequentially, reflecting higher\nsemi-custom revenue and strong demand for our Radeon GPUs. Client and\ngaming segment operating income was $867 million or 21% of revenue compared\nto $288 million or 12% a year ago, driven by higher revenue partially\noffset by increase in go-to-market investment to support our revenue\ngrowth.\n\n\nEmbedded segment revenue was $857 million, down 8% year-over-year. Embedded\nwas up 4% sequentially as we saw certain end market demand strengthen.\nEmbedded segment operating income was $283 million or 33% of revenue\ncompared to $372 million or 40% a year ago. The decline in operating income\nwas primarily due to lower revenue and end market mix. Before I review the\nbalance sheet and the cash flow, as a reminder, we closed the sale of ZT\nSystem manufacturing business to Sanmina last week. The third quarter\nfinancial results of the ZT manufacturing business are reported separately\nin our financial statements as discontinued operations and are excluded\nfrom our non-GAAP financials.\n\n\nTurning to the balance sheet and cash flow. During the quarter, we\ngenerated $1.8 billion in cash from operating activities of continuing\noperations, and the free cash flow was a record of $1.5 billion. We\nreturned $89 million to shareholders through share repurchases resulting in\n$1.3 billion in share repurchases for the first 3 quarters of 2025. Exiting\nthe quarter, we have $9.4 billion authorization remaining under our share\nrepurchase program. At the end of the quarter, cash, cash equivalent and\nshort-term investment were $7.2 billion. Our total debt was $3.2 billion.\n\n\nNow turning to our fourth quarter 2025 outlook. Please note that our fourth\nquarter outlook does not include any revenue from AMD Instinct MI308\nshipment to China. For the fourth quarter of 2025, we expect revenue to be\napproximately $9.6 billion, plus or minus $300 million. The midpoint of our\nguidance represents approximately 25% year-over-year revenue growth driven\nby strong double-digit growth in our data center, and client and gaming\nsegment and a return to growth in our embedded segment.\n\n\nSequentially, we expect revenue to grow by approximately 4% driven by\ndouble-digit growth in the data center segment with strong growth in server\nand continued ramp of our MI350 Series GPUs, a decline in our client and\ngaming segment with client revenue increasing and the gaming revenue down\nstrong double digits, and double-digit growth in our embedded segment. In\naddition, we expect fourth quarter non-GAAP gross margin to be\napproximately 54.5%, and we expect non-GAAP operating expenses to be\napproximately $2.8 billion. We expect net interest and other expenses to be\na gain of approximately $37 million. We expect our non-GAAP effective tax\nrate to be 13%, and diluted share count is expected to be approximately\n1.65 billion shares.\n\n\nIn closing, we executed very well, delivering record revenue for the first\n3 quarters of the year. The strategic investment we are making position us\nwell to capitalize on expanding AI opportunities across all our end\nmarkets, driving sustainable long-term revenue growth and earnings\nexpansion for compelling shareholder value creation.\n\n\nWith that, I'll turn it back to Matt for the Q&A session.\n\n\nMatthew D. Ramsay\nVice President of Financial Strategy & Investor RelationsThank you very\nmuch, Jean. John, we can go ahead and poll the audience for questions now.\nThank you.",
  "qa_text": "Operator\n\n[Operator Instructions] And the first question comes from the line of Vivek\nArya with Bank of America Securities.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nI had a near-term and a medium-term question. For the near term, Lisa, I\nwas hoping if you could give us some sense of the CPU, GPU mix in Q3 and\nQ4. And just tactically, how are you managing this transition from your\nMI355 towards MI400 in the second half of next year? Can you continue to\ngrow in the first half of next year from these Q4 levels? Or should we\nexpect some kind of pause or digestion before customers get onboard the\nMI400 Series?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Vivek. Thanks for the question. So couple comments, we had a very\nstrong Q3 for the data center business. I think we saw strong\noutperformance in both the server as well as the data center AI business.\nAnd a reminder that, that was without any MI308 sales. The MI355 has ramped\nreally nicely. We expected a sharp ramp into the third quarter and that\nproceeded well. And as I mentioned, we've also seen some strengthening of\nthe server CPU sales and not just, let's call it, near term, but we're\nseeing our customers are giving us some visibility in the next few quarters\nthat they see elevated demand, which is positive.\n\n\nGoing into the fourth quarter, again, strong data center performance, up\ndouble digits sequentially and up in both server and data center AI, again,\non the strength of those businesses. And to your question, I mean, we're\nnot guiding into 2026 yet obviously, but given what we see today, we see a\nvery good demand environment into 2026. So we would expect that MI355\ncontinue to ramp in the first half of '26 and then, as we mentioned, MI450\nSeries comes online in the second half of 2026, and we would expect a\nsharper ramp as we go into the second half of 2026 of our data center AI\nbusiness.\n\n\nVivek  Arya\nBofA Securities, Research Division\n\nAnd for my follow-up, there is some industry debate, Lisa, about OpenAI's\nability to kind of simultaneously engage with all 3 merchants and the ASIC\nsuppliers, just given the constraints around power and CapEx and their\nexisting kind of CSP partners and so forth. So how are you thinking about\nthat? Like what is your level of visibility in the initial engagement and\nthen more importantly how it kind of broadens out into '27? Is there a way\nthat one can model what the allocation would be? Or just how should we\nthink about the level of visibility in this very important customer?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, absolutely, Vivek. Look, we're very -- obviously, very excited about\nour relationship with OpenAI. It's a very significant relationship. Think\nabout it as it's a pretty unique time for AI right now. There's just so\nmuch compute demand across all of the workloads. I think in our work with\nOpenAI we are planning multiple quarters out, ensuring that the power is\navailable, that the supply chain is available.\n\n\nThe key point is the first gigawatt, we will start deploying in the second\nhalf of '26 and that work is well underway. And we continue -- just given\nwhere lead times are and things like that, we are planning very closely\nwith OpenAI as well as the CSP partners to ensure that we're all prepared\nwith Helios so that we can deploy the technology as we stated. So I think,\noverall, we're working very closely together. I think we have good\nvisibility into the MI450 ramp, and things are progressing very well.\n\n\nOperator\n\nAnd the next question comes from the line of Thomas O'Malley with Barclays.\n\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nCongrats on the good results. I had a first question on Helios. Obviously,\nwith the announcement at OCP, customer interaction has to be growing. Could\nyou talk about into next year what your view is on discrete sales versus\nsystem sales? When do you see that crossover kind of happening? And just\nwhat initial responses have been from customers after getting a better look\nat it at the shelf?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, sure. Tom, thanks for the question. There's a lot of excitement around\nMI450 and Helios. I think the OCP reception was phenomenal. We had numerous\ncustomers and frankly bringing their engineering teams to understand more\nabout the system, more about how it's built. There's always been some\ndiscussion about just how complex these rack-scale systems are, and they\ncertainly are, and we are very proud of the Helios design. I think it has\nall the features, functions, reliability, performance, power performance\nthat you would expect.\n\n\nI think the interest in MI450 and Helios has just expanded over the last\nnumber of weeks, certainly with some of the announcements that we've made\nwith OpenAI and OCI as well as the OCP show with Meta. I think, overall,\nfrom our perspective, I think things are going really well in both the\ndevelopment as well as the customer engagements there. So in terms of rack-\nscale solutions, we would expect that the early customers for MI450 will\nreally be around the rack-scale solutions. We will have other form factors\nas well for the MI450 Series, but there's a lot of interest in the full\nrack-scale solution.\n\n\nThomas James O'Malley\nBarclays Bank PLC, Research Division\n\nSuper helpful. And then as my follow-up, it's a broader question as well\nand similar to kind of what Vivek asked. But if you look at the power\nrequirements that are out there for some of the early announcements into\nnext year, they're pretty substantial. And then you also have component\nissues that you're seeing across interconnected memory. Just from your\nperspective as an industry leader, where do you think that the constraint\nwill be? Will it come first with components not being available? Or do you\nthink that both data center footprint in terms of infrastructure and/or\npower is the gating factor to some of these deployments into next year just\nas we really see some larger number starts get deployed.\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Sure, Tom. I think what you're pointing out is what we, as an\nindustry, have to do together. The entire ecosystem has to plan together\nand that is exactly what we're doing. So we're working with our customers\non their power plans over the next, actually, I would say, 2 years from a\nsilicon and a memory and a packaging and a component supply chain. We're\nworking with our supply chain partners to make sure all of that capacity is\navailable.\n\n\nI can tell you from our visibility, we feel very good that we have a strong\nsupply chain that is prepared to deliver sort of these very significant\ngrowth rates and large amount of compute that is out there. And I think all\nof this is going to be tight. I think there is a -- you can see from some\nof the CapEx spending that there's a desire to put on more compute, and\nwe're working closely together.\n\n\nI will say that the ecosystem is very -- I would say, works very hard when\nthere are these types of, let's call it, tightness out there. And so we\nalso see things open up as we're working, getting more power, getting more\nsupply, all of those things. So the net-net is, I think, we are well\npositioned to grow significantly as we transition into the second half of\n'26 into '27 with the MI450 and Helios.\n\n\nOperator\n\nAnd the next question comes from the line of Joshua Buchalter with TD\nCowen.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nActually, wanted to start on the CPU side. So you and your largest\ncompetitor in that space have talked about near-term strength, supporting\nAI workloads on general purpose servers from agentic. Maybe you could speak\nto the sustainability of these trends. And they called out supply\nconstraints. Are you seeing any of those in your supply chain? And like are\nwe in a period where we should think about the CPU business on the data\ncenter side as being a seasonal or should we expect normal seasonality in\nthe first half of next year?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Josh. A couple comments on the CPU server side. I think we've been\nwatching this trend for the last couple of quarters and we started seeing,\nlet's call it, some positive signs in CPU demand actually a couple quarters\nago. And what's happened as we've gone through 2025 is now we see sort of a\nbroadening of that CPU demand. So we have -- a number of our large\nhyperscale clients are now forecasting significant CPU build into 2026. And\nso from that standpoint, I think it's a positive demand environment, and it\nis because AI is requiring quite a bit of general-purpose compute. And\nthat's great. It catches our cycle as we're ramping Turin. So the Turin\nramp has gone extremely fast, and we see good pull for that product as well\nas consistent strong demand for our Genoa product line as well.\n\n\nSo back to seasonality as we go into 2026, I think we expect that the CPU\ndemand environment into 2026 is going to be, let's call it, positive. And\nso we'll guide more as we get into the end of the year, but I would expect\na positive demand environment for CPUs as we see this demand. I do feel\nlike it's durable. It is not a short-term thing. I think it is a multi-\nquarter phenomenon as we're seeing just much more demand as these AI\nworkloads really turn into -- you have to do real work.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nSo Josh, on the supply side, we have supplies to support our growth and\nespecially in 2026, we're prepared for the ramp.\n\n\nJoshua Louis Buchalter\nTD Cowen, Research Division\n\nGot it. And for my follow-up, Lisa, in your prepared remarks, you\nhighlighted progress you guys have made on ROCm 7. I know this has been an\narea of focus. And can you maybe spend a minute or 2 talking about where\nyou feel you're at competitively with ROCm? How wide is the breadth of\nsupport you're able to offer to the developer community? And what areas do\nyou still have work to do to close any potential competitive gap?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes, Josh, thanks for the question. Look, we've made great progress with\nROCm. ROCm 7 is a significant step forward in terms of performance and sort\nof all the frameworks that we support. It's been really, really important\nfor us to get sort of day zero support of all the newest models and native\nsupport for all the newest frameworks. I would say most customers who are\nstarting with AMD now have a very smooth experience as they're bringing on\ntheir workload to AMD. There's obviously always more work to do.\n\n\nWe're continuing to augment the libraries and the overall environment that\nwe have, especially as we go to some of the newer workloads where you see\ntraining and inference really coming together with reinforcement learning.\nBut overall, I think very strong progress with ROCm. And by the way, we're\ngoing to continue to invest in this area because it's so important to\nreally make our customer development experience as smooth as we can.\n\n\nOperator\n\nAnd the next question comes from the line of C.J. Muse with Cantor\nFitzgerald.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nI guess first question, as you think about the 355 to 400 transition and\nmoving to full rack scale, is there a framework that we should be thinking\nabout for gross margins throughout calendar '26?\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nYes, C.J., thanks for the question. I think in general, as we said in the\npast for our data center GPU business, the gross margin continue to improve\nwhen we ramp a new generation of product. Typically at the beginning of the\nramp you go through a transition period, then you will normalize the gross\nmargin. We're not guiding 2026, but our priority in data center GPU\nbusiness is to really expand the top line revenue growth and the gross\nmargin dollars, and of course, at the same time, we'll continue to drive\nthe gross margin percentage up, too.\n\n\nChristopher James Muse\nCantor Fitzgerald & Co., Research Division\n\nVery helpful. And I guess maybe, Lisa, to kind of probe kind of your growth\nexpectations through '26 and beyond, and you talked about tens of billions\nof dollars in '27, can you kind of speak at a high level how you're\nthinking about OpenAI and other large customers and how we should be\nthinking about the breadth of your customer kind of penetration throughout\ncalendar '26, '27? Any help on that would be super.\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, C.J. And we'll certainly address this topic in more detail at our\nAnalyst Day next week. But let me give you some maybe higher-level points.\nLook, I think we're really excited about our road map. I think we have seen\ngreat traction amongst the largest customers. The OpenAI relationship is\nextremely important to us, and it's great to be able to talk at the multi-\ngigawatt scale because I think that really is what we believe we can\ndeliver to the marketplace.\n\n\nBut there are numerous other customers that we are in deep engagements\nwith. We talked about OCI. We also announced a couple of systems with the\nDepartment of Energy that are significant systems, and we have many other\nengagements. So the way you should think about it is there are multiple\ncustomers that we would expect to have, let's call it, very significant\nscale in the MI450 generation. And that's sort of the breadth of the\ncustomer engagements that we've built, and it's also how we're dimensioning\nthe supply chain to ensure that we can supply certainly our OpenAI\npartnership as well as the numerous other partnerships that are well\nunderway.\n\n\nOperator\n\nAnd the next question comes from the line of Stacy Rasgon with Bernstein\nResearch.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nMy first one, for data center in the quarter, what grew more year-over-year\non a dollar to percentage basis, the servers or the GPUs?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Stacy, I think our commentary was data center grew nicely year-over-\nyear in both of the areas, both for servers as well as data center AI.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nYes. But could you -- I mean, just directionally, did one -- which one grew\nmore than the other? I'm not even asking for numbers, just directionally.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nDirectionally, they are similar, but server is a little bit better.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nServer is a little bit better. Okay. And then on the guidance, so you said\nthat servers -- I mean, data center overall up double digits. You said\nserver is up strong double digits. What does that mean? Is that like more\nthan 20%? Or like how do I think about what you mean by strong double\ndigits? Because, again, I'm trying to -- like I mean, for the GPUs for the\nyear, like do you think you're -- you were saying roughly like $6.5 billion\nor something last quarter for the year, do you think it's still in that\nrange? It kind of feels like you're still there.\n\n\nJean X. Hu\nExecutive VP, CFO, Treasurer & Interim Chief Accounting Officer\n\nStacy, here is what we guided. We guided sequentially data center will be\nup double digits, and we said server will go up strongly. And at the same\ntime, we also said that MI350 also going to ramp. So we did not -- I don't\nthink what you just mentioned was what we guided.\n\n\nStacy Aaron Rasgon\nSanford C. Bernstein & Co., LLC., Research Division\n\nOkay. So I mean if you say servers are up strongly, does that mean they're\nup more than the Instinct because you didn't really make that commentary on\nInstinct?\n\n\nLisa T. Su\nChair, President & CEO\n\nNo. Look, Stacy, let me say it. So data center [ up ] sequentially double-\ndigit percentage, both server and data center AI are going to be up as\nwell. And from the standpoint of where they are, I think we're pleased with\nhow both of them are performing. The strong double-digit percentage comment\nperhaps was applying to the year-over-year commentary.\n\n\nOperator\n\nAnd the next question comes from the line of Timothy Arcuri with UBS.\n\n\nTimothy Michael Arcuri\nUBS Investment Bank, Research Division\n\nLisa, I know it's only been a month since you announced this idea with\nOpenAI, but can you give us maybe some anecdotes of how this has influenced\nyour position in the market with other customers? Like are you engaged with\ncustomers that you wouldn't have been engaged with if you hadn't done this\ndeal? That's the first part of the question. And then the second part\nrelates to a prior question, which is that it looks like they could be\nsomething like half of your data center GPU revenue in the 2027, 2028 time\nframe. So how much risk, in your mind, is there around that single customer\nfor you?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Tim. So let me say a couple things. First of all, the OpenAI deal has\nbeen in the works for quite some time. We're happy to be able to talk about\nit broadly and also talk about the scale of the deployments and the scale\nof the engagement being multiyear, multi-gigawatt. I think all those things\nwere very positive. We've had a number of other engagements as well. I\nthink over the last -- if you were to ask specifically over the last month,\nI would say that it's been a number of factors. I think the OpenAI deal was\none of them.\n\n\nI think having -- being able to show the Helios rack in full force at Open\nCompute was also a very important milestone because people could see the\nengineering and sort of the capabilities of the Helios rack. And if you're\nasking whether we've seen an increase of interest or an acceleration of\ninterest, I think the answer is yes. I think customers are broadly engaged\nand perhaps broadly engaged at higher scale, which is a good thing.\n\n\nAnd then from the standpoint of customer concentration, I think a very key\nfoundation for us in this business is to have a broad set of customers.\nWe've always been engaged with a number of customers. I think we're\ndimensioning the supply chain in such a way that we would have ample supply\nto have multiple customers at similar scale as we go into the '27, '28 time\nframe, and that's certainly the goal.\n\n\nOperator\n\nAnd the next question comes from the line of Aaron Rakers with Wells Fargo.\n\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nI'm curious on the server strength that you're seeing, if there's a way to\nunpack how we think about unit growth versus ASP expansion as we move\nthrough the Turin product cycle. And how do you guys just kind of think\nabout that going forward?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. So Aaron, on the server CPU side, Turin certainly is more content, so\nwe see ASPs grow as Turin ramps. But I also mentioned in the prepared\nremarks that we're actually seeing a very good mix of Genoa still there. So\nTurin is ramping very quickly, but we are also seeing Genoa demand continue\nwell as the hyperscalers are not able to move everything to the latest\ngeneration immediately.\n\n\nSo from our standpoint, I think it's broad-based CPU demand across a number\nof different workloads. This is -- a little bit of this is, let's call it,\nserver refresh, but it seems like from our customer conversations, the\nworkloads are broadly due to the fact that AI workloads are spawning more\ntraditional compute, so more build-out is necessary.\n\n\nI think going forward, one of the things that we see is there is more of a\ndesire for the latest generation. And so as much as we're happy with how\nTurin is ramping, we're seeing actually a strong pull on Venice and a lot\nof early engagement in Venice, which kind of says a lot about kind of the\nimportance of general-purpose compute at this point in time.\n\n\nAaron Christopher Rakers\nWells Fargo Securities, LLC, Research Division\n\nAs a quick follow-up, I'm curious and not to steal maybe the discussion\nfrom next week, but Lisa, you've been very consistent, like $500 billion of\ntotal AI silicon TAM opportunity and obviously progressing above that. I'm\ncurious, as we think about these large megawatt kind of deployments, how\nyou think about the updated views on that AI silicon TAM as we look\nforward.\n\n\nLisa T. Su\nChair, President & CEO\n\nWell, Aaron, as you said, not to take too much away from what we're going\nto talk about next week, look, we're going to give you a full picture of\nhow we see the market next week. But suffice it to say, from everything\nthat we see, we see the AI compute TAM just going up. So we'll have some\nupdated numbers for you, but the view is, whereas $500 billion sounded like\na lot when we first talked about it, we think there is a larger opportunity\nfor us over the next few years, and that's pretty exciting.\n\n\nOperator\n\nThe next question comes from Antoine Chkaiban with New Street Research.\n\n\nAntoine  Chkaiban\nNew Street Research LLP\n\nSo I'd like to ask about whether the developing relationship with OpenAI\ncould be a tailwind to the development of your software stack. Can you\nmaybe tell us about how the collaboration works in practice and whether the\npartnership contributed in making ROCm more robust?\n\n\nLisa T. Su\nChair, President & CEO\n\nYes. Antoine, thanks for the question. I think the answer is yes. I think\nall of our large customers contribute to, let's call it, a broadening and\ndeepening of our software stack overall. I think the relationship with\nOpenAI is certainly one where our plans are to work deeply together on\nhardware as well as software as well as systems and future road map. And\nfrom that standpoint, the work that we're doing together with them on\nTriton is certainly very valuable.\n\n\nBut I will say beyond OpenAI, the work that we do with all of our largest\ncustomers are super helpful to strengthen the software stack. And we have\nput significant new resources into not just the largest customers, but we\nare working with a broad set of AI-native companies who are actively\ndeveloping on the ROCm stack. We get lots of feedback. I think we've made\nsignificant progress in the training and inference stack, and we're going\nto continue to double down and triple down in this area. So more customers\nthat use AMD, I think all of that goes to enhancing the ROCm stack. And\nwe're actually -- we'll talk a little bit more about this next week, but\nwe're also using AI to help us accelerate the rate and pace of some of the\nROCm kernel development and just the overall ecosystem.\n\n\nAntoine  Chkaiban\nNew Street Research LLP\n\nMaybe as a quick follow-up, could you tell us about the useful lives of\nGPUs? I know that most CSPs depreciate them over 5, 6 years. But in your\nconversations with them, I'm just wondering if you see or hear any early\nindication that, in practice, they may be planning to sweat those GPUs for\nlonger than that.\n\n\nLisa T. Su\nChair, President & CEO\n\nI think we have seen some early indications of that, Antoine. I think the\nkey point being, clearly, there's a desire to get on the latest and\ngreatest GPUs when you're building new data center infrastructure. And\ncertainly, when we're looking at MI355s, they're often going into new\nliquid-cooled facilities, MI450 Series as well. But then we're also seeing\nthe other trend, which is there's just a need for more AI compute. And from\nthat standpoint, some of the older generation -- MI300X is still doing\nquite well in terms of just where we see people deploying and using\nespecially for inference. And from that standpoint, I think you see a\nlittle bit of both.\n\n\nOperator\n\nAnd the next question comes from the line of Joe Moore with Morgan Stanley.\n\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nYou mentioned MI308, I guess what's your posture there to the extent that\nif there is some relief that you're able to ship, do you have readiness to\ndo that? Can you give us a sense for how much of a swing factor that could\nbe?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Joe. So look, it's still a pretty dynamic situation with MI308. So\nthat's the reason that we did not include any MI308 revenue in the Q4\nguide. We have received some licenses for MI308, so we're appreciative of\nthe administration supporting some licenses for MI308. We're still working\nwith our customers on the demand environment and sort of what the overall\nopportunity is. And so we'll be able to update that more in the next couple\nof months.\n\n\nJoseph Lawrence Moore\nMorgan Stanley, Research Division\n\nOkay. But you do have product to support that market if it does open up? Or\ndoes -- are you going to have to start to kind of rebuild inventory for\nthat?\n\n\nLisa T. Su\nChair, President & CEO\n\nWe've had some work in process. I think we continue to have that work in\nprocess, but we'll have to see sort of how the demand environment shapes\nup.\n\n\nOperator\n\nAnd the final question comes from the line of Ross Seymore with Deutsche\nBank.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nLisa, this might take longer than the amount of time we have left before\nthe top of the hour, but there's been so many of these multi-gigawatt\nannouncements from OpenAI. How does AMD truly differentiate in there? When\nyou see that big customer signing deals with other GPU vendors and ASIC\nvendors, et cetera, how do you attack that market differently than those\ncompetitors to not only get the 6 gigawatt initially but hopefully more\nafter that?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Ross. Well, look, what I see is actually this environment where the\nworld needs more AI compute. And from that standpoint, I think OpenAI has\nkind of led in the quest for more AI compute, but they're not alone. I\nthink when you look across the large customers, there is really a demand\nfor more AI compute as you go forward over the next couple of years. I\nthink we each have our advantages in terms of how we are positioning our\nproducts. I think MI450 Series, in particular, I think, is an extremely\nstrong product, rack-scale solution. Overall, when we look at compute\nperformance, when we look at memory performance, we think it's extremely\nwell positioned for both inference as well as training.\n\n\nI think the key here is time to market, it's total cost of ownership, it's\ndeep partnership and thinking about not just MI450 Series, but what happens\nafter that. So we're deep in conversations on MI500 and beyond. And we\ncertainly think we're well positioned to not only participate but\nparticipate in a very meaningful way across the sort of the demand\nenvironment here. And I think we have certainly learned a ton over the last\ncouple of years with our AI road map. We've made significant inroads in\nterms of just what the largest customer needs from a workload standpoint.\nSo I'm pretty optimistic about our ability to capture a significant piece\nof this market going forward.\n\n\nRoss Clark Seymore\nDeutsche Bank AG, Research Division\n\nGreat. And I guess as my follow-up, it'll be a direct follow-on to that.\nYou did a unique structure by granting some warrants with this deal, and I\nknow they're -- they vest according to a price that would be very accretive\nand make everybody happy. Do you think that was a relatively unique\nagreement or given that the world needs more processing power that AMD is\nopen to somewhat similar, conceptually similar creative ways to address\nthat demand over time with other equity vehicles, et cetera?\n\n\nLisa T. Su\nChair, President & CEO\n\nSure, Ross. So I would say it was a unique agreement from the standpoint\nthat unique time in AI, what we wanted, what we prioritized was really deep\npartnership and multiyear, multigeneration, significant scale. And I think\nwe got that. We got a structure that has extremely aligned incentives.\nEverybody wins, right? We win. OpenAI wins, and our shareholder win -- sort\nof benefits from this. And all of that accrues to the overall road map.\n\n\nI think as we look forward, I think we have a lot of very interesting\npartnerships that are developing, whether they're with the largest AI users\nor you think about sovereign AI opportunities. And we look at each one of\nthese as a unique opportunity where we're bringing sort of the whole of\nAMD, both technically as well as all the rest of our capabilities to the\nparty. So I would say OpenAI was pretty unique, but I would imagine that\nthere are lots of other opportunities for us to bring our capabilities into\nthe ecosystem and participate in a significant way.\n\n\nOperatorLadies and gentlemen, that does conclude the question-and-answer\nsession and that also concludes today's teleconference. We thank you for\nyour participation. You may disconnect your lines at this time.\nCopyright  2025 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2025 S&P Global Market Intelligence.",
  "has_qa": 1,
  "speaker_turns": [
    {
      "speaker": "Unknown",
      "role": "",
      "text": "Advanced Micro Devices, Inc. NasdaqGS:AMD FQ3 2025 Earnings Call Transcripts Tuesday, November 4, 2025 10:00 PM GMT S&P Global Market Intelligence Estimates Presentation"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "Greetings, and welcome to the AMD Third Quarter 2025 Conference Call. [Operator Instructions] As a reminder, this conference call is being recorded. It is now my pleasure to introduce to you Matt Ramsay, VP, Financial Strategy and Investor Relations. Thank you, Matt. You may begin."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor Relations",
      "text": "Vice President of Financial Strategy & Investor Relations Thank you, and welcome to AMD's Third Quarter 2025 Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the opportunity to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations are available in today's press release and the slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and CEO; and Jean Hu, our Executive Vice President, CFO and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin the call, I would like to note that Dr. Lisa Su, along with members of AMD's executive team, will present our long-term financial strategy at our Financial Analyst Day next Tuesday, November 11 in New York. Dr. Lisa Su will present at the UBS Global Technology and AI Conference on Wednesday, December 3. And finally, Jean Hu will present at the 23rd Annual Barclays Global Technology Conference on Wednesday, December 10. Today's discussion contains forward-looking statements based on our current beliefs, assumptions and expectations, speak only as of today and as such involve risks and uncertainties that could cause results to deliver -- to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on these factors that could cause actual results to differ materially. And with that, I will hand the call over to Lisa."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Thank you, Matt, and good afternoon to all those listening today. We delivered an outstanding quarter with record revenue and profitability, reflecting broad-based demand across our data center AI, server and PC businesses. Revenue grew 36% year-over-year to $9.2 billion. Net income rose 31%, and free cash flow more than tripled led by record EPYC, Ryzen and Instinct processor sales. Our record third quarter performance marks a clear step-up in our growth trajectory as the combination of our expanding compute franchise and rapidly scaling data center AI business drives significant revenue and earnings growth. Turning to our segments. Data center segment revenue increased 22% year- over-year to a record $4.3 billion led by the ramp of our Instinct MI350 Series GPUs and server share gains. Server CPU revenue reached an all-time high as adoption of 5th Gen EPYC Turin processors accelerated rapidly, accounting for nearly half of overall EPYC revenue in the quarter. Sales of our prior generation EPYC processors were also very robust in the quarter reflecting their strong competitive positioning across a wide range of workloads. In cloud, we had record sales as hyperscalers expanded EPYC CPU deployments to power both their own first-party services and public cloud offerings. Hyperscalers launched more than 160 EPYC-powered instances in the quarter, including new Turin offerings from Google, Microsoft Azure, Alibaba and others that deliver unmatched performance and price performance across a wide range of workloads. There are now more than 1,350 public EPYC cloud instances available globally, a nearly 50% increase from a year ago. Adoption of EPYC in the cloud by large businesses more than tripled year- over-year as our on-prem share gains are driving increased demand from enterprise customers for AMD cloud instances to support hybrid compute. We expect cloud demand to remain very strong as hyperscalers are significantly increasing their general-purpose compute capacity as they scale their AI workloads. Many customers are now planning substantially larger CPU build- outs over the coming quarters to support increased demands from AI serving as a powerful new catalyst for our server business. Turning to enterprise adoption. EPYC server sell-through increased sharply year-over-year and sequentially reflecting accelerating enterprise adoption. More than 170 5th Gen EPYC platforms are in market from HPE, Dell, Lenovo, Super Micro and others, our broadest portfolio to date with solutions optimized for virtually every enterprise workload. We closed large new wins in the quarter with leading Fortune 500 technology, telecom, financial services, retail, streaming, social and automotive companies as we expand our footprint across major verticals. The performance and TCO advantages of our EPYC portfolio combined with our increased go-to-market investments and the expanded breadth of offerings from the leading server and solutions providers position us well for continued enterprise share gains. Looking ahead, we remain on track to launch our next-generation 2-nanometer Venice processors in 2026. Venice silicon is in the labs and performing very well, delivering substantial gains in performance, efficiency and compute density. Customer pull and engagement for Venice are the strongest we have seen reflecting our competitive positioning and the growing demand for more data center compute. Multiple cloud OEM partners have already brought their first Venice platforms online, setting the stage for broad solution availability and cloud deployments at launch. Turning to data center AI. Our Instinct GPU business continues to accelerate. Revenue grew year-over-year driven by the sharp ramp of MI350 Series GPU sales and broader MI MI300 Series deployments. Multiple MI350 Series deployments are underway with large cloud and AI providers, with additional large-scale rollouts on track to ramp over the coming quarters. Oracle became the first hyperscaler to publicly offer MI355X instances, delivering significantly higher performance for real-time inference and multimodal training workloads on OCI zettascale supercluster. Neocloud providers Crusoe, DigitalOcean, TensorWave, Vultr and others also began ramping availability of their MI350 Series public cloud offerings in the quarter. MI300 Series GPU deployments with AI developers also broadened in the quarter. IBM and Zyphra will train multiple generations of future multimodal models on a large-scale MI300X cluster. And Cohere is now using MI300X at OCI to train its Command family of models. For inference, a number of new partners, including Character.AI and Luma AI, are now running production workloads on MI300 Series demonstrating the performance and TCO advantages of our architecture for real-time AI applications. We also made significant progress on the software front in the quarter. We launched ROCm 7, our most advanced and feature-rich release to date, delivering up to 4.6x higher inference and 3x higher training performance compared to ROCm 6. ROCm 7 also introduces seamless distributed inference, enhanced code portability across hardware and new enterprise tools that simplify the deployment and management of Instinct solutions. Importantly, our open software strategy is resonating with developers. Hugging Face, vLLM, SGLang and others contributed directly to ROCm 7 as we make ROCm the open platform for AI development at scale. Looking ahead, our data center AI business is entering its next phase of growth with customer momentum building rapidly ahead of the launch of our next-gen MI400 Series accelerators and Helios rack-scale solutions in 2026. The MI400 Series combines a new compute engine with industry-leading memory capacity and advanced networking capabilities to deliver a major leap in performance for the most demanding AI training and inference workloads. The MI400 Series brings together our silicon, software and systems expertise to power Helios, our rack-scale AI platform designed to redefine performance and efficiency at data center scale. Helios integrates our Instinct MI400 Series GPUs, Venice EPYC CPUs and Pensando NICs in a double-wide rack solution optimized for the performance, power, cooling and serviceability required for the next generation of AI infrastructure and supports Meta's new open rack wide standard. Development of both our MI400 Series GPUs and Helios rack is progressing rapidly, supported by deep technical engagements across a growing set of hyperscalers, AI companies and OEM and ODM partners to enable large-scale deployments next year. The ZT Systems team we acquired last year is playing a critical role in Helios development, leveraging their decades of experience building infrastructure for the world's largest cloud providers to ensure customers can deploy and scale Helios quickly within their environments. In addition, last week, we completed the sale of the ZT manufacturing business to Sanmina and entered a strategic partnership that makes them our lead manufacturing partner for Helios. This collaboration will accelerate large customer deployments of our rack-scale AI solutions. On the customer front, we announced a comprehensive multiyear agreement with OpenAI to deploy 6 gigawatts of Instinct GPUs with the first gigawatt of MI450 Series accelerators scheduled to start coming online in the second half of 2026. The partnership establishes AMD as a core compute provider for OpenAI and underscores the strength of our hardware, software and full stack solution strategy. Moving forward, AMD and OpenAI will work even more closely on future hardware, software, networking and system-level road maps and technologies. OpenAI's decision to use AMD Instinct platforms for its most sophisticated and complex AI workloads sends a clear signal that our Instinct GPUs and ROCm open software stack deliver the performance and TCO required for the most demanding deployments. We expect this partnership will significantly accelerate our data center AI business with the potential to generate well over $100 billion in revenue over the next few years. Oracle announced they will also be a lead launch partner for the MI450 Series, deploying tens of thousands of MI450 GPUs across Oracle Cloud Infrastructure beginning in 2026 and expanding through 2027 and beyond. Our Instinct platforms are also gaining traction with sovereign AI and national supercomputing programs. In the UAE, Cisco and G42 will deploy a large-scale AI cluster powered by Instinct MI350X GPUs to support the nation's most advanced AI workloads. In the U.S., we are partnering with the Department of Energy and Oak Ridge National Labs to build Lux AI, the first AI factory dedicated to scientific discovery together with our industrial partners, OCI and HPE. Powered by our Instinct MI350 series GPUs, EPYC CPUs and Pensando networking, Lux AI will provide a secure open platform for large-scale training and distributed inference when it comes online in early 2026. The U.S. Department of Energy also selected our upcoming MI430X GPUs and EPYC Venice CPUs to power Discovery, the next flagship supercomputer at Oak Ridge designed to set the standard for AI-driven scientific computing and extend U.S. high-performance computing leadership. Our MI430X GPUs are designed specifically to power nation-scale AI and supercomputing programs, extending our leadership, powering the world's most powerful computers to enable the next generation of scientific breakthroughs. In summary, our AI business is entering a new phase of growth and is on a clear trajectory towards tens of billions in annual revenue in 2027 driven by our leadership rack-scale solutions, expanding customer adoption and an increasing number of large-scale global deployments. I look forward to providing more details on our data center AI growth plans at our Financial Analyst Day next week. In client and gaming, segment revenue increased 73% year-over-year to $4 billion. Our PC processor business is performing exceptionally well with record quarterly sales as the strong demand environment and breadth of our leadership Ryzen portfolio accelerates growth. Desktop CPU sales reached an all-time high with record channel sell-in and sell-out led by robust demand for our Ryzen 9000 processors which deliver unmatched performance across gaming, productivity and content creation applications. OEM sell-through of Ryzen-powered notebooks also increased sharply in the quarter reflecting sustained end customer pull for premium gaming and commercial AMD PCs. Commercial momentum accelerated in the quarter with Ryzen PC sell-through up more than 30% year-over-year as enterprise adoption grew sharply driven by large wins with Fortune 500 companies across health care, financial services, manufacturing, automotive and pharmaceuticals. Looking ahead, we see significant opportunity to continue growing our client business faster than the overall PC market based on the strength of our Ryzen portfolio, broader platform coverage and expanded go-to-market investments. In gaming, revenue increased 181% year-over-year to $1.3 billion. Semi- custom revenue increased as Sony and Microsoft prepare for the upcoming holiday sales period. In gaming graphics, revenue and channel sell-out grew significantly driven by the performance per dollar leadership of our Radeon 9000 family. FSR 4, our machine learning upscaling technology that boosts frame rates and creates more immersive visuals saw rapid adoption this quarter with the number of supported games doubling since launch to more than 85. Turning to our embedded segment. Revenue decreased 8% year-over-year to $857 million. Sequentially, revenue and sell-through increased as the demand environment strengthened across multiple markets led by test and emulation, aerospace and defense, and industrial, vision and health care. We expanded our embedded product portfolio with new solutions that extend our leadership across adaptive and x86 computing. We began shipping industry-leading Versal Prime Series Gen 2 adaptive SoCs to lead customers, delivered our first Versal RF development platforms to support several next- generation design wins and introduced the Ryzen Embedded 9000 Series with industry-leading performance per watt and latency for robotics, edge computing and smart factory applications. The design momentum remains very strong across our embedded portfolio. We are on track for a second straight year of record design wins already totaling more than $14 billion year-to-date, reflecting the growing adoption of our leadership products across a broad range of markets and expanding set of applications. In summary, our record third quarter results and strong fourth quarter outlook reflect the significant momentum building across our business driven by sustained product leadership and disciplined execution. Our data center AI, server and PC businesses are each entering periods of strong growth led by an expanding TAM, accelerating adoption of our Instinct platforms and EPYC and Ryzen CPU share gains. The demand for compute has never been greater as every major breakthrough in business, science and society now relies on access to more powerful, efficient and intelligent computing. These trends are driving unprecedented growth opportunities for AMD. I look forward to sharing more on our strategy, road maps and long-range financial targets at our financial analyst meeting next week. Now I'll turn the call over to Jean to provide additional color on our third quarter results. Jean?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer",
      "text": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our outlook for the fourth quarter of fiscal 2025. We are pleased with our strong third quarter financial results. We delivered a record revenue of $9.2 billion, up 36% year-over- year, exceeding the high end of our guidance, reflecting strong momentum across our business. Our third quarter results do not include any revenue from shipments of the MI308 GPU products to China. Revenue increased 20% sequentially driven by strong growth in the data center, and client and gaming segment and modest growth in the embedded segment. Gross margin was 54%, up 40 basis points year-over-year primarily driven by product mix. Operating expenses were approximately $2.8 billion, an increase of 42% year-over-year as we continue to invest aggressively in R&D to capitalize on significant AI opportunities and go-to-market activities for revenue growth. Operating income was $2.2 billion, representing a 24% operating margin. Taxes, interest expense and other totaled $273 million. For the third quarter of 2025, diluted earnings per share were $1.20 compared to $0.92 a year ago, an increase of 30% year-over-year. Now turning to our reportable segments, starting with data center. Data center segment revenue was a record of $4.3 billion, up 22% year-over-year primarily driven by the strong demand for 5th Generation EPYC processors and Instinct MI350 Series GPUs. On a sequential basis, data center revenue increased 34%, primarily driven by strong ramp of our AMD Instinct MI350 Series GPUs. The data center segment operating income was $1.1 billion or 25% of revenue compared to $1 billion a year ago or 29% of revenue driven by higher revenue partially offset by higher R&D investment to capitalize on significant AI opportunities. Client and gaming segment revenue was a record of $4 billion, up 73% year- over-year and 12% sequentially driven by strong demand for the latest generation of client and graphic processors and stronger sales of console gaming products. In the client business, revenue was a record $2.8 billion, up 46% year-over-year and 10% sequentially driven by record sales of our Ryzen processors and a richer product mix. Gaming revenue rose to $1.3 billion, up 181% year-over-year and 16% sequentially, reflecting higher semi-custom revenue and strong demand for our Radeon GPUs. Client and gaming segment operating income was $867 million or 21% of revenue compared to $288 million or 12% a year ago, driven by higher revenue partially offset by increase in go-to-market investment to support our revenue growth. Embedded segment revenue was $857 million, down 8% year-over-year. Embedded was up 4% sequentially as we saw certain end market demand strengthen. Embedded segment operating income was $283 million or 33% of revenue compared to $372 million or 40% a year ago. The decline in operating income was primarily due to lower revenue and end market mix. Before I review the balance sheet and the cash flow, as a reminder, we closed the sale of ZT System manufacturing business to Sanmina last week. The third quarter financial results of the ZT manufacturing business are reported separately in our financial statements as discontinued operations and are excluded from our non-GAAP financials. Turning to the balance sheet and cash flow. During the quarter, we generated $1.8 billion in cash from operating activities of continuing operations, and the free cash flow was a record of $1.5 billion. We returned $89 million to shareholders through share repurchases resulting in $1.3 billion in share repurchases for the first 3 quarters of 2025. Exiting the quarter, we have $9.4 billion authorization remaining under our share repurchase program. At the end of the quarter, cash, cash equivalent and short-term investment were $7.2 billion. Our total debt was $3.2 billion. Now turning to our fourth quarter 2025 outlook. Please note that our fourth quarter outlook does not include any revenue from AMD Instinct MI308 shipment to China. For the fourth quarter of 2025, we expect revenue to be approximately $9.6 billion, plus or minus $300 million. The midpoint of our guidance represents approximately 25% year-over-year revenue growth driven by strong double-digit growth in our data center, and client and gaming segment and a return to growth in our embedded segment. Sequentially, we expect revenue to grow by approximately 4% driven by double-digit growth in the data center segment with strong growth in server and continued ramp of our MI350 Series GPUs, a decline in our client and gaming segment with client revenue increasing and the gaming revenue down strong double digits, and double-digit growth in our embedded segment. In addition, we expect fourth quarter non-GAAP gross margin to be approximately 54.5%, and we expect non-GAAP operating expenses to be approximately $2.8 billion. We expect net interest and other expenses to be a gain of approximately $37 million. We expect our non-GAAP effective tax rate to be 13%, and diluted share count is expected to be approximately 1.65 billion shares. In closing, we executed very well, delivering record revenue for the first 3 quarters of the year. The strategic investment we are making position us well to capitalize on expanding AI opportunities across all our end markets, driving sustainable long-term revenue growth and earnings expansion for compelling shareholder value creation. With that, I'll turn it back to Matt for the Q&A session."
    },
    {
      "speaker": "Matthew D. Ramsay",
      "role": "Vice President of Financial Strategy & Investor RelationsThank you very",
      "text": "Vice President of Financial Strategy & Investor RelationsThank you very much, Jean. John, we can go ahead and poll the audience for questions now. Thank you. Question and Answer"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "[Operator Instructions] And the first question comes from the line of Vivek Arya with Bank of America Securities."
    },
    {
      "speaker": "Vivek  Arya",
      "role": "BofA Securities, Research Division",
      "text": "BofA Securities, Research Division I had a near-term and a medium-term question. For the near term, Lisa, I was hoping if you could give us some sense of the CPU, GPU mix in Q3 and Q4. And just tactically, how are you managing this transition from your MI355 towards MI400 in the second half of next year? Can you continue to grow in the first half of next year from these Q4 levels? Or should we expect some kind of pause or digestion before customers get onboard the MI400 Series?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Vivek. Thanks for the question. So couple comments, we had a very strong Q3 for the data center business. I think we saw strong outperformance in both the server as well as the data center AI business. And a reminder that, that was without any MI308 sales. The MI355 has ramped really nicely. We expected a sharp ramp into the third quarter and that proceeded well. And as I mentioned, we've also seen some strengthening of the server CPU sales and not just, let's call it, near term, but we're seeing our customers are giving us some visibility in the next few quarters that they see elevated demand, which is positive. Going into the fourth quarter, again, strong data center performance, up double digits sequentially and up in both server and data center AI, again, on the strength of those businesses. And to your question, I mean, we're not guiding into 2026 yet obviously, but given what we see today, we see a very good demand environment into 2026. So we would expect that MI355 continue to ramp in the first half of '26 and then, as we mentioned, MI450 Series comes online in the second half of 2026, and we would expect a sharper ramp as we go into the second half of 2026 of our data center AI business."
    },
    {
      "speaker": "Vivek  Arya",
      "role": "BofA Securities, Research Division",
      "text": "BofA Securities, Research Division And for my follow-up, there is some industry debate, Lisa, about OpenAI's ability to kind of simultaneously engage with all 3 merchants and the ASIC suppliers, just given the constraints around power and CapEx and their existing kind of CSP partners and so forth. So how are you thinking about that? Like what is your level of visibility in the initial engagement and then more importantly how it kind of broadens out into '27? Is there a way that one can model what the allocation would be? Or just how should we think about the level of visibility in this very important customer?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes, absolutely, Vivek. Look, we're very -- obviously, very excited about our relationship with OpenAI. It's a very significant relationship. Think about it as it's a pretty unique time for AI right now. There's just so much compute demand across all of the workloads. I think in our work with OpenAI we are planning multiple quarters out, ensuring that the power is available, that the supply chain is available. The key point is the first gigawatt, we will start deploying in the second half of '26 and that work is well underway. And we continue -- just given where lead times are and things like that, we are planning very closely with OpenAI as well as the CSP partners to ensure that we're all prepared with Helios so that we can deploy the technology as we stated. So I think, overall, we're working very closely together. I think we have good visibility into the MI450 ramp, and things are progressing very well."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Thomas O'Malley with Barclays."
    },
    {
      "speaker": "Thomas James O'Malley",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division Congrats on the good results. I had a first question on Helios. Obviously, with the announcement at OCP, customer interaction has to be growing. Could you talk about into next year what your view is on discrete sales versus system sales? When do you see that crossover kind of happening? And just what initial responses have been from customers after getting a better look at it at the shelf?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes, sure. Tom, thanks for the question. There's a lot of excitement around MI450 and Helios. I think the OCP reception was phenomenal. We had numerous customers and frankly bringing their engineering teams to understand more about the system, more about how it's built. There's always been some discussion about just how complex these rack-scale systems are, and they certainly are, and we are very proud of the Helios design. I think it has all the features, functions, reliability, performance, power performance that you would expect. I think the interest in MI450 and Helios has just expanded over the last number of weeks, certainly with some of the announcements that we've made with OpenAI and OCI as well as the OCP show with Meta. I think, overall, from our perspective, I think things are going really well in both the development as well as the customer engagements there. So in terms of rack- scale solutions, we would expect that the early customers for MI450 will really be around the rack-scale solutions. We will have other form factors as well for the MI450 Series, but there's a lot of interest in the full rack-scale solution."
    },
    {
      "speaker": "Thomas James O'Malley",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division Super helpful. And then as my follow-up, it's a broader question as well and similar to kind of what Vivek asked. But if you look at the power requirements that are out there for some of the early announcements into next year, they're pretty substantial. And then you also have component issues that you're seeing across interconnected memory. Just from your perspective as an industry leader, where do you think that the constraint will be? Will it come first with components not being available? Or do you think that both data center footprint in terms of infrastructure and/or power is the gating factor to some of these deployments into next year just as we really see some larger number starts get deployed."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Sure, Tom. I think what you're pointing out is what we, as an industry, have to do together. The entire ecosystem has to plan together and that is exactly what we're doing. So we're working with our customers on their power plans over the next, actually, I would say, 2 years from a silicon and a memory and a packaging and a component supply chain. We're working with our supply chain partners to make sure all of that capacity is available. I can tell you from our visibility, we feel very good that we have a strong supply chain that is prepared to deliver sort of these very significant growth rates and large amount of compute that is out there. And I think all of this is going to be tight. I think there is a -- you can see from some of the CapEx spending that there's a desire to put on more compute, and we're working closely together. I will say that the ecosystem is very -- I would say, works very hard when there are these types of, let's call it, tightness out there. And so we also see things open up as we're working, getting more power, getting more supply, all of those things. So the net-net is, I think, we are well positioned to grow significantly as we transition into the second half of '26 into '27 with the MI450 and Helios."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Joshua Buchalter with TD Cowen."
    },
    {
      "speaker": "Joshua Louis Buchalter",
      "role": "TD Cowen, Research Division",
      "text": "TD Cowen, Research Division Actually, wanted to start on the CPU side. So you and your largest competitor in that space have talked about near-term strength, supporting AI workloads on general purpose servers from agentic. Maybe you could speak to the sustainability of these trends. And they called out supply constraints. Are you seeing any of those in your supply chain? And like are we in a period where we should think about the CPU business on the data center side as being a seasonal or should we expect normal seasonality in the first half of next year?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Josh. A couple comments on the CPU server side. I think we've been watching this trend for the last couple of quarters and we started seeing, let's call it, some positive signs in CPU demand actually a couple quarters ago. And what's happened as we've gone through 2025 is now we see sort of a broadening of that CPU demand. So we have -- a number of our large hyperscale clients are now forecasting significant CPU build into 2026. And so from that standpoint, I think it's a positive demand environment, and it is because AI is requiring quite a bit of general-purpose compute. And that's great. It catches our cycle as we're ramping Turin. So the Turin ramp has gone extremely fast, and we see good pull for that product as well as consistent strong demand for our Genoa product line as well. So back to seasonality as we go into 2026, I think we expect that the CPU demand environment into 2026 is going to be, let's call it, positive. And so we'll guide more as we get into the end of the year, but I would expect a positive demand environment for CPUs as we see this demand. I do feel like it's durable. It is not a short-term thing. I think it is a multi- quarter phenomenon as we're seeing just much more demand as these AI workloads really turn into -- you have to do real work."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer",
      "text": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer So Josh, on the supply side, we have supplies to support our growth and especially in 2026, we're prepared for the ramp."
    },
    {
      "speaker": "Joshua Louis Buchalter",
      "role": "TD Cowen, Research Division",
      "text": "TD Cowen, Research Division Got it. And for my follow-up, Lisa, in your prepared remarks, you highlighted progress you guys have made on ROCm 7. I know this has been an area of focus. And can you maybe spend a minute or 2 talking about where you feel you're at competitively with ROCm? How wide is the breadth of support you're able to offer to the developer community? And what areas do you still have work to do to close any potential competitive gap?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes, Josh, thanks for the question. Look, we've made great progress with ROCm. ROCm 7 is a significant step forward in terms of performance and sort of all the frameworks that we support. It's been really, really important for us to get sort of day zero support of all the newest models and native support for all the newest frameworks. I would say most customers who are starting with AMD now have a very smooth experience as they're bringing on their workload to AMD. There's obviously always more work to do. We're continuing to augment the libraries and the overall environment that we have, especially as we go to some of the newer workloads where you see training and inference really coming together with reinforcement learning. But overall, I think very strong progress with ROCm. And by the way, we're going to continue to invest in this area because it's so important to really make our customer development experience as smooth as we can."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of C.J. Muse with Cantor Fitzgerald."
    },
    {
      "speaker": "Christopher James Muse",
      "role": "Cantor Fitzgerald & Co., Research Division",
      "text": "Cantor Fitzgerald & Co., Research Division I guess first question, as you think about the 355 to 400 transition and moving to full rack scale, is there a framework that we should be thinking about for gross margins throughout calendar '26?"
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer",
      "text": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer Yes, C.J., thanks for the question. I think in general, as we said in the past for our data center GPU business, the gross margin continue to improve when we ramp a new generation of product. Typically at the beginning of the ramp you go through a transition period, then you will normalize the gross margin. We're not guiding 2026, but our priority in data center GPU business is to really expand the top line revenue growth and the gross margin dollars, and of course, at the same time, we'll continue to drive the gross margin percentage up, too."
    },
    {
      "speaker": "Christopher James Muse",
      "role": "Cantor Fitzgerald & Co., Research Division",
      "text": "Cantor Fitzgerald & Co., Research Division Very helpful. And I guess maybe, Lisa, to kind of probe kind of your growth expectations through '26 and beyond, and you talked about tens of billions of dollars in '27, can you kind of speak at a high level how you're thinking about OpenAI and other large customers and how we should be thinking about the breadth of your customer kind of penetration throughout calendar '26, '27? Any help on that would be super."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, C.J. And we'll certainly address this topic in more detail at our Analyst Day next week. But let me give you some maybe higher-level points. Look, I think we're really excited about our road map. I think we have seen great traction amongst the largest customers. The OpenAI relationship is extremely important to us, and it's great to be able to talk at the multi- gigawatt scale because I think that really is what we believe we can deliver to the marketplace. But there are numerous other customers that we are in deep engagements with. We talked about OCI. We also announced a couple of systems with the Department of Energy that are significant systems, and we have many other engagements. So the way you should think about it is there are multiple customers that we would expect to have, let's call it, very significant scale in the MI450 generation. And that's sort of the breadth of the customer engagements that we've built, and it's also how we're dimensioning the supply chain to ensure that we can supply certainly our OpenAI partnership as well as the numerous other partnerships that are well underway."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Stacy Rasgon with Bernstein Research."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division My first one, for data center in the quarter, what grew more year-over-year on a dollar to percentage basis, the servers or the GPUs?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Stacy, I think our commentary was data center grew nicely year-over- year in both of the areas, both for servers as well as data center AI."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division Yes. But could you -- I mean, just directionally, did one -- which one grew more than the other? I'm not even asking for numbers, just directionally."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer",
      "text": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer Directionally, they are similar, but server is a little bit better."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division Server is a little bit better. Okay. And then on the guidance, so you said that servers -- I mean, data center overall up double digits. You said server is up strong double digits. What does that mean? Is that like more than 20%? Or like how do I think about what you mean by strong double digits? Because, again, I'm trying to -- like I mean, for the GPUs for the year, like do you think you're -- you were saying roughly like $6.5 billion or something last quarter for the year, do you think it's still in that range? It kind of feels like you're still there."
    },
    {
      "speaker": "Jean X. Hu",
      "role": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer",
      "text": "Executive VP, CFO, Treasurer & Interim Chief Accounting Officer Stacy, here is what we guided. We guided sequentially data center will be up double digits, and we said server will go up strongly. And at the same time, we also said that MI350 also going to ramp. So we did not -- I don't think what you just mentioned was what we guided."
    },
    {
      "speaker": "Stacy Aaron Rasgon",
      "role": "Sanford C. Bernstein & Co., LLC., Research Division",
      "text": "Sanford C. Bernstein & Co., LLC., Research Division Okay. So I mean if you say servers are up strongly, does that mean they're up more than the Instinct because you didn't really make that commentary on Instinct?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO No. Look, Stacy, let me say it. So data center [ up ] sequentially double- digit percentage, both server and data center AI are going to be up as well. And from the standpoint of where they are, I think we're pleased with how both of them are performing. The strong double-digit percentage comment perhaps was applying to the year-over-year commentary."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Timothy Arcuri with UBS."
    },
    {
      "speaker": "Timothy Michael Arcuri",
      "role": "UBS Investment Bank, Research Division",
      "text": "UBS Investment Bank, Research Division Lisa, I know it's only been a month since you announced this idea with OpenAI, but can you give us maybe some anecdotes of how this has influenced your position in the market with other customers? Like are you engaged with customers that you wouldn't have been engaged with if you hadn't done this deal? That's the first part of the question. And then the second part relates to a prior question, which is that it looks like they could be something like half of your data center GPU revenue in the 2027, 2028 time frame. So how much risk, in your mind, is there around that single customer for you?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Tim. So let me say a couple things. First of all, the OpenAI deal has been in the works for quite some time. We're happy to be able to talk about it broadly and also talk about the scale of the deployments and the scale of the engagement being multiyear, multi-gigawatt. I think all those things were very positive. We've had a number of other engagements as well. I think over the last -- if you were to ask specifically over the last month, I would say that it's been a number of factors. I think the OpenAI deal was one of them. I think having -- being able to show the Helios rack in full force at Open Compute was also a very important milestone because people could see the engineering and sort of the capabilities of the Helios rack. And if you're asking whether we've seen an increase of interest or an acceleration of interest, I think the answer is yes. I think customers are broadly engaged and perhaps broadly engaged at higher scale, which is a good thing. And then from the standpoint of customer concentration, I think a very key foundation for us in this business is to have a broad set of customers. We've always been engaged with a number of customers. I think we're dimensioning the supply chain in such a way that we would have ample supply to have multiple customers at similar scale as we go into the '27, '28 time frame, and that's certainly the goal."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Aaron Rakers with Wells Fargo."
    },
    {
      "speaker": "Aaron Christopher Rakers",
      "role": "Wells Fargo Securities, LLC, Research Division",
      "text": "Wells Fargo Securities, LLC, Research Division I'm curious on the server strength that you're seeing, if there's a way to unpack how we think about unit growth versus ASP expansion as we move through the Turin product cycle. And how do you guys just kind of think about that going forward?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. So Aaron, on the server CPU side, Turin certainly is more content, so we see ASPs grow as Turin ramps. But I also mentioned in the prepared remarks that we're actually seeing a very good mix of Genoa still there. So Turin is ramping very quickly, but we are also seeing Genoa demand continue well as the hyperscalers are not able to move everything to the latest generation immediately. So from our standpoint, I think it's broad-based CPU demand across a number of different workloads. This is -- a little bit of this is, let's call it, server refresh, but it seems like from our customer conversations, the workloads are broadly due to the fact that AI workloads are spawning more traditional compute, so more build-out is necessary. I think going forward, one of the things that we see is there is more of a desire for the latest generation. And so as much as we're happy with how Turin is ramping, we're seeing actually a strong pull on Venice and a lot of early engagement in Venice, which kind of says a lot about kind of the importance of general-purpose compute at this point in time."
    },
    {
      "speaker": "Aaron Christopher Rakers",
      "role": "Wells Fargo Securities, LLC, Research Division",
      "text": "Wells Fargo Securities, LLC, Research Division As a quick follow-up, I'm curious and not to steal maybe the discussion from next week, but Lisa, you've been very consistent, like $500 billion of total AI silicon TAM opportunity and obviously progressing above that. I'm curious, as we think about these large megawatt kind of deployments, how you think about the updated views on that AI silicon TAM as we look forward."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Well, Aaron, as you said, not to take too much away from what we're going to talk about next week, look, we're going to give you a full picture of how we see the market next week. But suffice it to say, from everything that we see, we see the AI compute TAM just going up. So we'll have some updated numbers for you, but the view is, whereas $500 billion sounded like a lot when we first talked about it, we think there is a larger opportunity for us over the next few years, and that's pretty exciting."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from Antoine Chkaiban with New Street Research."
    },
    {
      "speaker": "Antoine  Chkaiban",
      "role": "New Street Research LLP",
      "text": "New Street Research LLP So I'd like to ask about whether the developing relationship with OpenAI could be a tailwind to the development of your software stack. Can you maybe tell us about how the collaboration works in practice and whether the partnership contributed in making ROCm more robust?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Yes. Antoine, thanks for the question. I think the answer is yes. I think all of our large customers contribute to, let's call it, a broadening and deepening of our software stack overall. I think the relationship with OpenAI is certainly one where our plans are to work deeply together on hardware as well as software as well as systems and future road map. And from that standpoint, the work that we're doing together with them on Triton is certainly very valuable. But I will say beyond OpenAI, the work that we do with all of our largest customers are super helpful to strengthen the software stack. And we have put significant new resources into not just the largest customers, but we are working with a broad set of AI-native companies who are actively developing on the ROCm stack. We get lots of feedback. I think we've made significant progress in the training and inference stack, and we're going to continue to double down and triple down in this area. So more customers that use AMD, I think all of that goes to enhancing the ROCm stack. And we're actually -- we'll talk a little bit more about this next week, but we're also using AI to help us accelerate the rate and pace of some of the ROCm kernel development and just the overall ecosystem."
    },
    {
      "speaker": "Antoine  Chkaiban",
      "role": "New Street Research LLP",
      "text": "New Street Research LLP Maybe as a quick follow-up, could you tell us about the useful lives of GPUs? I know that most CSPs depreciate them over 5, 6 years. But in your conversations with them, I'm just wondering if you see or hear any early indication that, in practice, they may be planning to sweat those GPUs for longer than that."
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO I think we have seen some early indications of that, Antoine. I think the key point being, clearly, there's a desire to get on the latest and greatest GPUs when you're building new data center infrastructure. And certainly, when we're looking at MI355s, they're often going into new liquid-cooled facilities, MI450 Series as well. But then we're also seeing the other trend, which is there's just a need for more AI compute. And from that standpoint, some of the older generation -- MI300X is still doing quite well in terms of just where we see people deploying and using especially for inference. And from that standpoint, I think you see a little bit of both."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the next question comes from the line of Joe Moore with Morgan Stanley."
    },
    {
      "speaker": "Joseph Lawrence Moore",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division You mentioned MI308, I guess what's your posture there to the extent that if there is some relief that you're able to ship, do you have readiness to do that? Can you give us a sense for how much of a swing factor that could be?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Joe. So look, it's still a pretty dynamic situation with MI308. So that's the reason that we did not include any MI308 revenue in the Q4 guide. We have received some licenses for MI308, so we're appreciative of the administration supporting some licenses for MI308. We're still working with our customers on the demand environment and sort of what the overall opportunity is. And so we'll be able to update that more in the next couple of months."
    },
    {
      "speaker": "Joseph Lawrence Moore",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division Okay. But you do have product to support that market if it does open up? Or does -- are you going to have to start to kind of rebuild inventory for that?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO We've had some work in process. I think we continue to have that work in process, but we'll have to see sort of how the demand environment shapes up."
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the final question comes from the line of Ross Seymore with Deutsche Bank."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division Lisa, this might take longer than the amount of time we have left before the top of the hour, but there's been so many of these multi-gigawatt announcements from OpenAI. How does AMD truly differentiate in there? When you see that big customer signing deals with other GPU vendors and ASIC vendors, et cetera, how do you attack that market differently than those competitors to not only get the 6 gigawatt initially but hopefully more after that?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Ross. Well, look, what I see is actually this environment where the world needs more AI compute. And from that standpoint, I think OpenAI has kind of led in the quest for more AI compute, but they're not alone. I think when you look across the large customers, there is really a demand for more AI compute as you go forward over the next couple of years. I think we each have our advantages in terms of how we are positioning our products. I think MI450 Series, in particular, I think, is an extremely strong product, rack-scale solution. Overall, when we look at compute performance, when we look at memory performance, we think it's extremely well positioned for both inference as well as training. I think the key here is time to market, it's total cost of ownership, it's deep partnership and thinking about not just MI450 Series, but what happens after that. So we're deep in conversations on MI500 and beyond. And we certainly think we're well positioned to not only participate but participate in a very meaningful way across the sort of the demand environment here. And I think we have certainly learned a ton over the last couple of years with our AI road map. We've made significant inroads in terms of just what the largest customer needs from a workload standpoint. So I'm pretty optimistic about our ability to capture a significant piece of this market going forward."
    },
    {
      "speaker": "Ross Clark Seymore",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division Great. And I guess as my follow-up, it'll be a direct follow-on to that. You did a unique structure by granting some warrants with this deal, and I know they're -- they vest according to a price that would be very accretive and make everybody happy. Do you think that was a relatively unique agreement or given that the world needs more processing power that AMD is open to somewhat similar, conceptually similar creative ways to address that demand over time with other equity vehicles, et cetera?"
    },
    {
      "speaker": "Lisa T. Su",
      "role": "Chair, President & CEO",
      "text": "Chair, President & CEO Sure, Ross. So I would say it was a unique agreement from the standpoint that unique time in AI, what we wanted, what we prioritized was really deep partnership and multiyear, multigeneration, significant scale. And I think we got that. We got a structure that has extremely aligned incentives. Everybody wins, right? We win. OpenAI wins, and our shareholder win -- sort of benefits from this. And all of that accrues to the overall road map. I think as we look forward, I think we have a lot of very interesting partnerships that are developing, whether they're with the largest AI users or you think about sovereign AI opportunities. And we look at each one of these as a unique opportunity where we're bringing sort of the whole of AMD, both technically as well as all the rest of our capabilities to the party. So I would say OpenAI was pretty unique, but I would imagine that there are lots of other opportunities for us to bring our capabilities into the ecosystem and participate in a significant way. OperatorLadies and gentlemen, that does conclude the question-and-answer session and that also concludes today's teleconference. We thank you for your participation. You may disconnect your lines at this time. Copyright  2025 by S&P Global Market Intelligence, a division of S&P Global Inc. All rights reserved. These materials have been prepared solely for information purposes based upon information generally available to the public and from sources believed to be reliable. No content (including index data, ratings, credit- related analyses and data, research, model, software or other application or output therefrom) or any part thereof (Content) may be modified, reverse engineered, reproduced or distributed in any form by any means, or stored in a database or retrieval system, without the prior written permission of S&P Global Market Intelligence or its affiliates (collectively, S&P Global). The Content shall not be used for any unlawful or unauthorized purposes. S&P Global and any third-party providers, (collectively S&P Global Parties) do not guarantee the accuracy, completeness, timeliness or availability of the Content. S&P Global Parties are not responsible for any errors or omissions, regardless of the cause, for the results obtained from the use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P GLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR DEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE CONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no event shall S&P Global Parties be liable to any party for any direct, indirect, incidental, exemplary, compensatory, punitive, special or consequential damages, costs, expenses, legal fees, or losses (including, without limitation, lost income or lost profits and opportunity costs or losses caused by negligence) in connection with any use of the Content even if advised of the possibility of such damages. S&P Global Market Intelligence's opinions, quotes and credit-related and other analyses are statements of opinion as of the date they are expressed and not statements of fact or recommendations to purchase, hold, or sell any securities or to make any investment decisions, and do not address the suitability of any security. S&P Global Market Intelligence may provide index data. Direct investment in an index is not possible. Exposure to an asset class represented by an index is available through investable instruments based on that index. S&P Global Market Intelligence assumes no obligation to update the Content following publication in any form or format. The Content should not be relied on and is not a substitute for the skill, judgment and experience of the user, its management, employees, advisors and/or clients when making investment and other business decisions. S&P Global Market Intelligence does not act as a fiduciary or an investment advisor except where registered as such. S&P Global keeps certain activities of its divisions separate from each other in order to preserve the independence and objectivity of their respective activities. As a result, certain divisions of S&P Global may have information that is not available to other S&P Global divisions. S&P Global has established policies and procedures to maintain the confidentiality of certain nonpublic information received in connection with each analytical process. S&P Global may receive compensation for its ratings and certain analyses, normally from issuers or underwriters of securities or from obligors. S&P Global reserves the right to disseminate its opinions and analyses. S&P Global's public ratings and analyses are made available on its Web sites, www.standardandpoors.com  (free of charge), and www.ratingsdirect.com  and www.globalcreditportal.com (subscription), and may be distributed through other means, including via S&P Global publications and third-party redistributors. Additional information about our ratings fees is available at www.standardandpoors.com/usratingsfees.  2025 S&P Global Market Intelligence."
    }
  ],
  "source_file": "Advanced Micro Devices, Inc., Q3 2025 Earnings Call, Nov 04, 2025.rtf"
}