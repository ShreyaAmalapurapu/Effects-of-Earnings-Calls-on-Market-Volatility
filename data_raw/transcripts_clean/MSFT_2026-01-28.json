{
  "event_id": "MSFT_2026-01-28",
  "ticker": "MSFT",
  "company": "Microsoft Corporation",
  "quarter": 2,
  "fiscal_year": 2026,
  "call_date": "2026-01-28",
  "call_start_ts": "2026-01-28 22:30:00+00:00",
  "raw_text": "Microsoft Corporation NasdaqGS:MSFT\nFQ2 2026 Earnings Call Transcripts\nWednesday, January 28, 2026 10:30 PM GMT\nS&P Global Market Intelligence Estimates\n\nPresentation\n\nOperator\n\nGreetings, and welcome to the Microsoft Fiscal Year 2026 Second Quarter\nEarnings Conference Call. [Operator Instructions] As a reminder, this\nconference is being recorded. It is now my pleasure to introduce Jonathan\nNeilson, Vice President of Investor Relations. Please go ahead.\n\nJonathan Neilson\nVice President of Investor Relations\n\nGood afternoon, and thank you for joining us today. On the call with me are\nSatya Nadella, Chairman and Chief Executive Officer; Amy Hood, Chief\nFinancial Officer; Alice Jolla, Chief Accounting Officer; and Keith\nDolliver, Corporate Secretary and Deputy General Counsel.\n\nOn the Microsoft Investor Relations website, you can find our earnings\npress release and financial summary slide deck, which is intended to\nsupplement our prepared remarks during today's call and provides the\nreconciliation of differences between GAAP and non-GAAP financial measures.\nMore detailed outlook slides will be available on the Microsoft Investor\nRelations website where we provide outlook commentary on today's call.\n\nOn this call, we will discuss certain non-GAAP items. The non-GAAP\nfinancial measures provided should not be considered as a substitute for or\nsuperior to the measures of financial performance prepared in accordance\nwith GAAP. They are included as additional clarifying items to aid\ninvestors in further understanding the company's second quarter performance\nin addition to the impact these items and events have on the financial\nresults.\n\nAll growth comparisons we make on the call today relates to the\ncorresponding period of last year, unless otherwise noted. We will also\nprovide growth rates in constant currency when available as a framework for\nassessing how our underlying businesses performed, excluding the effect of\nforeign currency rate fluctuations. Where growth rates are the same in\nconstant currency, we will refer to the growth rate only.\n\nWe will post our prepared remarks to our website immediately following the\ncall until the complete transcript is available.\n\nToday's call is being webcast live and recorded. If you ask a question, it\nwill be included in our live transmission, in the transcript, and in any\nfuture use of the recording. You can replay the call and view the\ntranscript on the Microsoft Investor Relations website.\n\nDuring this call, we will be making forward-looking statements, which are\npredictions, projections or other statements about future events. These\nstatements are based on current expectations and assumptions that are\nsubject to risks and uncertainties. Actual results could materially differ\nbecause of factors discussed in today's earnings press release, in the\ncomments made during this conference call, and in the Risk Factors section\nof our Form 10-K, Forms 10-Q and other reports and filings with the\nSecurities and Exchange Commission. We do not undertake any duty to update\nany forward-looking statement.\n\nAnd with that, I'll turn the call over to Satya.\n\nSatya Nadella\nChairman & CEO\n\nThank you very much, Jonathan. This quarter, the Microsoft Cloud surpassed\n$50 billion in revenue for the first time, up 26% year-over-year,\nreflecting the strength of our platform and accelerating demand. We are in\nthe beginning phases of AI diffusion and its broad GDP impact. Our TAM will\ngrow substantially across every layer of the tech stack as this diffusion\naccelerates and spreads. In fact, even in this early innings, we have built\nan AI business that is larger than some of our biggest franchises that took\ndecades to build. Today, I'll focus my remarks across the 3 layers of our\nstack, cloud and token factory, agent platform and high-value agentic\nexperiences.\n\nWhen it comes to our cloud and token factory, the key to long-term\ncompetitiveness is shaping our infrastructure to support new high-scale\nworkloads. We are building this infrastructure out for the heterogeneous\nand distributed nature of these workloads, ensuring the right fit with the\ngeographic and segment specific needs for all customers, including the long\ntail. The key metric we're optimizing for is tokens per watt per dollar,\nwhich comes down to increasing utilization and decreasing TCO using silicon\nsystems and software. A good example of this is the 50% increase in\nthroughput we were able to achieve in one of our highest volume workloads,\nOpenAI inferencing, powering our Copilots.\n\nAnd another example was the unlocking of new capabilities and efficiencies\nfor our Fairwater data centers. In this instance, we connected both Atlanta\nand Wisconsin site through an AI WAN to build a first of its kind AI super\nfactory. Fairwater's 2-storey design and liquid cooling allow us to run\nhigher GPU densities and thereby improve both performance and latencies for\nhigh-scale training. All up, we added nearly 1 gigawatt of total capacity\nthis quarter alone.\n\nAt the silicon layer, we have NVIDIA and AMD and our own Maia chips,\ndelivering the best all up fleet performance, cost and supply across\nmultiple generations of hardware. Earlier this week, we brought online our\nMaia 200 accelerator. Maia 200 delivers 10-plus petaFLOPS at FP4 precision\nwith over 30% improved TCO compared to the latest generation hardware in\nour fleet. We will be scaling this starting with inferencing and synthetic\ndata gen for our Superintelligence Team as well as doing inferencing for\nCopilot and Foundry.\n\nAnd given AI workloads are not just about AI accelerators, but also consume\nlarge amounts of compute, we are pleased with the progress we are making on\nthe CPU side as well. Cobalt 200 is another big leap forward, delivering\nover 50% higher performance compared to our first custom build processor\nfor cloud-native workloads. Sovereignty is increasingly top of mind for\ncustomers, and we are expanding our solutions and global footprint to\nmatch. We announced DC investments in 7 countries this quarter alone,\nsupporting local data residency needs. And we offer the most comprehensive\nset of sovereignty solutions across public, private and national partner\ncloud, so customers can choose the right approach for each workload with\nthe local control they require.\n\nNext, I want to talk about the agent platform. Like in every platform\nshift, all software is being rewritten. A new app platform is being born.\nYou can think of agents as the new apps and to build, deploy and manage\nagents, customers will need a model catalog, tuning services, harness for\norchestration, services for context engineering, AI safety, management,\nobservability and security. It starts with having broad model choice. Our\ncustomers expect to use multiple models as part of any workload that they\ncan fine tune and optimize based on cost, latency and performance\nrequirements. And we offer the broadest selection of models of any\nhyperscaler. This quarter, we added support for GPT-5.2 as well as Claude\n4.5. Already over 1,500 customers have used both Anthropic and OpenAI\nmodels on Foundry. We are seeing increasing demand for region-specific\nmodels, including Mistral and Cohere as more customers look for sovereign\nAI choices, and we continue to invest in our first-party models, which are\noptimized to address the highest value customer scenarios such as\nproductivity, coding and security.\n\nAs part of Foundry, we also give customers the ability to customize and\nfine-tune models. Increasingly, customers want to be able to capture the\ntacit knowledge they possess inside of model weights as their core IP. This\nis probably the most important sovereign consideration for firms as AI\ndiffuses more broadly across our GDP and every firm needs to protect their\nenterprise value. For agents to be effective, they need to be grounded in\nenterprise data and knowledge, that means connecting their agents to\nsystems of record and operational data, analytical data as well as semi-\nstructured and unstructured productivity and communications data. And this\nis what we are doing with our unified IQ layer, spanning Fabric, Foundry\nand data powering Microsoft 365.\n\nIn the world of context engineering, Foundry knowledge and Fabric are\ngaining momentum. Foundry knowledge delivers better context with automated\nsource routing an advanced agentic retrieval while respecting user\npermissions. And Fabric brings together end-to-end operational real-time\nand analytical data. 2 years since it became broadly available, Fabric's\nannual revenue run rate is now over $2 billion with over 31,000 customers,\nand it continues to be the fastest-growing analytics platform on the market\nwith revenue up 60% year-over-year. All of the number of customers spending\n$1 million plus per quarter on Foundry grew nearly 80%, driven by strong\ngrowth in every industry. And over 250 customers are on track to process\nover 1 trillion tokens on Foundry this year. There are many great examples\nof customers using all of this capability on Foundry to build their own\nagentic systems. Alaska Airlines is creating natural language flight\nsearch. BMW is speeding up design cycles, Land O'Lakes is enabling\nprecision farming for co-op members, and SymphonyAI is addressing\nbottlenecks in the CPG industry. And of course, Foundry remains a powerful\non-ramp for the entire cloud. The vast majority of Foundry customers use\nadditional Azure solutions like developer services, app services, databases\nas they scale.\n\nBeyond Fabric and Foundry, we are also addressing agent building by\nknowledge workers with Copilot Studio and Agent Builder. Over 80% of the\nFortune 500 have active agents built using these low-code/no-code tools. As\nagents proliferate, every customer will need new ways to deploy, manage and\nprotect them. We believe this creates a major new category and significant\ngrowth opportunity for us. This quarter, we introduced Agent 365, which\nmakes it easy for organizations to extend their existing governance,\nidentity, security and management to agents. That means the same controls\nthey already use across Microsoft 365 and Azure, now extend to agents they\nbuild and deploy on our cloud or any other cloud. And partners like Adobe,\nDatabricks, Genspark, Glean, NVIDIA, SAP, ServiceNow and Workday are\nalready integrating Agent 365. We are the first provider to offer this type\nof agent control plane across clouds.\n\nNow let's turn to the high-value agentic experiences we are building. AI\nexperiences are intent-driven and are beginning to work at task scope. We\nare entering an age of macro delegation and micro steering across domains.\nIntelligence using multiple models is built into multiple form factors. You\nsee this in chat, in new agent inbox, apps, coworkers, scaffoldings, agent\nworkflows embedded in applications and IDs that are used every day or even\nin our command line with file system access and skills. That's the approach\nwe are taking with our first-party family of copilot spanning key domains.\n\nIn consumer, for example, Copilot experiences span chat, news, feed,\nsearch, creation, browsing, shopping and integrations into the operating\nsystem, and it's gaining momentum. Daily users of our Copilot app increased\nnearly 3x year-over-year. And with Copilot checkout, we have partnered with\nPayPal, Shopify and Stripe, so customers can make purchases directly within\nthe app. With Microsoft 365 Copilot, we are focused on organization-wide\nproductivity.\n\nWork IQ takes the data underneath Microsoft 365 and creates the most\nvaluable stateful agent for every organization. It delivers powerful\nreasoning capabilities over people, their roles, their artifacts, their\ncommunications and their history and memory all within an organization\nsecurity boundary. Microsoft 365 Copilot's accuracy and latency powered by\nWork IQ is unmatched, delivering faster and more accurate work grounded\nresults than competition, and we have seen our biggest quarter-over-quarter\nimprovement in response quality to date. This has driven record usage\nintensity with average number of conversations per user doubling year-over-\nyear. Microsoft 365 Copilot also is becoming true daily habit with daily\nactive users increasing 10x year-over-year.\n\nWe're also seeing strong momentum with researcher agent, which supports\nboth OpenAI and Claude, as well as agent mode in Excel, PowerPoint and\nWord. All up, it was a record quarter for Microsoft 365 Copilot seat adds,\nup over 160% year-over-year. We saw accelerating seat growth quarter-over-\nquarter and now have 15 million paid Microsoft 365 Copilot seats and\nmultiples more enterprise chat users.\n\nAnd we are seeing larger commercial deployments. The number of customers\nwith over 35,000 seats tripled year-over-year. Fiserv, ING, NASA,\nUniversity of Kentucky, University of Manchester, U.S. Department of\nInterior and Westpac, all purchased over 35,000 seats. Publicis alone\npurchased over 95,000 seats for nearly all its employees. We are also\ntaking share in Dynamics 365 with built-in agents across the entire suite.\nA great example of this is how Visa is turning customer conversations data\ninto knowledge articles with our customer knowledge management agent and\ndynamics. And how Sandvik is using our sales qualification agent to\nautomate lead qualification across tens and thousands of potential\ncustomers.\n\nIn coding, we are seeing strong growth across all paid GitHub Copilot.\nCopilot Pro Plus subs for individual devs increased 77% quarter-over-\nquarter, and all up now, we have 4.7 million paid Copilot subscribers, up\n75% year-over-year. Siemens, for example, is going all in on GitHub\nadopting the full platform to increase developer productivity after a\nsuccessful Copilot rollout to 30,000-plus developers. GitHub Agent HQ is\nthe organizing layer for all coding agents like Anthropic, OpenAI, Google,\nCognition and xAI in the context of customers GitHub repos. With Copilot\nCLI and VS Code, we offer developers the full spectrum of form factors and\nmodels they need for AI-first coding workflows.\n\nAnd when you add Work IQ as a skill or an MCP to our developer workflow,\nit's a game changer, surfacing more context like e-mails, meetings, docs,\nprojects, messages and more. You can simply ask the agent to plan and\nexecute changes to your code base based on an update to a spec-in\nSharepoint or using the transcript of your last engineering and design\nmeeting in Teams.\n\nAnd we're going beyond that with GitHub Copilot STK. Developers can now\nembed the same run time behind Copilot CLI, multi-model, multistep planning\ntools, MCP integration, Ops streaming directly into their applications. In\nsecurity, we added a dozen new and updated security Copilot agents across\nDefender, Entra, Intune, and Purview. For example, Icertis, the SOC team\nused Security Copilot agent to reduce manual triage time by 75%, which is a\nreal game changer in an industry facing a severe talent shortage.\n\nTo make it easier for security teams to onboard, we are rolling out\nsecurity copilot to all our E5 customers and our security solutions are\nalso becoming essential to manage organization's AI deployments. 24 billion\nCopilot interactions were audited by Purview this quarter, up 9x year-over-\nyear.\n\nFinally, I want to talk about 2 additional high-impact agenetic\nexperiences. First, in health care, Dragon Copilot is the leader in its\ncategory, helping over 100,000 medical providers automate their workflows.\nMount Sinai Health is now moving to a system-wide Dragon Copilot deployment\nfor providers after a successful trial with its primary care physicians.\nAll up, we helped document 21 million patient encounters this quarter, up\n3x year-over-year.\n\nAnd second, when it comes to science and engineering, companies like\nUnilever in consumer goods and Synopsys in EDA are using Microsoft\nDiscovery to orchestrate specialized agents for R&D end-to-end. They're\nable to reason over scientific literature and internal knowledge, formulate\nhypotheses, spin up simulations and continuously iterate to drive new\ndiscoveries.\n\nBeyond AI, we continue to invest in all our core franchises and meet the\nneeds of our customers and partners, and we are seeing strong progress. For\nexample, when it comes to cloud migrations, our new SQL server has over 2x\nthe IaaS adoption of the previous version. In Security, we now have 1.6\nmillion security customers, including over 1 million who use 4 or more of\nour workloads. Windows reached a big milestone, 1 billion Windows 11 users\nup over 45% year-over-year. And we had share gains this quarter across\nWindows, Edge and Bing, double-digit member growth in LinkedIn with 30%\ngrowth in paid video ads.\n\nAnd in gaming, we are committed to delivering great games across Xbox, PC,\nCloud and every other device, and we saw record PC players in paid\nstreaming hours on Xbox.\n\nIn closing, we feel very good about how we are delivering for customers\ntoday and building the full stack to capture the opportunity ahead.\n\nWith that, let me turn it over to Amy to walk through our financial results\nand outlook, and I look forward to rejoining for your questions.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThank you, Satya, and good afternoon, everyone. With growing demand for our\nofferings and focused execution by our sales teams, we again exceeded\nexpectations across revenue, operating income and earnings per share, while\ninvesting to fuel long-term growth. This quarter, revenue was $81.3\nbillion, up 17% and 15% in constant currency. Gross margin dollars\nincreased 16% and 14% in constant currency, while operating income\nincreased 21% and 19% in constant currency.\n\nEarnings per share was $4.14, an increase of 24% and 21% in constant\ncurrency when adjusted for the impact from our investment in OpenAI. And FX\nincreased reported results slightly less than expected, particularly in\nIntelligent Cloud revenue. Company gross margin percentage was 68%, down\nslightly year-over-year, primarily driven by continued investments in AI\ninfrastructure and growing AI product usage that was partially offset by\nongoing efficiency gains, particularly in Azure and M365 Commercial Cloud\nas well as sales mix shift to higher-margin businesses.\n\nOperating expenses increased 5% and 4% in constant currency, driven by R&D\ninvestments in compute capacity and AI talent as well as impairment charges\nin our gaming business. Operating margins increased year-over-year to 47%,\nahead of expectations. As a reminder, we still account for investment in\nOpenAI under the equity method. And as a result of OpenAI's\nrecapitalization, we now record gains or losses based on our share of the\nchange in their net assets on their balance sheet as opposed to our share\nof their operating profit or losses from their income statement. Therefore,\nwe recorded a gain which drove other income and expense to $10 billion in\nour GAAP results.\n\nWhen adjusted for the OpenAI impact, other income and expense was slightly\nnegative and lower than expected driven by net losses on investments.\nCapital expenditures were $37.5 billion, and this quarter, roughly 2/3 of\nour CapEx was on short-lived assets, primarily GPUs and CPUs. Our customer\ndemand continues to exceed our supply. Therefore, we must balance the need\nto have our incoming supply better meet growing Azure demand with expanding\nfirst-party AI usage across services like M365 Copilot and GitHub Copilot,\nincreasing allocations to R&D teams to accelerate product innovation and\ncontinued replacement of end-of-life server and networking equipment.\n\nThe remaining spend was for long-lived assets that will support\nmonetization for the next 15 years and beyond. This quarter, total finance\nleases were $6.7 billion, and were primarily for large data center sites.\nAnd cash paid for PP&E was $29.9 billion. Cash flow from operations was\n$35.8 billion, up 60%, driven by strong Cloud billings and collections. And\nfree cash flow was $5.9 billion and decreased sequentially, reflecting the\nhigher cash capital expenditures from a lower mix of finance leases. And\nfinally, we returned $12.7 billion to shareholders through dividend and\nshare repurchases, an increase of 32% year-over-year.\n\nNow to our commercial results. Commercial bookings increased 230% and 228%\nin constant currency, driven by the previously announced large Azure\ncommitment from OpenAI that reflects multiyear demand needs as well as the\npreviously announced Anthropic commitment from November and healthy growth\nacross our core annuity sales motions.\n\nCommercial remaining performance obligation, which continues to be reported\nnet of reserves increased to $625 billion, and was up 110% year-over-year\nwith a weighted average duration of approximately 2.5 years. Roughly 25%\nwill be recognized in revenue in the next 12 months, up 39% year-over-year.\nThe remaining portion recognized beyond the next 12 months increased 156%.\nApproximately 45% of our commercial RPO balance is from OpenAI. The\nsignificant remaining balance grew 28% and reflects ongoing broad customer\ndemand across the portfolio.\n\nMicrosoft Cloud revenue was $51.5 billion and grew 26% and 24% in constant\ncurrency. Microsoft Cloud gross margin percentage was slightly better than\nexpected at 67%, and down year-over-year due to continued investments in AI\nthat were partially offset by ongoing efficiency gains noted earlier.\n\nNow to our segment results. Revenue from Productivity and Business\nProcesses was $34.1 billion and grew 16% and 14% in constant currency. M365\nCommercial cloud revenue increased 17% and 14% in constant currency with\nconsistent execution in the core business and increasing contribution from\nstrong copilot results. ARPU growth was again led by E5 and M365 Copilot,\nand paid M365 commercial seats grew 6% year-over-year to over 450 million\nwith installed base expansion across all customer segments, though\nprimarily in our small and medium business and frontline worker offerings.\n\nM365 Commercial products revenue increased 13% and 10% in constant\ncurrency, ahead of expectations due to higher-than-expected Office 2024\ntransactional purchasing. M365 consumer cloud revenue increased 29% and 27%\nin constant currency, again driven by ARPU growth. M365 consumer\nsubscriptions grew 6%. LinkedIn revenue increased 11% and 10% in constant\ncurrency driven by Marketing Solutions.\n\nDynamics 365 revenue increased 19% and 17% in constant currency with\ncontinued growth across all workloads. Segment gross margin dollars\nincreased 17% and 15% in constant currency, and gross margin percentage\nincreased, again driven by efficiency gains at M365 Commercial Cloud that\nwere partially offset by continued investments in AI, including the impact\nof growing copilot usage.\n\nOperating expenses increased 6% and 5% in constant currency, and operating\nincome increased 22% and 19% in constant currency. Operating margins\nincreased year-over-year to 60%, driven by improved operating leverage as\nwell as the higher gross margins noted earlier.\n\nNext, the Intelligent Cloud segment. Revenue was $32.9 billion and grew 29%\nand 28% in constant currency. In Azure and Other Cloud services, revenue\ngrew 39% and 38% in constant currency, slightly ahead of expectations with\nongoing efficiency gains across our fungible fleet, enabling us to\nreallocate some capacity to Azure that was monetized in the quarter.\n\nAs mentioned earlier, we continue to see strong demand across workloads,\ncustomer segments and geographic regions, and demand continues to exceed\navailable supply. In our on-premises server business, revenue increased 2%\nand 1% in constant currency, ahead of expectations, driven by demand for\nour hybrid solutions, including a benefit from the launch of SQL Server\n2025, as well as higher transactional purchasing ahead of memory price\nincreases. Segment gross margin dollars increased 20% and 19% in constant\ncurrency. Gross margin percentage decreased year-over-year, driven by\ncontinued investments in AI and sales mix shift to Azure, partially offset\nby efficiency gains in Azure.\n\nOperating expenses increased 3% and 2% in constant currency, and operating\nincome grew 28% and 27% in constant currency. Operating margins were 42%,\ndown slightly year-over-year as increased investments in AI were mostly\noffset by improved operating leverage.\n\nNow to More Personal Computing. Revenue was $14.3 billion and declined 3%.\nWindows OEM and devices revenue increased 1%, and was relatively unchanged\nin constant currency. Windows OEM grew 5% with strong execution as well as\na continued benefit from Windows 10 end of support. Results were ahead of\nexpectations as inventory levels remained elevated with increased\npurchasing ahead of memory price increases.\n\nSearch and news advertising revenue ex TAC increased 10% and 9% in constant\ncurrency, slightly below expectations, driven by some execution challenges.\nAs expected, the sequential growth rate moderated as the benefit from third-\nparty partnerships normalized.\n\nAnd in Gaming. Revenue decreased 9% and 10% in constant currency. Xbox\ncontent and services revenue decreased 5% and 6% in constant currency, and\nwas below expectations driven by first-party content with impact across the\nplatform. Segment gross margin dollars increased 2% and 1% in constant\ncurrency, and gross margin percentage increased year-over-year, driven by\nsales mix shift to higher-margin businesses.\n\nOperating expenses increased 6% and 5% in constant currency, driven by the\nimpairment charges in our gaming business noted earlier, as well as R&D\ninvestments in compute capacity and AI talent. Operating income decreased\n3% and 4% in constant currency, and operating margins were relatively\nunchanged year-over-year at 27% as higher operating expenses were mostly\noffset by higher gross margins.\n\nNow moving to our Q3 outlook, which unless specifically noted otherwise, is\non a U.S. dollar basis. Based on current rates, we expect FX to increase\ntotal revenue growth by 3 points. Within the segments, we expect FX to\nincrease revenue growth by 4 points in Productivity and Business Processes,\nand 2 points in Intelligent Cloud and More Personal Computing. We expect FX\nto increase COGS and operating expense growth by 2 points. As a reminder,\nthis impact is due to the exchange rates a year ago.\n\nStarting with the total company. We expect revenue of USD 80.65 billion to\nUSD 81.75 billion or growth of 15% to 17%, with continued strong growth\nacross our commercial businesses, partially offset by our consumer\nbusinesses. We expect COGS of USD 26.65 billion to USD 26.85 billion or\ngrowth of 22% to 23%, and operating expense of USD 17.8 billion to USD 17.9\nbillion or growth of 10% to 11%, driven by continued investment in R&D, AI\ncompute capacity and talent against a low prior year comparable. Operating\nmargins should be down slightly year-over-year.\n\nExcluding any impact from our investments in OpenAI, other income and\nexpense is expected to be roughly $700 million, driven by a fair market\ngain in our equity portfolio and interest income, partially offset by\ninterest expense, which includes the interest payments related to data\ncenter finance leases. And we expect our adjusted Q3 effective tax rate to\nbe approximately 19%.\n\nNext, we expect capital expenditures to decrease on a sequential basis due\nto the normal variability from cloud infrastructure build-outs and the\ntiming of delivery of finance leases. As we work to close the gap between\ndemand and supply, we expect the mix of short-lived assets to remain\nsimilar to Q2.\n\nNow our commercial business. In commercial bookings, we expect healthy\ngrowth in the core business on a growing expiry base when adjusted for the\nOpenAI contracts in the prior year. As a reminder, the significant OpenAI\ncontracts signed in Q2 represents multiyear demand needs from them, which\nwill result in some quarterly volatility in both bookings and RPO growth\nrates going forward. Microsoft Cloud gross margin percentage to be roughly\n65%, down year-over-year, driven by continued investments in AI.\n\nNow to segment guidance. In Productivity and Business Processes, we expect\nrevenue of USD 34.25 billion to USD 34.55 billion or growth of 14% to 15%.\nIn M365 Commercial Cloud, we expect revenue growth to be between 13% and\n14% in constant currency with continued stability and year-over-year growth\nrates on a large and expanding base. Accelerating Copilot momentum and\nongoing E5 adoption will again drive ARPU growth. M365 commercial products\nrevenue should decline in the low single digits, down sequentially,\nassuming office 2024 transactional purchasing trends normalize.\n\nAs a reminder, M365 commercial products include components that can be\nvariable due to in-period revenue recognition dynamics. M365 consumer cloud\nrevenue growth should be in the mid- to high 20% range, driven by growth in\nARPU as well as continued subscription volume. For LinkedIn, we expect\nrevenue growth to be in the low double digits. And in Dynamics 365, we\nexpect revenue growth to be in the high teens with continued growth across\nall workloads.\n\nFor Intelligent Cloud, we expect revenue of USD 34.1 billion to USD 34.4\nbillion or growth of 27% to 29%. In Azure, we expect Q3 revenue growth to\nbe between 37% and 38% in constant currency against a prior year comparable\nthat included significantly accelerating growth rates in both Q3 and Q4. As\nmentioned earlier, demand continues to exceed supply, and we will need to\ncontinue to balance the incoming supply we can allocate here against other\npriorities.\n\nAs a reminder, there can be quarterly variability in year-on-year growth\nrates depending on the timing of capacity delivery and when it comes online\nas well as from in-period revenue recognition depending on the mix of\ncontracts. In our on-premises server business, we expect revenue to decline\nin the low single digits as growth rates normalize following the launch of\nSQL Server 2025, though increased memory pricing could create additional\nvolatility in transactional purchasing.\n\nIn More Personal Computing, we expect revenue to be USD 12.3 billion to USD\n12.8 billion. Windows OEM and devices revenue should decline in the low\nteens. Growth rates will be impacted as the benefit from Windows 10 end of\nsupport normalizes and as elevated inventory levels come down through the\nquarter. Therefore, Windows OEM revenue should decline roughly 10%.\n\nThe range of potential outcomes remains wider than normal, in part due to\nthe potential impact on the PC market from increased memory pricing. Search\nand News advertising ex TAC revenue growth should be in the high single\ndigits. Even as we work to improve execution, we expect continued share\ngains across Bing and Edge with growth driven by volume, and we expect\nsequential growth moderation as the contribution from third-party\npartnerships continues to normalize.\n\nAnd in Xbox content and services, we expect revenue to decline in the mid-\nsingle digits against a prior year comparable that benefited from strong\ncontent performance, partially offset by growth in Xbox Game Pass. And\nhardware revenue should decline year-over-year.\n\nNow some additional thoughts on the rest of the fiscal year and beyond.\nFirst, FX. Based on current rates, we expect FX to increase Q4 total\nrevenue and COGS growth by less than 1 point with no impact to operating\nexpense growth. Within the segments, we expect FX to increase revenue\ngrowth by roughly 1 point in Productivity and Business Processes and More\nPersonal Computing, and less than 1 point in Intelligent Cloud.\n\nWith the strong work delivered in H1 to prioritize investment in key growth\nareas and the favorable impact from a higher mix of revenue in our Windows\nOEM and commercial on-prem businesses, we now expect FY '26 operating\nmargins to be up slightly. We mentioned the potential impact on Windows OEM\nand on-premises server markets from increased memory pricing earlier. In\naddition, rising memory prices would impact capital expenditures, though\nthe impact on Microsoft Cloud gross margins will build more gradually as\nthese assets depreciate over 6 years.\nIn closing, we delivered strong top line growth in H1, and are investing\nacross every layer of the stack to continue to deliver high-value solutions\nand tools to our customers. With that, let's go to Q&A, Jonathan.\n\nQuestion and Answer\n\nJonathan Neilson\nVice President of Investor Relations\n\nThanks, Amy. We'll now move over to Q&A. Out of respects for others on the\ncall, we request that participants please only ask 1 question. Operator,\ncan you please repeat your instructions?\n\nOperator\n\n[Operator Instructions] And our first question comes from the line of Keith\nWeiss with Morgan Stanley.\n\nKeith Weiss\nMorgan Stanley, Research Division\n\nI'm looking at Microsoft print where earnings is growing 24% year-on-year,\nwhich is a spectacular result. Great execution on your part, top line\ngrowing well, margins expanding. But I'm looking at after-hours trading and\nthe stock is still down. And I think one of the core issues that is\nweighing on investors is CapEx is growing faster than we expected and maybe\nAzure is growing a little bit slower than we expected. And I think that\nfundamentally comes down to a concern on the ROI on this CapEx spend over\ntime. So I was hoping you guys could help us fill in some of the blanks a\nlittle bit in terms of how should we think about capacity expansion and\nwhat that can yield in terms of Azure growth going forward. More to the\npoint, how should we think about the ROI on this investment as it comes to\nfruition?\n\nAmy E. Hood\nExecutive VP & CFO\n\nThanks, Keith. And let me start and Satya can add some broader comments,\nI'm sure. I think the first thing, I think you really asked a very direct\ncorrelation that I do think many investors are doing, which is between the\nCapEx spend and seeing an Azure revenue number. And we tried last quarter,\nand I think, again, this quarter to talk more specifically about all the\nplaces that the CapEx spend, especially the short-lived CapEx spend across\nCPU and GPU and where that will show up.\n\nSometimes, I think it's probably better to think about the Azure guidance\nthat we give as an allocated capacity guide about what we can deliver in\nAzure revenue. Because as we spend the capital and put GPUs specifically,\nit applies to CPUs, the GPUs more specifically, we're really making long-\nterm decisions. And the first thing we're doing is solving for the\nincreased usage in sales and the accelerating pace of M365 Copilot as well\nas GitHub Copilot, our first-party apps. Then we make sure we're investing\nin the long-term nature of R&D and product innovation. And much of the\nacceleration that I think you've seen from us and products over the past a\nbit is coming because we are allocating GPUs and capacity to many of the\ntalented AI people we've been hiring over the past years.\n\nThen, when you end up, is that, you end up with the remainder going towards\nserving the Azure capacity that continues to grow in terms of demand. And a\nway to think about it, because I think, I get asked this question\nsometimes, is if I had taken the GPUs that just came online in Q1 and Q2 in\nterms of GPUs and allocated them all to Azure, the KPI would have been over\n40. And I think the most important thing to realize is that this is about\ninvesting in all the layers of the stack that benefit customers. And I\nthink that's hopefully helpful in terms of thinking about capital growth,\nit shows in every piece, it shows in revenue growth across the business and\nshows as OpEx growth as we invest in our people.\n\nSatya Nadella\nChairman & CEO\n\nYes, I think you -- Amy covered it. But basically, as an investor, I think\nwhen you think about our capital and you think about the GM profile of our\nportfolio, you should obviously think about Azure. But you should think\nabout M365 Copilot and you should think about GitHub pilot, you should\nthink about Dragon Copilot, Security Copilot. All of those have a GM\nprofile and lifetime value. I mean if you think about it, acquiring an\nAzure customer is super important to us, but so is acquiring an M365 or a\nGitHub or a Dragon Copilot, which are all by the way incremental businesses\nand TAMs for us. And so we don't want to maximize just 1 business of ours,\nwe want to be able to allocate capacity while we're sort of supply\nconstrained in a way that allow us to essentially build the best LTV\nportfolio. That's on one side. And the other one that Amy mentioned is also\nR&D. I mean you got to think about compute is also R&D, and that's sort of\nthe second element of it. And so we are using all of that, obviously, to\noptimize for the long term.\n\nOperator\n\nThe next question comes from the line of Mark Moerdler with Bernstein\nResearch.\n\nMark L. Moerdler\nBernstein Institutional Services LLC, Research Division\n\nCongrats on the quarter. One of the other questions we believe investors\nwant to understand is how to think about your line of sight from hardware\nCapEx investment to revenue and margins. You capitalized servers over 6\nyears, but the average duration of your RPO is 2.5 years, up from 2 years\nlast quarter. How do investors get comfortable that since this is a lot of\nthis CapEx is AI-centric that you'll be able to capture sufficient revenue\nover the 6-year useful life of the hardware to deliver solid revenue and\ngross profit dollars growth, hopefully, one similar to the CPU revenue.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThanks, Mark. Let me start with at a high level and Satya can add as well.\nI think when you think about average duration, I think what you're getting\nto is -- and we need to remember, is it, average duration is a combination\nof a broad set of contract arrangements that we have. A lot of them around\nthings like M365 or our BizApps portfolio, are shorter dated, right, 3-year\ncontracts. And so they have, quite frankly, a short duration. The majority\nthen that's remaining are Azure contracts are longer duration. And you saw\nthat this quarter when we saw the extension of that duration from around 2\nyears to 2.5 years. And the way to think about that is the majority of the\ncapital that we're spending today, and a lot of the GPUs that we're buying\nare already contracted for most of their useful life. And so a way to think\nabout that is much of that risk that I think you're pointing to isn't\nthere, because they're already sold for the entirety of their useful life.\nAnd so part of it exists because you have this shorter-dated RPO because of\nsome of the M365 stuff. If you look at the Azure only, RPO is a little bit\nmore extended. A lot of that is CPU basis. It's not just GPU. And on the\nGPU contracts that we've talked about, including for some of our largest\ncustomers, those are sold for the entire useful life of the GPU. And so\nthere's not the risk to which I think you may be referring. Hopefully,\nthat's helpful.\n\nSatya Nadella\nChairman & CEO\n\nYes. And just to -- one other thing I would add to it is, in addition to\nsort of what Amy mentioned, which is it's already contracted for the useful\nlife is we do use software to continuously around even the latest models on\nthe fleet that is aging, if you will. So that's sort of what gives us that\nduration. And so at the end of the day, we want to have -- that's why we\neven think about aging the fleet constantly, right? So it's not about\nbuying a whole lot of gear 1 year. It's about each year, you write the\nMoore's Law, you add, you use software, and then you optimize across all of\nit.\n\nAmy E. Hood\nExecutive VP & CFO\n\nAnd Mark, maybe to state this in case it's not obvious, is that as you go\nthrough the useful life, actually, you get more and more and more efficient\nat delivery. So where you've sold the entirety of its life, the margins\nactually improved with time. And so I think that may be a good reminder to\npeople as we see that, obviously, in the CPU fleet all the time.\n\nOperator\n\nThe next question comes from the line of Brent Thill with Jefferies.\n\nBrent John Thill\nJefferies LLC, Research Division\n\nAmy, on 45% of the backlog being related to OpenAI. I'm just curious if you\ncan comment, there's obviously concern about the durability. And I know\nmaybe there's not much you can say on this, but I think everyone is\nconcerned about the exposure. And if you could maybe talk through your\nperspective and what both you and Satya are seeing.\n\nAmy E. Hood\nExecutive VP & CFO\n\nI think maybe I would have thought about the question quite differently,\nBrent. The first thing to focus on is the reason we talked about that\nnumber is because 55% or roughly $350 billion is related to the breadth of\nour portfolio, a breadth of customers across solutions, across Azure,\nacross industries, across geographies. That is a significant RPO balance,\nlarger than most peers, more diversified than most peers. And frankly, I\nthink we have super high confidence in it.\n\nAnd when you think about that portion alone growing 28%, it's really\nimpressive work on the breadth as well as the adoption curve that we're\nseeing, which is I think what I get asked most frequently, it's grown by\ncustomer segment, by industry and by geo. And so it's very consistent. And\nso then if you're asking about how do I feel about OpenAI and the contract\nand the health, listen, it's a great partnership. We continue to be their\nprovider of scale. We're excited to do that. We sit under one of the most\nsuccessful businesses built, and we continue to feel quite good about that.\nIt's allowed us to remain a leader in terms of what we're building and\nbeing on the cutting edge of app innovation.\n\nOperator\n\nThe next question comes from the line of Karl Keirstead with UBS.\n\nKarl Emil Keirstead\nUBS Investment Bank, Research Division\n\nAmy, regardless of how you allocate the capacity between first party and\nthird party, can you comment qualitatively on the amount of capacity that's\ncoming on. I think the 1 gigawatt added in the December quarter was\nextraordinary and hence that the capacity adds are accelerating. But I\nthink a lot of investors have their eyes on Fairwater Atlanta, Fairwater\nWisconsin, and would love some comments about the magnitude of the capacity\nadds regardless of how they're allocated in the coming quarters.\n\nAmy E. Hood\nExecutive VP & CFO\n\nYes, Karl, I think we've said a couple of things. We're working as hard as\nwe can to add capacity as quickly as we can. You've mentioned specific\nsites like Atlanta or Wisconsin, those are multiyear deliveries. So I\nwouldn't focus necessarily on specific locations. The real thing we've got\nto do, and we're working incredibly hard doing it, is adding capacity\nglobally. A lot of that will be added in the United States, the 2 locations\nyou've mentioned, but it also needs to be added across the globe to meet\nthe customer demand that we're seeing and the increased usage. We'll\ncontinue to add both long-lived infrastructure. The way to think about that\nis we need to make sure we've got power and land and facilities available\nand we'll continue to put GPUs and CPUs in them when they're done as\nquickly as we can.\n\nAnd then finally, we'll try to make sure we can get as efficient as we\npossibly can on the pace at which we do that and how we operate them so\nthat they can have the highest possible utility. And so I think it's not\nreally about 2 places, Karl, I would definitely abstract away from that.\nThose are multiyear delivery time lines. But really, we just need to get it\ndone every location where we're currently in a build or starting to do\nthat. We're working as quickly as we can.\n\nOperator\n\nThe next question comes from the line of Mark Murphy with JPMorgan.\n\nMark Ronald Murphy\nJPMorgan Chase & Co, Research Division\n\nSatya, the performance achievements of the Maia 200 accelerator for\ninference, look quite remarkable, especially in comparison to TPUs and\nTrinium and Blackwell, which have just been around a lot longer. Could you\nput that accomplishment in perspective in terms of how much of a core\ncompetency you think silicon might become for Microsoft. And Amy, are there\nany ramifications worth mentioning there in terms of supporting your gross\nmargin profile for inference costs going forward?\n\nSatya Nadella\nChairman & CEO\n\nYes, thanks for the question. So a couple of things. One is we've been at\nthis in a variety of different forms for a long, long time in terms of\nbuilding our own silicon. And so we're very, very thrilled about the\nprogress with Maia 200, and -- especially when we think about running a GPT-\n5.2 and the performance we were able to get in the GEMS at FB4, just proof\npoint that when you have a new workload, a new shape of a workload, you can\nstart innovating end-to-end between the model and the silicon and the\nentire system. It's just not even about just the silicon, the way the\nnetworking works at rack scale that's optimized with memory for this\nparticular workload.\n\nAnd the other thing is we're obviously round-tripping and working very\nclosely with own super intelligence team with all of our models, as you can\nimagine, whatever we build will be all optimized for Maia. So we feel great\nabout it. And I think the way to think about all up is we're in such early\ninnings. I mean, even just look at the amount of silicon innovation and\nsystems innovation. Even since December, I think the new thing is everybody\nis talking about low latency inference, right? And so one of the things we\nwant to make sure is we are not locked into any one thing. If anything, we\nhave great partnership with NVIDIA, with AMD, they are innovating, we're\ninnovating. We want a fleet at any given point in time to have access to\nthe best TCO. And it's not a one-generation game. I think a lot of folks\njust talk about who's ahead. It's just remember, you have to be ahead for\nall time to come. And that means you really want to think about having a\nlot of innovation that happens out there to be in your fleet, so that your\nfleet is fundamentally advantaged at the TCO level. So that's kind of how I\nlook at it, which is we are excited about Maia. We're excited about Cobalt.\nWe're excited about our DPU, our NIC. So we have a lot of systems\ncapability. That means we can vertically integrate. And because we can\nvertically integrate doesn't mean we just only vertically integrate. And so\nwe want to be able to have the flexibility here, and that's what you see us\ndo.\n\nOperator\n\nThe next question comes from the line of Brad Zelnick with Deutsche Bank.\n\nBrad Alan Zelnick\nDeutsche Bank AG, Research Division\n\nSatya, we heard a lot about Frontier transformations from Judson at Ignite,\nand we've seen customers realize breakthrough benefits when they adopt the\nMicrosoft AI stack. Can you help frame for us the momentum in enterprises\nembarking on these journeys? And any expectation for how much their spend\nwith Microsoft can expand in becoming frontier firms?\n\nSatya Nadella\nChairman & CEO\n\nYes. Thank you for that. So I think one of the things that we are seeing is\nthe adoption across the 3 major suites of ours, right? So if you take M365,\nyou take what's happening with security and you take GitHub. In fact, it's\nfascinating. I mean these 3 things had effectively compounding effects for\nour customers in the past, like something like Entra as an identity system,\nor Defender as the protection system, across all 3 was sort of super\nhelpful.\n\nBut so what now you're seeing is something like Work IQ, right? So I mean\njust to give you a favor for it, the most important database underneath for\nany company that uses Microsoft today is the data underneath Microsoft 365.\nAnd the reason is because it has all those tacit information, right, who\nare your people, what are their relationships, what are their projects\nthey're working on, what are their artifacts, their communications. So\nthat's a super important asset for any business process, business workflow\ncontext.\n\nIn fact, the scenario I even had in my transcript around you can now take\nWork IQ as an MCP server and GitHub Repo and say, \"Hey, please look at my\ndesign meetings for the last month in Teams and tell me if my repo reflects\nit.\" I mean that's a pretty high-level way to think about how, what is\nhappening previously perhaps with our tools business and our GitHub\nbusiness are suddenly now being transformative, right? That agent black\nplane is really transforming companies in some sense, right? That's, I\nthink, the most magical thing, which is you deploy these things. And\nsuddenly, the agents are helping you coordinate, bring more leverage to\nyour enterprise.\n\nThen on top of it, of course, there is the transformation, which is what\nbusinesses are doing. How should we think about customer service. How\nshould we think about marketing. How should we think about finance. How\nshould we think about that and build our own agents. That's where all the\nservices in Fabric and Foundry. And of course, GitHub tooling is helping\nthem or even the low-code/no-code tools. I had some stats on how much\nthat's being used. But one of the more exciting things for me is the new\nagents systems, M365 Copilot, GitHub Copilot, Security Copilot, all coming\ntogether to compound the benefits of all the data and all the deployment, I\nthink, is probably the most transformative effect right now.\n\nJonathan Neilson\nVice President of Investor Relations\n\nThanks, Brad. Operator, we have time for 1 last question.\n\nOperator\n\nAnd the last question will come from the line of Raimo Lenschow with\nBarclays.\n\nRaimo Lenschow\nBarclays Bank PLC, Research Division\n\nThe last few quarters we talked -- besides the GPU side, you talked about\nCPU as well on the Azure side and you had some operational changes at the\nbeginning of January last year. Can you speak what you saw there? And maybe\nput it more on a bigger picture in terms of clients realizing that their\nmove to the cloud is important if you want to deliver proper AI. So what\nare we seeing in terms of cloud transition?\n\nSatya Nadella\nChairman & CEO\n\nI didn't quite...\n\nJonathan Neilson\nVice President of Investor Relations\n\nSorry, Raimo, you were asking about the SMC CPU side? Or can you just\nrepeat the question, please?\n\nRaimo Lenschow\nBarclays Bank PLC, Research Division\n\nYes. Sorry. So I was wondering about the CPU side of Azure because we had\nsome operational changes there. And we also hear from the [ field a lot ]\nthat people are realizing they need to be in the Cloud if you want to do\nproper AI and if that's kind of driving momentum.\n\nSatya Nadella\nChairman & CEO\n\nYes. I think I get it. So first of all, I had mentioned in my remarks that\nwhen you think about AI workloads, you should think of AI workloads as just\nAI accelerator compute, right? Because in some sense, you take any agent,\nthe agent will then spawn through tools used maybe a container, which runs\nobviously on compute. In fact, we have -- whenever we think about even\nbuilding out of the fleet, we think of in ratios or even for a training\njob, by the way. An AI training job requires a bunch of compute and a bunch\nof storage very close to compute. So therefore -- and same thing in\ninferencing as well.\n\nSo in inferencing with agent mode would require you to essentially\nprovision a computer or computing resources to the agent. So not -- they\ndon't need GPUs. They're running on GPUs, but they need computers, which\nare compute and storage. So that's what's happening even in the new world.\n\nThe other thing you mentioned is the Cloud migrations are still going on.\nIn fact, 1 of the stats I had was SQL -- latest SQL server growing as an\nIaaS service in Azure. And so -- that's one of the reasons why we have to\nthink about our commercial cloud and keep it balanced with the rest of our\nAI Cloud because when clients bring their workloads and build new\nworkloads, they need all of these infrastructure elements in the region in\nwhich they are deploying.\n\nJonathan Neilson\nVice President of Investor Relations\n\nThat wraps up the Q&A portion of today's earnings call. Thank you for\njoining us today, and we look forward to speaking with you all soon.\n\nSatya Nadella\nChairman & CEO\n\nThank you all.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThank you.\n\nOperatorThank you. This concludes today's conference. You may disconnect\nyour lines at this time, and we thank you for your participation. Have a\ngreat night.\nCopyright  2026 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com (free of charge), and www.ratingsdirect.com and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2026 S&P Global Market Intelligence.",
  "presentation_text": "Operator\n\nGreetings, and welcome to the Microsoft Fiscal Year 2026 Second Quarter\nEarnings Conference Call. [Operator Instructions] As a reminder, this\nconference is being recorded. It is now my pleasure to introduce Jonathan\nNeilson, Vice President of Investor Relations. Please go ahead.\n\nJonathan Neilson\nVice President of Investor Relations\n\nGood afternoon, and thank you for joining us today. On the call with me are\nSatya Nadella, Chairman and Chief Executive Officer; Amy Hood, Chief\nFinancial Officer; Alice Jolla, Chief Accounting Officer; and Keith\nDolliver, Corporate Secretary and Deputy General Counsel.\n\nOn the Microsoft Investor Relations website, you can find our earnings\npress release and financial summary slide deck, which is intended to\nsupplement our prepared remarks during today's call and provides the\nreconciliation of differences between GAAP and non-GAAP financial measures.\nMore detailed outlook slides will be available on the Microsoft Investor\nRelations website where we provide outlook commentary on today's call.\n\nOn this call, we will discuss certain non-GAAP items. The non-GAAP\nfinancial measures provided should not be considered as a substitute for or\nsuperior to the measures of financial performance prepared in accordance\nwith GAAP. They are included as additional clarifying items to aid\ninvestors in further understanding the company's second quarter performance\nin addition to the impact these items and events have on the financial\nresults.\n\nAll growth comparisons we make on the call today relates to the\ncorresponding period of last year, unless otherwise noted. We will also\nprovide growth rates in constant currency when available as a framework for\nassessing how our underlying businesses performed, excluding the effect of\nforeign currency rate fluctuations. Where growth rates are the same in\nconstant currency, we will refer to the growth rate only.\n\nWe will post our prepared remarks to our website immediately following the\ncall until the complete transcript is available.\n\nToday's call is being webcast live and recorded. If you ask a question, it\nwill be included in our live transmission, in the transcript, and in any\nfuture use of the recording. You can replay the call and view the\ntranscript on the Microsoft Investor Relations website.\n\nDuring this call, we will be making forward-looking statements, which are\npredictions, projections or other statements about future events. These\nstatements are based on current expectations and assumptions that are\nsubject to risks and uncertainties. Actual results could materially differ\nbecause of factors discussed in today's earnings press release, in the\ncomments made during this conference call, and in the Risk Factors section\nof our Form 10-K, Forms 10-Q and other reports and filings with the\nSecurities and Exchange Commission. We do not undertake any duty to update\nany forward-looking statement.\n\nAnd with that, I'll turn the call over to Satya.\n\nSatya Nadella\nChairman & CEO\n\nThank you very much, Jonathan. This quarter, the Microsoft Cloud surpassed\n$50 billion in revenue for the first time, up 26% year-over-year,\nreflecting the strength of our platform and accelerating demand. We are in\nthe beginning phases of AI diffusion and its broad GDP impact. Our TAM will\ngrow substantially across every layer of the tech stack as this diffusion\naccelerates and spreads. In fact, even in this early innings, we have built\nan AI business that is larger than some of our biggest franchises that took\ndecades to build. Today, I'll focus my remarks across the 3 layers of our\nstack, cloud and token factory, agent platform and high-value agentic\nexperiences.\n\nWhen it comes to our cloud and token factory, the key to long-term\ncompetitiveness is shaping our infrastructure to support new high-scale\nworkloads. We are building this infrastructure out for the heterogeneous\nand distributed nature of these workloads, ensuring the right fit with the\ngeographic and segment specific needs for all customers, including the long\ntail. The key metric we're optimizing for is tokens per watt per dollar,\nwhich comes down to increasing utilization and decreasing TCO using silicon\nsystems and software. A good example of this is the 50% increase in\nthroughput we were able to achieve in one of our highest volume workloads,\nOpenAI inferencing, powering our Copilots.\n\nAnd another example was the unlocking of new capabilities and efficiencies\nfor our Fairwater data centers. In this instance, we connected both Atlanta\nand Wisconsin site through an AI WAN to build a first of its kind AI super\nfactory. Fairwater's 2-storey design and liquid cooling allow us to run\nhigher GPU densities and thereby improve both performance and latencies for\nhigh-scale training. All up, we added nearly 1 gigawatt of total capacity\nthis quarter alone.\n\nAt the silicon layer, we have NVIDIA and AMD and our own Maia chips,\ndelivering the best all up fleet performance, cost and supply across\nmultiple generations of hardware. Earlier this week, we brought online our\nMaia 200 accelerator. Maia 200 delivers 10-plus petaFLOPS at FP4 precision\nwith over 30% improved TCO compared to the latest generation hardware in\nour fleet. We will be scaling this starting with inferencing and synthetic\ndata gen for our Superintelligence Team as well as doing inferencing for\nCopilot and Foundry.\n\nAnd given AI workloads are not just about AI accelerators, but also consume\nlarge amounts of compute, we are pleased with the progress we are making on\nthe CPU side as well. Cobalt 200 is another big leap forward, delivering\nover 50% higher performance compared to our first custom build processor\nfor cloud-native workloads. Sovereignty is increasingly top of mind for\ncustomers, and we are expanding our solutions and global footprint to\nmatch. We announced DC investments in 7 countries this quarter alone,\nsupporting local data residency needs. And we offer the most comprehensive\nset of sovereignty solutions across public, private and national partner\ncloud, so customers can choose the right approach for each workload with\nthe local control they require.\n\nNext, I want to talk about the agent platform. Like in every platform\nshift, all software is being rewritten. A new app platform is being born.\nYou can think of agents as the new apps and to build, deploy and manage\nagents, customers will need a model catalog, tuning services, harness for\norchestration, services for context engineering, AI safety, management,\nobservability and security. It starts with having broad model choice. Our\ncustomers expect to use multiple models as part of any workload that they\ncan fine tune and optimize based on cost, latency and performance\nrequirements. And we offer the broadest selection of models of any\nhyperscaler. This quarter, we added support for GPT-5.2 as well as Claude\n4.5. Already over 1,500 customers have used both Anthropic and OpenAI\nmodels on Foundry. We are seeing increasing demand for region-specific\nmodels, including Mistral and Cohere as more customers look for sovereign\nAI choices, and we continue to invest in our first-party models, which are\noptimized to address the highest value customer scenarios such as\nproductivity, coding and security.\n\nAs part of Foundry, we also give customers the ability to customize and\nfine-tune models. Increasingly, customers want to be able to capture the\ntacit knowledge they possess inside of model weights as their core IP. This\nis probably the most important sovereign consideration for firms as AI\ndiffuses more broadly across our GDP and every firm needs to protect their\nenterprise value. For agents to be effective, they need to be grounded in\nenterprise data and knowledge, that means connecting their agents to\nsystems of record and operational data, analytical data as well as semi-\nstructured and unstructured productivity and communications data. And this\nis what we are doing with our unified IQ layer, spanning Fabric, Foundry\nand data powering Microsoft 365.\n\nIn the world of context engineering, Foundry knowledge and Fabric are\ngaining momentum. Foundry knowledge delivers better context with automated\nsource routing an advanced agentic retrieval while respecting user\npermissions. And Fabric brings together end-to-end operational real-time\nand analytical data. 2 years since it became broadly available, Fabric's\nannual revenue run rate is now over $2 billion with over 31,000 customers,\nand it continues to be the fastest-growing analytics platform on the market\nwith revenue up 60% year-over-year. All of the number of customers spending\n$1 million plus per quarter on Foundry grew nearly 80%, driven by strong\ngrowth in every industry. And over 250 customers are on track to process\nover 1 trillion tokens on Foundry this year. There are many great examples\nof customers using all of this capability on Foundry to build their own\nagentic systems. Alaska Airlines is creating natural language flight\nsearch. BMW is speeding up design cycles, Land O'Lakes is enabling\nprecision farming for co-op members, and SymphonyAI is addressing\nbottlenecks in the CPG industry. And of course, Foundry remains a powerful\non-ramp for the entire cloud. The vast majority of Foundry customers use\nadditional Azure solutions like developer services, app services, databases\nas they scale.\n\nBeyond Fabric and Foundry, we are also addressing agent building by\nknowledge workers with Copilot Studio and Agent Builder. Over 80% of the\nFortune 500 have active agents built using these low-code/no-code tools. As\nagents proliferate, every customer will need new ways to deploy, manage and\nprotect them. We believe this creates a major new category and significant\ngrowth opportunity for us. This quarter, we introduced Agent 365, which\nmakes it easy for organizations to extend their existing governance,\nidentity, security and management to agents. That means the same controls\nthey already use across Microsoft 365 and Azure, now extend to agents they\nbuild and deploy on our cloud or any other cloud. And partners like Adobe,\nDatabricks, Genspark, Glean, NVIDIA, SAP, ServiceNow and Workday are\nalready integrating Agent 365. We are the first provider to offer this type\nof agent control plane across clouds.\n\nNow let's turn to the high-value agentic experiences we are building. AI\nexperiences are intent-driven and are beginning to work at task scope. We\nare entering an age of macro delegation and micro steering across domains.\nIntelligence using multiple models is built into multiple form factors. You\nsee this in chat, in new agent inbox, apps, coworkers, scaffoldings, agent\nworkflows embedded in applications and IDs that are used every day or even\nin our command line with file system access and skills. That's the approach\nwe are taking with our first-party family of copilot spanning key domains.\n\nIn consumer, for example, Copilot experiences span chat, news, feed,\nsearch, creation, browsing, shopping and integrations into the operating\nsystem, and it's gaining momentum. Daily users of our Copilot app increased\nnearly 3x year-over-year. And with Copilot checkout, we have partnered with\nPayPal, Shopify and Stripe, so customers can make purchases directly within\nthe app. With Microsoft 365 Copilot, we are focused on organization-wide\nproductivity.\n\nWork IQ takes the data underneath Microsoft 365 and creates the most\nvaluable stateful agent for every organization. It delivers powerful\nreasoning capabilities over people, their roles, their artifacts, their\ncommunications and their history and memory all within an organization\nsecurity boundary. Microsoft 365 Copilot's accuracy and latency powered by\nWork IQ is unmatched, delivering faster and more accurate work grounded\nresults than competition, and we have seen our biggest quarter-over-quarter\nimprovement in response quality to date. This has driven record usage\nintensity with average number of conversations per user doubling year-over-\nyear. Microsoft 365 Copilot also is becoming true daily habit with daily\nactive users increasing 10x year-over-year.\n\nWe're also seeing strong momentum with researcher agent, which supports\nboth OpenAI and Claude, as well as agent mode in Excel, PowerPoint and\nWord. All up, it was a record quarter for Microsoft 365 Copilot seat adds,\nup over 160% year-over-year. We saw accelerating seat growth quarter-over-\nquarter and now have 15 million paid Microsoft 365 Copilot seats and\nmultiples more enterprise chat users.\n\nAnd we are seeing larger commercial deployments. The number of customers\nwith over 35,000 seats tripled year-over-year. Fiserv, ING, NASA,\nUniversity of Kentucky, University of Manchester, U.S. Department of\nInterior and Westpac, all purchased over 35,000 seats. Publicis alone\npurchased over 95,000 seats for nearly all its employees. We are also\ntaking share in Dynamics 365 with built-in agents across the entire suite.\nA great example of this is how Visa is turning customer conversations data\ninto knowledge articles with our customer knowledge management agent and\ndynamics. And how Sandvik is using our sales qualification agent to\nautomate lead qualification across tens and thousands of potential\ncustomers.\n\nIn coding, we are seeing strong growth across all paid GitHub Copilot.\nCopilot Pro Plus subs for individual devs increased 77% quarter-over-\nquarter, and all up now, we have 4.7 million paid Copilot subscribers, up\n75% year-over-year. Siemens, for example, is going all in on GitHub\nadopting the full platform to increase developer productivity after a\nsuccessful Copilot rollout to 30,000-plus developers. GitHub Agent HQ is\nthe organizing layer for all coding agents like Anthropic, OpenAI, Google,\nCognition and xAI in the context of customers GitHub repos. With Copilot\nCLI and VS Code, we offer developers the full spectrum of form factors and\nmodels they need for AI-first coding workflows.\n\nAnd when you add Work IQ as a skill or an MCP to our developer workflow,\nit's a game changer, surfacing more context like e-mails, meetings, docs,\nprojects, messages and more. You can simply ask the agent to plan and\nexecute changes to your code base based on an update to a spec-in\nSharepoint or using the transcript of your last engineering and design\nmeeting in Teams.\n\nAnd we're going beyond that with GitHub Copilot STK. Developers can now\nembed the same run time behind Copilot CLI, multi-model, multistep planning\ntools, MCP integration, Ops streaming directly into their applications. In\nsecurity, we added a dozen new and updated security Copilot agents across\nDefender, Entra, Intune, and Purview. For example, Icertis, the SOC team\nused Security Copilot agent to reduce manual triage time by 75%, which is a\nreal game changer in an industry facing a severe talent shortage.\n\nTo make it easier for security teams to onboard, we are rolling out\nsecurity copilot to all our E5 customers and our security solutions are\nalso becoming essential to manage organization's AI deployments. 24 billion\nCopilot interactions were audited by Purview this quarter, up 9x year-over-\nyear.\n\nFinally, I want to talk about 2 additional high-impact agenetic\nexperiences. First, in health care, Dragon Copilot is the leader in its\ncategory, helping over 100,000 medical providers automate their workflows.\nMount Sinai Health is now moving to a system-wide Dragon Copilot deployment\nfor providers after a successful trial with its primary care physicians.\nAll up, we helped document 21 million patient encounters this quarter, up\n3x year-over-year.\n\nAnd second, when it comes to science and engineering, companies like\nUnilever in consumer goods and Synopsys in EDA are using Microsoft\nDiscovery to orchestrate specialized agents for R&D end-to-end. They're\nable to reason over scientific literature and internal knowledge, formulate\nhypotheses, spin up simulations and continuously iterate to drive new\ndiscoveries.\n\nBeyond AI, we continue to invest in all our core franchises and meet the\nneeds of our customers and partners, and we are seeing strong progress. For\nexample, when it comes to cloud migrations, our new SQL server has over 2x\nthe IaaS adoption of the previous version. In Security, we now have 1.6\nmillion security customers, including over 1 million who use 4 or more of\nour workloads. Windows reached a big milestone, 1 billion Windows 11 users\nup over 45% year-over-year. And we had share gains this quarter across\nWindows, Edge and Bing, double-digit member growth in LinkedIn with 30%\ngrowth in paid video ads.\n\nAnd in gaming, we are committed to delivering great games across Xbox, PC,\nCloud and every other device, and we saw record PC players in paid\nstreaming hours on Xbox.\n\nIn closing, we feel very good about how we are delivering for customers\ntoday and building the full stack to capture the opportunity ahead.\n\nWith that, let me turn it over to Amy to walk through our financial results\nand outlook, and I look forward to rejoining for your questions.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThank you, Satya, and good afternoon, everyone. With growing demand for our\nofferings and focused execution by our sales teams, we again exceeded\nexpectations across revenue, operating income and earnings per share, while\ninvesting to fuel long-term growth. This quarter, revenue was $81.3\nbillion, up 17% and 15% in constant currency. Gross margin dollars\nincreased 16% and 14% in constant currency, while operating income\nincreased 21% and 19% in constant currency.\n\nEarnings per share was $4.14, an increase of 24% and 21% in constant\ncurrency when adjusted for the impact from our investment in OpenAI. And FX\nincreased reported results slightly less than expected, particularly in\nIntelligent Cloud revenue. Company gross margin percentage was 68%, down\nslightly year-over-year, primarily driven by continued investments in AI\ninfrastructure and growing AI product usage that was partially offset by\nongoing efficiency gains, particularly in Azure and M365 Commercial Cloud\nas well as sales mix shift to higher-margin businesses.\n\nOperating expenses increased 5% and 4% in constant currency, driven by R&D\ninvestments in compute capacity and AI talent as well as impairment charges\nin our gaming business. Operating margins increased year-over-year to 47%,\nahead of expectations. As a reminder, we still account for investment in\nOpenAI under the equity method. And as a result of OpenAI's\nrecapitalization, we now record gains or losses based on our share of the\nchange in their net assets on their balance sheet as opposed to our share\nof their operating profit or losses from their income statement. Therefore,\nwe recorded a gain which drove other income and expense to $10 billion in\nour GAAP results.\n\nWhen adjusted for the OpenAI impact, other income and expense was slightly\nnegative and lower than expected driven by net losses on investments.\nCapital expenditures were $37.5 billion, and this quarter, roughly 2/3 of\nour CapEx was on short-lived assets, primarily GPUs and CPUs. Our customer\ndemand continues to exceed our supply. Therefore, we must balance the need\nto have our incoming supply better meet growing Azure demand with expanding\nfirst-party AI usage across services like M365 Copilot and GitHub Copilot,\nincreasing allocations to R&D teams to accelerate product innovation and\ncontinued replacement of end-of-life server and networking equipment.\n\nThe remaining spend was for long-lived assets that will support\nmonetization for the next 15 years and beyond. This quarter, total finance\nleases were $6.7 billion, and were primarily for large data center sites.\nAnd cash paid for PP&E was $29.9 billion. Cash flow from operations was\n$35.8 billion, up 60%, driven by strong Cloud billings and collections. And\nfree cash flow was $5.9 billion and decreased sequentially, reflecting the\nhigher cash capital expenditures from a lower mix of finance leases. And\nfinally, we returned $12.7 billion to shareholders through dividend and\nshare repurchases, an increase of 32% year-over-year.\n\nNow to our commercial results. Commercial bookings increased 230% and 228%\nin constant currency, driven by the previously announced large Azure\ncommitment from OpenAI that reflects multiyear demand needs as well as the\npreviously announced Anthropic commitment from November and healthy growth\nacross our core annuity sales motions.\n\nCommercial remaining performance obligation, which continues to be reported\nnet of reserves increased to $625 billion, and was up 110% year-over-year\nwith a weighted average duration of approximately 2.5 years. Roughly 25%\nwill be recognized in revenue in the next 12 months, up 39% year-over-year.\nThe remaining portion recognized beyond the next 12 months increased 156%.\nApproximately 45% of our commercial RPO balance is from OpenAI. The\nsignificant remaining balance grew 28% and reflects ongoing broad customer\ndemand across the portfolio.\n\nMicrosoft Cloud revenue was $51.5 billion and grew 26% and 24% in constant\ncurrency. Microsoft Cloud gross margin percentage was slightly better than\nexpected at 67%, and down year-over-year due to continued investments in AI\nthat were partially offset by ongoing efficiency gains noted earlier.\n\nNow to our segment results. Revenue from Productivity and Business\nProcesses was $34.1 billion and grew 16% and 14% in constant currency. M365\nCommercial cloud revenue increased 17% and 14% in constant currency with\nconsistent execution in the core business and increasing contribution from\nstrong copilot results. ARPU growth was again led by E5 and M365 Copilot,\nand paid M365 commercial seats grew 6% year-over-year to over 450 million\nwith installed base expansion across all customer segments, though\nprimarily in our small and medium business and frontline worker offerings.\n\nM365 Commercial products revenue increased 13% and 10% in constant\ncurrency, ahead of expectations due to higher-than-expected Office 2024\ntransactional purchasing. M365 consumer cloud revenue increased 29% and 27%\nin constant currency, again driven by ARPU growth. M365 consumer\nsubscriptions grew 6%. LinkedIn revenue increased 11% and 10% in constant\ncurrency driven by Marketing Solutions.\n\nDynamics 365 revenue increased 19% and 17% in constant currency with\ncontinued growth across all workloads. Segment gross margin dollars\nincreased 17% and 15% in constant currency, and gross margin percentage\nincreased, again driven by efficiency gains at M365 Commercial Cloud that\nwere partially offset by continued investments in AI, including the impact\nof growing copilot usage.\n\nOperating expenses increased 6% and 5% in constant currency, and operating\nincome increased 22% and 19% in constant currency. Operating margins\nincreased year-over-year to 60%, driven by improved operating leverage as\nwell as the higher gross margins noted earlier.\n\nNext, the Intelligent Cloud segment. Revenue was $32.9 billion and grew 29%\nand 28% in constant currency. In Azure and Other Cloud services, revenue\ngrew 39% and 38% in constant currency, slightly ahead of expectations with\nongoing efficiency gains across our fungible fleet, enabling us to\nreallocate some capacity to Azure that was monetized in the quarter.\n\nAs mentioned earlier, we continue to see strong demand across workloads,\ncustomer segments and geographic regions, and demand continues to exceed\navailable supply. In our on-premises server business, revenue increased 2%\nand 1% in constant currency, ahead of expectations, driven by demand for\nour hybrid solutions, including a benefit from the launch of SQL Server\n2025, as well as higher transactional purchasing ahead of memory price\nincreases. Segment gross margin dollars increased 20% and 19% in constant\ncurrency. Gross margin percentage decreased year-over-year, driven by\ncontinued investments in AI and sales mix shift to Azure, partially offset\nby efficiency gains in Azure.\n\nOperating expenses increased 3% and 2% in constant currency, and operating\nincome grew 28% and 27% in constant currency. Operating margins were 42%,\ndown slightly year-over-year as increased investments in AI were mostly\noffset by improved operating leverage.\n\nNow to More Personal Computing. Revenue was $14.3 billion and declined 3%.\nWindows OEM and devices revenue increased 1%, and was relatively unchanged\nin constant currency. Windows OEM grew 5% with strong execution as well as\na continued benefit from Windows 10 end of support. Results were ahead of\nexpectations as inventory levels remained elevated with increased\npurchasing ahead of memory price increases.\n\nSearch and news advertising revenue ex TAC increased 10% and 9% in constant\ncurrency, slightly below expectations, driven by some execution challenges.\nAs expected, the sequential growth rate moderated as the benefit from third-\nparty partnerships normalized.\n\nAnd in Gaming. Revenue decreased 9% and 10% in constant currency. Xbox\ncontent and services revenue decreased 5% and 6% in constant currency, and\nwas below expectations driven by first-party content with impact across the\nplatform. Segment gross margin dollars increased 2% and 1% in constant\ncurrency, and gross margin percentage increased year-over-year, driven by\nsales mix shift to higher-margin businesses.\n\nOperating expenses increased 6% and 5% in constant currency, driven by the\nimpairment charges in our gaming business noted earlier, as well as R&D\ninvestments in compute capacity and AI talent. Operating income decreased\n3% and 4% in constant currency, and operating margins were relatively\nunchanged year-over-year at 27% as higher operating expenses were mostly\noffset by higher gross margins.\n\nNow moving to our Q3 outlook, which unless specifically noted otherwise, is\non a U.S. dollar basis. Based on current rates, we expect FX to increase\ntotal revenue growth by 3 points. Within the segments, we expect FX to\nincrease revenue growth by 4 points in Productivity and Business Processes,\nand 2 points in Intelligent Cloud and More Personal Computing. We expect FX\nto increase COGS and operating expense growth by 2 points. As a reminder,\nthis impact is due to the exchange rates a year ago.\n\nStarting with the total company. We expect revenue of USD 80.65 billion to\nUSD 81.75 billion or growth of 15% to 17%, with continued strong growth\nacross our commercial businesses, partially offset by our consumer\nbusinesses. We expect COGS of USD 26.65 billion to USD 26.85 billion or\ngrowth of 22% to 23%, and operating expense of USD 17.8 billion to USD 17.9\nbillion or growth of 10% to 11%, driven by continued investment in R&D, AI\ncompute capacity and talent against a low prior year comparable. Operating\nmargins should be down slightly year-over-year.\n\nExcluding any impact from our investments in OpenAI, other income and\nexpense is expected to be roughly $700 million, driven by a fair market\ngain in our equity portfolio and interest income, partially offset by\ninterest expense, which includes the interest payments related to data\ncenter finance leases. And we expect our adjusted Q3 effective tax rate to\nbe approximately 19%.\n\nNext, we expect capital expenditures to decrease on a sequential basis due\nto the normal variability from cloud infrastructure build-outs and the\ntiming of delivery of finance leases. As we work to close the gap between\ndemand and supply, we expect the mix of short-lived assets to remain\nsimilar to Q2.\n\nNow our commercial business. In commercial bookings, we expect healthy\ngrowth in the core business on a growing expiry base when adjusted for the\nOpenAI contracts in the prior year. As a reminder, the significant OpenAI\ncontracts signed in Q2 represents multiyear demand needs from them, which\nwill result in some quarterly volatility in both bookings and RPO growth\nrates going forward. Microsoft Cloud gross margin percentage to be roughly\n65%, down year-over-year, driven by continued investments in AI.\n\nNow to segment guidance. In Productivity and Business Processes, we expect\nrevenue of USD 34.25 billion to USD 34.55 billion or growth of 14% to 15%.\nIn M365 Commercial Cloud, we expect revenue growth to be between 13% and\n14% in constant currency with continued stability and year-over-year growth\nrates on a large and expanding base. Accelerating Copilot momentum and\nongoing E5 adoption will again drive ARPU growth. M365 commercial products\nrevenue should decline in the low single digits, down sequentially,\nassuming office 2024 transactional purchasing trends normalize.\n\nAs a reminder, M365 commercial products include components that can be\nvariable due to in-period revenue recognition dynamics. M365 consumer cloud\nrevenue growth should be in the mid- to high 20% range, driven by growth in\nARPU as well as continued subscription volume. For LinkedIn, we expect\nrevenue growth to be in the low double digits. And in Dynamics 365, we\nexpect revenue growth to be in the high teens with continued growth across\nall workloads.\n\nFor Intelligent Cloud, we expect revenue of USD 34.1 billion to USD 34.4\nbillion or growth of 27% to 29%. In Azure, we expect Q3 revenue growth to\nbe between 37% and 38% in constant currency against a prior year comparable\nthat included significantly accelerating growth rates in both Q3 and Q4. As\nmentioned earlier, demand continues to exceed supply, and we will need to\ncontinue to balance the incoming supply we can allocate here against other\npriorities.\n\nAs a reminder, there can be quarterly variability in year-on-year growth\nrates depending on the timing of capacity delivery and when it comes online\nas well as from in-period revenue recognition depending on the mix of\ncontracts. In our on-premises server business, we expect revenue to decline\nin the low single digits as growth rates normalize following the launch of\nSQL Server 2025, though increased memory pricing could create additional\nvolatility in transactional purchasing.\n\nIn More Personal Computing, we expect revenue to be USD 12.3 billion to USD\n12.8 billion. Windows OEM and devices revenue should decline in the low\nteens. Growth rates will be impacted as the benefit from Windows 10 end of\nsupport normalizes and as elevated inventory levels come down through the\nquarter. Therefore, Windows OEM revenue should decline roughly 10%.\n\nThe range of potential outcomes remains wider than normal, in part due to\nthe potential impact on the PC market from increased memory pricing. Search\nand News advertising ex TAC revenue growth should be in the high single\ndigits. Even as we work to improve execution, we expect continued share\ngains across Bing and Edge with growth driven by volume, and we expect\nsequential growth moderation as the contribution from third-party\npartnerships continues to normalize.\n\nAnd in Xbox content and services, we expect revenue to decline in the mid-\nsingle digits against a prior year comparable that benefited from strong\ncontent performance, partially offset by growth in Xbox Game Pass. And\nhardware revenue should decline year-over-year.\n\nNow some additional thoughts on the rest of the fiscal year and beyond.\nFirst, FX. Based on current rates, we expect FX to increase Q4 total\nrevenue and COGS growth by less than 1 point with no impact to operating\nexpense growth. Within the segments, we expect FX to increase revenue\ngrowth by roughly 1 point in Productivity and Business Processes and More\nPersonal Computing, and less than 1 point in Intelligent Cloud.\n\nWith the strong work delivered in H1 to prioritize investment in key growth\nareas and the favorable impact from a higher mix of revenue in our Windows\nOEM and commercial on-prem businesses, we now expect FY '26 operating\nmargins to be up slightly. We mentioned the potential impact on Windows OEM\nand on-premises server markets from increased memory pricing earlier. In\naddition, rising memory prices would impact capital expenditures, though\nthe impact on Microsoft Cloud gross margins will build more gradually as\nthese assets depreciate over 6 years.\nIn closing, we delivered strong top line growth in H1, and are investing\nacross every layer of the stack to continue to deliver high-value solutions\nand tools to our customers. With that, let's go to Q&A, Jonathan.",
  "qa_text": "Jonathan Neilson\nVice President of Investor Relations\n\nThanks, Amy. We'll now move over to Q&A. Out of respects for others on the\ncall, we request that participants please only ask 1 question. Operator,\ncan you please repeat your instructions?\n\nOperator\n\n[Operator Instructions] And our first question comes from the line of Keith\nWeiss with Morgan Stanley.\n\nKeith Weiss\nMorgan Stanley, Research Division\n\nI'm looking at Microsoft print where earnings is growing 24% year-on-year,\nwhich is a spectacular result. Great execution on your part, top line\ngrowing well, margins expanding. But I'm looking at after-hours trading and\nthe stock is still down. And I think one of the core issues that is\nweighing on investors is CapEx is growing faster than we expected and maybe\nAzure is growing a little bit slower than we expected. And I think that\nfundamentally comes down to a concern on the ROI on this CapEx spend over\ntime. So I was hoping you guys could help us fill in some of the blanks a\nlittle bit in terms of how should we think about capacity expansion and\nwhat that can yield in terms of Azure growth going forward. More to the\npoint, how should we think about the ROI on this investment as it comes to\nfruition?\n\nAmy E. Hood\nExecutive VP & CFO\n\nThanks, Keith. And let me start and Satya can add some broader comments,\nI'm sure. I think the first thing, I think you really asked a very direct\ncorrelation that I do think many investors are doing, which is between the\nCapEx spend and seeing an Azure revenue number. And we tried last quarter,\nand I think, again, this quarter to talk more specifically about all the\nplaces that the CapEx spend, especially the short-lived CapEx spend across\nCPU and GPU and where that will show up.\n\nSometimes, I think it's probably better to think about the Azure guidance\nthat we give as an allocated capacity guide about what we can deliver in\nAzure revenue. Because as we spend the capital and put GPUs specifically,\nit applies to CPUs, the GPUs more specifically, we're really making long-\nterm decisions. And the first thing we're doing is solving for the\nincreased usage in sales and the accelerating pace of M365 Copilot as well\nas GitHub Copilot, our first-party apps. Then we make sure we're investing\nin the long-term nature of R&D and product innovation. And much of the\nacceleration that I think you've seen from us and products over the past a\nbit is coming because we are allocating GPUs and capacity to many of the\ntalented AI people we've been hiring over the past years.\n\nThen, when you end up, is that, you end up with the remainder going towards\nserving the Azure capacity that continues to grow in terms of demand. And a\nway to think about it, because I think, I get asked this question\nsometimes, is if I had taken the GPUs that just came online in Q1 and Q2 in\nterms of GPUs and allocated them all to Azure, the KPI would have been over\n40. And I think the most important thing to realize is that this is about\ninvesting in all the layers of the stack that benefit customers. And I\nthink that's hopefully helpful in terms of thinking about capital growth,\nit shows in every piece, it shows in revenue growth across the business and\nshows as OpEx growth as we invest in our people.\n\nSatya Nadella\nChairman & CEO\n\nYes, I think you -- Amy covered it. But basically, as an investor, I think\nwhen you think about our capital and you think about the GM profile of our\nportfolio, you should obviously think about Azure. But you should think\nabout M365 Copilot and you should think about GitHub pilot, you should\nthink about Dragon Copilot, Security Copilot. All of those have a GM\nprofile and lifetime value. I mean if you think about it, acquiring an\nAzure customer is super important to us, but so is acquiring an M365 or a\nGitHub or a Dragon Copilot, which are all by the way incremental businesses\nand TAMs for us. And so we don't want to maximize just 1 business of ours,\nwe want to be able to allocate capacity while we're sort of supply\nconstrained in a way that allow us to essentially build the best LTV\nportfolio. That's on one side. And the other one that Amy mentioned is also\nR&D. I mean you got to think about compute is also R&D, and that's sort of\nthe second element of it. And so we are using all of that, obviously, to\noptimize for the long term.\n\nOperator\n\nThe next question comes from the line of Mark Moerdler with Bernstein\nResearch.\n\nMark L. Moerdler\nBernstein Institutional Services LLC, Research Division\n\nCongrats on the quarter. One of the other questions we believe investors\nwant to understand is how to think about your line of sight from hardware\nCapEx investment to revenue and margins. You capitalized servers over 6\nyears, but the average duration of your RPO is 2.5 years, up from 2 years\nlast quarter. How do investors get comfortable that since this is a lot of\nthis CapEx is AI-centric that you'll be able to capture sufficient revenue\nover the 6-year useful life of the hardware to deliver solid revenue and\ngross profit dollars growth, hopefully, one similar to the CPU revenue.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThanks, Mark. Let me start with at a high level and Satya can add as well.\nI think when you think about average duration, I think what you're getting\nto is -- and we need to remember, is it, average duration is a combination\nof a broad set of contract arrangements that we have. A lot of them around\nthings like M365 or our BizApps portfolio, are shorter dated, right, 3-year\ncontracts. And so they have, quite frankly, a short duration. The majority\nthen that's remaining are Azure contracts are longer duration. And you saw\nthat this quarter when we saw the extension of that duration from around 2\nyears to 2.5 years. And the way to think about that is the majority of the\ncapital that we're spending today, and a lot of the GPUs that we're buying\nare already contracted for most of their useful life. And so a way to think\nabout that is much of that risk that I think you're pointing to isn't\nthere, because they're already sold for the entirety of their useful life.\nAnd so part of it exists because you have this shorter-dated RPO because of\nsome of the M365 stuff. If you look at the Azure only, RPO is a little bit\nmore extended. A lot of that is CPU basis. It's not just GPU. And on the\nGPU contracts that we've talked about, including for some of our largest\ncustomers, those are sold for the entire useful life of the GPU. And so\nthere's not the risk to which I think you may be referring. Hopefully,\nthat's helpful.\n\nSatya Nadella\nChairman & CEO\n\nYes. And just to -- one other thing I would add to it is, in addition to\nsort of what Amy mentioned, which is it's already contracted for the useful\nlife is we do use software to continuously around even the latest models on\nthe fleet that is aging, if you will. So that's sort of what gives us that\nduration. And so at the end of the day, we want to have -- that's why we\neven think about aging the fleet constantly, right? So it's not about\nbuying a whole lot of gear 1 year. It's about each year, you write the\nMoore's Law, you add, you use software, and then you optimize across all of\nit.\n\nAmy E. Hood\nExecutive VP & CFO\n\nAnd Mark, maybe to state this in case it's not obvious, is that as you go\nthrough the useful life, actually, you get more and more and more efficient\nat delivery. So where you've sold the entirety of its life, the margins\nactually improved with time. And so I think that may be a good reminder to\npeople as we see that, obviously, in the CPU fleet all the time.\n\nOperator\n\nThe next question comes from the line of Brent Thill with Jefferies.\n\nBrent John Thill\nJefferies LLC, Research Division\n\nAmy, on 45% of the backlog being related to OpenAI. I'm just curious if you\ncan comment, there's obviously concern about the durability. And I know\nmaybe there's not much you can say on this, but I think everyone is\nconcerned about the exposure. And if you could maybe talk through your\nperspective and what both you and Satya are seeing.\n\nAmy E. Hood\nExecutive VP & CFO\n\nI think maybe I would have thought about the question quite differently,\nBrent. The first thing to focus on is the reason we talked about that\nnumber is because 55% or roughly $350 billion is related to the breadth of\nour portfolio, a breadth of customers across solutions, across Azure,\nacross industries, across geographies. That is a significant RPO balance,\nlarger than most peers, more diversified than most peers. And frankly, I\nthink we have super high confidence in it.\n\nAnd when you think about that portion alone growing 28%, it's really\nimpressive work on the breadth as well as the adoption curve that we're\nseeing, which is I think what I get asked most frequently, it's grown by\ncustomer segment, by industry and by geo. And so it's very consistent. And\nso then if you're asking about how do I feel about OpenAI and the contract\nand the health, listen, it's a great partnership. We continue to be their\nprovider of scale. We're excited to do that. We sit under one of the most\nsuccessful businesses built, and we continue to feel quite good about that.\nIt's allowed us to remain a leader in terms of what we're building and\nbeing on the cutting edge of app innovation.\n\nOperator\n\nThe next question comes from the line of Karl Keirstead with UBS.\n\nKarl Emil Keirstead\nUBS Investment Bank, Research Division\n\nAmy, regardless of how you allocate the capacity between first party and\nthird party, can you comment qualitatively on the amount of capacity that's\ncoming on. I think the 1 gigawatt added in the December quarter was\nextraordinary and hence that the capacity adds are accelerating. But I\nthink a lot of investors have their eyes on Fairwater Atlanta, Fairwater\nWisconsin, and would love some comments about the magnitude of the capacity\nadds regardless of how they're allocated in the coming quarters.\n\nAmy E. Hood\nExecutive VP & CFO\n\nYes, Karl, I think we've said a couple of things. We're working as hard as\nwe can to add capacity as quickly as we can. You've mentioned specific\nsites like Atlanta or Wisconsin, those are multiyear deliveries. So I\nwouldn't focus necessarily on specific locations. The real thing we've got\nto do, and we're working incredibly hard doing it, is adding capacity\nglobally. A lot of that will be added in the United States, the 2 locations\nyou've mentioned, but it also needs to be added across the globe to meet\nthe customer demand that we're seeing and the increased usage. We'll\ncontinue to add both long-lived infrastructure. The way to think about that\nis we need to make sure we've got power and land and facilities available\nand we'll continue to put GPUs and CPUs in them when they're done as\nquickly as we can.\n\nAnd then finally, we'll try to make sure we can get as efficient as we\npossibly can on the pace at which we do that and how we operate them so\nthat they can have the highest possible utility. And so I think it's not\nreally about 2 places, Karl, I would definitely abstract away from that.\nThose are multiyear delivery time lines. But really, we just need to get it\ndone every location where we're currently in a build or starting to do\nthat. We're working as quickly as we can.\n\nOperator\n\nThe next question comes from the line of Mark Murphy with JPMorgan.\n\nMark Ronald Murphy\nJPMorgan Chase & Co, Research Division\n\nSatya, the performance achievements of the Maia 200 accelerator for\ninference, look quite remarkable, especially in comparison to TPUs and\nTrinium and Blackwell, which have just been around a lot longer. Could you\nput that accomplishment in perspective in terms of how much of a core\ncompetency you think silicon might become for Microsoft. And Amy, are there\nany ramifications worth mentioning there in terms of supporting your gross\nmargin profile for inference costs going forward?\n\nSatya Nadella\nChairman & CEO\n\nYes, thanks for the question. So a couple of things. One is we've been at\nthis in a variety of different forms for a long, long time in terms of\nbuilding our own silicon. And so we're very, very thrilled about the\nprogress with Maia 200, and -- especially when we think about running a GPT-\n5.2 and the performance we were able to get in the GEMS at FB4, just proof\npoint that when you have a new workload, a new shape of a workload, you can\nstart innovating end-to-end between the model and the silicon and the\nentire system. It's just not even about just the silicon, the way the\nnetworking works at rack scale that's optimized with memory for this\nparticular workload.\n\nAnd the other thing is we're obviously round-tripping and working very\nclosely with own super intelligence team with all of our models, as you can\nimagine, whatever we build will be all optimized for Maia. So we feel great\nabout it. And I think the way to think about all up is we're in such early\ninnings. I mean, even just look at the amount of silicon innovation and\nsystems innovation. Even since December, I think the new thing is everybody\nis talking about low latency inference, right? And so one of the things we\nwant to make sure is we are not locked into any one thing. If anything, we\nhave great partnership with NVIDIA, with AMD, they are innovating, we're\ninnovating. We want a fleet at any given point in time to have access to\nthe best TCO. And it's not a one-generation game. I think a lot of folks\njust talk about who's ahead. It's just remember, you have to be ahead for\nall time to come. And that means you really want to think about having a\nlot of innovation that happens out there to be in your fleet, so that your\nfleet is fundamentally advantaged at the TCO level. So that's kind of how I\nlook at it, which is we are excited about Maia. We're excited about Cobalt.\nWe're excited about our DPU, our NIC. So we have a lot of systems\ncapability. That means we can vertically integrate. And because we can\nvertically integrate doesn't mean we just only vertically integrate. And so\nwe want to be able to have the flexibility here, and that's what you see us\ndo.\n\nOperator\n\nThe next question comes from the line of Brad Zelnick with Deutsche Bank.\n\nBrad Alan Zelnick\nDeutsche Bank AG, Research Division\n\nSatya, we heard a lot about Frontier transformations from Judson at Ignite,\nand we've seen customers realize breakthrough benefits when they adopt the\nMicrosoft AI stack. Can you help frame for us the momentum in enterprises\nembarking on these journeys? And any expectation for how much their spend\nwith Microsoft can expand in becoming frontier firms?\n\nSatya Nadella\nChairman & CEO\n\nYes. Thank you for that. So I think one of the things that we are seeing is\nthe adoption across the 3 major suites of ours, right? So if you take M365,\nyou take what's happening with security and you take GitHub. In fact, it's\nfascinating. I mean these 3 things had effectively compounding effects for\nour customers in the past, like something like Entra as an identity system,\nor Defender as the protection system, across all 3 was sort of super\nhelpful.\n\nBut so what now you're seeing is something like Work IQ, right? So I mean\njust to give you a favor for it, the most important database underneath for\nany company that uses Microsoft today is the data underneath Microsoft 365.\nAnd the reason is because it has all those tacit information, right, who\nare your people, what are their relationships, what are their projects\nthey're working on, what are their artifacts, their communications. So\nthat's a super important asset for any business process, business workflow\ncontext.\n\nIn fact, the scenario I even had in my transcript around you can now take\nWork IQ as an MCP server and GitHub Repo and say, \"Hey, please look at my\ndesign meetings for the last month in Teams and tell me if my repo reflects\nit.\" I mean that's a pretty high-level way to think about how, what is\nhappening previously perhaps with our tools business and our GitHub\nbusiness are suddenly now being transformative, right? That agent black\nplane is really transforming companies in some sense, right? That's, I\nthink, the most magical thing, which is you deploy these things. And\nsuddenly, the agents are helping you coordinate, bring more leverage to\nyour enterprise.\n\nThen on top of it, of course, there is the transformation, which is what\nbusinesses are doing. How should we think about customer service. How\nshould we think about marketing. How should we think about finance. How\nshould we think about that and build our own agents. That's where all the\nservices in Fabric and Foundry. And of course, GitHub tooling is helping\nthem or even the low-code/no-code tools. I had some stats on how much\nthat's being used. But one of the more exciting things for me is the new\nagents systems, M365 Copilot, GitHub Copilot, Security Copilot, all coming\ntogether to compound the benefits of all the data and all the deployment, I\nthink, is probably the most transformative effect right now.\n\nJonathan Neilson\nVice President of Investor Relations\n\nThanks, Brad. Operator, we have time for 1 last question.\n\nOperator\n\nAnd the last question will come from the line of Raimo Lenschow with\nBarclays.\n\nRaimo Lenschow\nBarclays Bank PLC, Research Division\n\nThe last few quarters we talked -- besides the GPU side, you talked about\nCPU as well on the Azure side and you had some operational changes at the\nbeginning of January last year. Can you speak what you saw there? And maybe\nput it more on a bigger picture in terms of clients realizing that their\nmove to the cloud is important if you want to deliver proper AI. So what\nare we seeing in terms of cloud transition?\n\nSatya Nadella\nChairman & CEO\n\nI didn't quite...\n\nJonathan Neilson\nVice President of Investor Relations\n\nSorry, Raimo, you were asking about the SMC CPU side? Or can you just\nrepeat the question, please?\n\nRaimo Lenschow\nBarclays Bank PLC, Research Division\n\nYes. Sorry. So I was wondering about the CPU side of Azure because we had\nsome operational changes there. And we also hear from the [ field a lot ]\nthat people are realizing they need to be in the Cloud if you want to do\nproper AI and if that's kind of driving momentum.\n\nSatya Nadella\nChairman & CEO\n\nYes. I think I get it. So first of all, I had mentioned in my remarks that\nwhen you think about AI workloads, you should think of AI workloads as just\nAI accelerator compute, right? Because in some sense, you take any agent,\nthe agent will then spawn through tools used maybe a container, which runs\nobviously on compute. In fact, we have -- whenever we think about even\nbuilding out of the fleet, we think of in ratios or even for a training\njob, by the way. An AI training job requires a bunch of compute and a bunch\nof storage very close to compute. So therefore -- and same thing in\ninferencing as well.\n\nSo in inferencing with agent mode would require you to essentially\nprovision a computer or computing resources to the agent. So not -- they\ndon't need GPUs. They're running on GPUs, but they need computers, which\nare compute and storage. So that's what's happening even in the new world.\n\nThe other thing you mentioned is the Cloud migrations are still going on.\nIn fact, 1 of the stats I had was SQL -- latest SQL server growing as an\nIaaS service in Azure. And so -- that's one of the reasons why we have to\nthink about our commercial cloud and keep it balanced with the rest of our\nAI Cloud because when clients bring their workloads and build new\nworkloads, they need all of these infrastructure elements in the region in\nwhich they are deploying.\n\nJonathan Neilson\nVice President of Investor Relations\n\nThat wraps up the Q&A portion of today's earnings call. Thank you for\njoining us today, and we look forward to speaking with you all soon.\n\nSatya Nadella\nChairman & CEO\n\nThank you all.\n\nAmy E. Hood\nExecutive VP & CFO\n\nThank you.\n\nOperatorThank you. This concludes today's conference. You may disconnect\nyour lines at this time, and we thank you for your participation. Have a\ngreat night.\nCopyright  2026 by S&P Global Market Intelligence, a division of S&P\nGlobal Inc. All rights reserved.\n\nThese materials have been prepared solely for information purposes based\nupon information generally available to the public and from sources\nbelieved to be reliable. No content (including index data, ratings, credit-\nrelated analyses and data, research, model, software or other application\nor output therefrom) or any part thereof (Content) may be modified, reverse\nengineered, reproduced or distributed in any form by any means, or stored\nin a database or retrieval system, without the prior written permission of\nS&P Global Market Intelligence or its affiliates (collectively, S&P\nGlobal). The Content shall not be used for any unlawful or unauthorized\npurposes. S&P Global and any third-party providers, (collectively S&P\nGlobal Parties) do not guarantee the accuracy, completeness, timeliness or\navailability of the Content. S&P Global Parties are not responsible for any\nerrors or omissions, regardless of the cause, for the results obtained from\nthe use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P\nGLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS\nFOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR\nDEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE\nCONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no\nevent shall S&P Global Parties be liable to any party for any direct,\nindirect, incidental, exemplary, compensatory, punitive, special or\nconsequential damages, costs, expenses, legal fees, or losses (including,\nwithout limitation, lost income or lost profits and opportunity costs or\nlosses caused by negligence) in connection with any use of the Content even\nif advised of the possibility of such damages. S&P Global Market\nIntelligence's opinions, quotes and credit-related and other analyses are\nstatements of opinion as of the date they are expressed and not statements\nof fact or recommendations to purchase, hold, or sell any securities or to\nmake any investment decisions, and do not address the suitability of any\nsecurity. S&P Global Market Intelligence may provide index data. Direct\ninvestment in an index is not possible. Exposure to an asset class\nrepresented by an index is available through investable instruments based\non that index. S&P Global Market Intelligence assumes no obligation to\nupdate the Content following publication in any form or format. The Content\nshould not be relied on and is not a substitute for the skill, judgment and\nexperience of the user, its management, employees, advisors and/or clients\nwhen making investment and other business decisions. S&P Global Market\nIntelligence does not act as a fiduciary or an investment advisor except\nwhere registered as such. S&P Global keeps certain activities of its\ndivisions separate from each other in order to preserve the independence\nand objectivity of their respective activities. As a result, certain\ndivisions of S&P Global may have information that is not available to other\nS&P Global divisions. S&P Global has established policies and procedures to\nmaintain the confidentiality of certain nonpublic information received in\nconnection with each analytical process.\n\nS&P Global may receive compensation for its ratings and certain analyses,\nnormally from issuers or underwriters of securities or from obligors. S&P\nGlobal reserves the right to disseminate its opinions and analyses. S&P\nGlobal's public ratings and analyses are made available on its Web sites,\nwww.standardandpoors.com (free of charge), and www.ratingsdirect.com and\nwww.globalcreditportal.com (subscription), and may be distributed through\nother means, including via S&P Global publications and third-party\nredistributors. Additional information about our ratings fees is available\nat www.standardandpoors.com/usratingsfees.\n 2026 S&P Global Market Intelligence.",
  "has_qa": 1,
  "speaker_turns": [
    {
      "speaker": "Unknown",
      "role": "",
      "text": "Microsoft Corporation NasdaqGS:MSFT FQ2 2026 Earnings Call Transcripts Wednesday, January 28, 2026 10:30 PM GMT S&P Global Market Intelligence Estimates Presentation",
      "role_category": "Unknown"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "Greetings, and welcome to the Microsoft Fiscal Year 2026 Second Quarter Earnings Conference Call. [Operator Instructions] As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Neilson, Vice President of Investor Relations. Please go ahead.",
      "role_category": "Operator"
    },
    {
      "speaker": "Jonathan  Neilson",
      "role": "Vice President of Investor Relations",
      "text": "Vice President of Investor Relations Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer; Amy Hood, Chief Financial Officer; Alice Jolla, Chief Accounting Officer; and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website where we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company's second quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relates to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward-looking statements, which are predictions, projections or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Forms 10-Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. And with that, I'll turn the call over to Satya.",
      "role_category": "Executive"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Thank you very much, Jonathan. This quarter, the Microsoft Cloud surpassed $50 billion in revenue for the first time, up 26% year-over-year, reflecting the strength of our platform and accelerating demand. We are in the beginning phases of AI diffusion and its broad GDP impact. Our TAM will grow substantially across every layer of the tech stack as this diffusion accelerates and spreads. In fact, even in this early innings, we have built an AI business that is larger than some of our biggest franchises that took decades to build. Today, I'll focus my remarks across the 3 layers of our stack, cloud and token factory, agent platform and high-value agentic experiences. When it comes to our cloud and token factory, the key to long-term competitiveness is shaping our infrastructure to support new high-scale workloads. We are building this infrastructure out for the heterogeneous and distributed nature of these workloads, ensuring the right fit with the geographic and segment specific needs for all customers, including the long tail. The key metric we're optimizing for is tokens per watt per dollar, which comes down to increasing utilization and decreasing TCO using silicon systems and software. A good example of this is the 50% increase in throughput we were able to achieve in one of our highest volume workloads, OpenAI inferencing, powering our Copilots. And another example was the unlocking of new capabilities and efficiencies for our Fairwater data centers. In this instance, we connected both Atlanta and Wisconsin site through an AI WAN to build a first of its kind AI super factory. Fairwater's 2-storey design and liquid cooling allow us to run higher GPU densities and thereby improve both performance and latencies for high-scale training. All up, we added nearly 1 gigawatt of total capacity this quarter alone. At the silicon layer, we have NVIDIA and AMD and our own Maia chips, delivering the best all up fleet performance, cost and supply across multiple generations of hardware. Earlier this week, we brought online our Maia 200 accelerator. Maia 200 delivers 10-plus petaFLOPS at FP4 precision with over 30% improved TCO compared to the latest generation hardware in our fleet. We will be scaling this starting with inferencing and synthetic data gen for our Superintelligence Team as well as doing inferencing for Copilot and Foundry. And given AI workloads are not just about AI accelerators, but also consume large amounts of compute, we are pleased with the progress we are making on the CPU side as well. Cobalt 200 is another big leap forward, delivering over 50% higher performance compared to our first custom build processor for cloud-native workloads. Sovereignty is increasingly top of mind for customers, and we are expanding our solutions and global footprint to match. We announced DC investments in 7 countries this quarter alone, supporting local data residency needs. And we offer the most comprehensive set of sovereignty solutions across public, private and national partner cloud, so customers can choose the right approach for each workload with the local control they require. Next, I want to talk about the agent platform. Like in every platform shift, all software is being rewritten. A new app platform is being born. You can think of agents as the new apps and to build, deploy and manage agents, customers will need a model catalog, tuning services, harness for orchestration, services for context engineering, AI safety, management, observability and security. It starts with having broad model choice. Our customers expect to use multiple models as part of any workload that they can fine tune and optimize based on cost, latency and performance requirements. And we offer the broadest selection of models of any hyperscaler. This quarter, we added support for GPT-5.2 as well as Claude 4.5. Already over 1,500 customers have used both Anthropic and OpenAI models on Foundry. We are seeing increasing demand for region-specific models, including Mistral and Cohere as more customers look for sovereign AI choices, and we continue to invest in our first-party models, which are optimized to address the highest value customer scenarios such as productivity, coding and security. As part of Foundry, we also give customers the ability to customize and fine-tune models. Increasingly, customers want to be able to capture the tacit knowledge they possess inside of model weights as their core IP. This is probably the most important sovereign consideration for firms as AI diffuses more broadly across our GDP and every firm needs to protect their enterprise value. For agents to be effective, they need to be grounded in enterprise data and knowledge, that means connecting their agents to systems of record and operational data, analytical data as well as semi- structured and unstructured productivity and communications data. And this is what we are doing with our unified IQ layer, spanning Fabric, Foundry and data powering Microsoft 365. In the world of context engineering, Foundry knowledge and Fabric are gaining momentum. Foundry knowledge delivers better context with automated source routing an advanced agentic retrieval while respecting user permissions. And Fabric brings together end-to-end operational real-time and analytical data. 2 years since it became broadly available, Fabric's annual revenue run rate is now over $2 billion with over 31,000 customers, and it continues to be the fastest-growing analytics platform on the market with revenue up 60% year-over-year. All of the number of customers spending $1 million plus per quarter on Foundry grew nearly 80%, driven by strong growth in every industry. And over 250 customers are on track to process over 1 trillion tokens on Foundry this year. There are many great examples of customers using all of this capability on Foundry to build their own agentic systems. Alaska Airlines is creating natural language flight search. BMW is speeding up design cycles, Land O'Lakes is enabling precision farming for co-op members, and SymphonyAI is addressing bottlenecks in the CPG industry. And of course, Foundry remains a powerful on-ramp for the entire cloud. The vast majority of Foundry customers use additional Azure solutions like developer services, app services, databases as they scale. Beyond Fabric and Foundry, we are also addressing agent building by knowledge workers with Copilot Studio and Agent Builder. Over 80% of the Fortune 500 have active agents built using these low-code/no-code tools. As agents proliferate, every customer will need new ways to deploy, manage and protect them. We believe this creates a major new category and significant growth opportunity for us. This quarter, we introduced Agent 365, which makes it easy for organizations to extend their existing governance, identity, security and management to agents. That means the same controls they already use across Microsoft 365 and Azure, now extend to agents they build and deploy on our cloud or any other cloud. And partners like Adobe, Databricks, Genspark, Glean, NVIDIA, SAP, ServiceNow and Workday are already integrating Agent 365. We are the first provider to offer this type of agent control plane across clouds. Now let's turn to the high-value agentic experiences we are building. AI experiences are intent-driven and are beginning to work at task scope. We are entering an age of macro delegation and micro steering across domains. Intelligence using multiple models is built into multiple form factors. You see this in chat, in new agent inbox, apps, coworkers, scaffoldings, agent workflows embedded in applications and IDs that are used every day or even in our command line with file system access and skills. That's the approach we are taking with our first-party family of copilot spanning key domains. In consumer, for example, Copilot experiences span chat, news, feed, search, creation, browsing, shopping and integrations into the operating system, and it's gaining momentum. Daily users of our Copilot app increased nearly 3x year-over-year. And with Copilot checkout, we have partnered with PayPal, Shopify and Stripe, so customers can make purchases directly within the app. With Microsoft 365 Copilot, we are focused on organization-wide productivity. Work IQ takes the data underneath Microsoft 365 and creates the most valuable stateful agent for every organization. It delivers powerful reasoning capabilities over people, their roles, their artifacts, their communications and their history and memory all within an organization security boundary. Microsoft 365 Copilot's accuracy and latency powered by Work IQ is unmatched, delivering faster and more accurate work grounded results than competition, and we have seen our biggest quarter-over-quarter improvement in response quality to date. This has driven record usage intensity with average number of conversations per user doubling year-over- year. Microsoft 365 Copilot also is becoming true daily habit with daily active users increasing 10x year-over-year. We're also seeing strong momentum with researcher agent, which supports both OpenAI and Claude, as well as agent mode in Excel, PowerPoint and Word. All up, it was a record quarter for Microsoft 365 Copilot seat adds, up over 160% year-over-year. We saw accelerating seat growth quarter-over- quarter and now have 15 million paid Microsoft 365 Copilot seats and multiples more enterprise chat users. And we are seeing larger commercial deployments. The number of customers with over 35,000 seats tripled year-over-year. Fiserv, ING, NASA, University of Kentucky, University of Manchester, U.S. Department of Interior and Westpac, all purchased over 35,000 seats. Publicis alone purchased over 95,000 seats for nearly all its employees. We are also taking share in Dynamics 365 with built-in agents across the entire suite. A great example of this is how Visa is turning customer conversations data into knowledge articles with our customer knowledge management agent and dynamics. And how Sandvik is using our sales qualification agent to automate lead qualification across tens and thousands of potential customers. In coding, we are seeing strong growth across all paid GitHub Copilot. Copilot Pro Plus subs for individual devs increased 77% quarter-over- quarter, and all up now, we have 4.7 million paid Copilot subscribers, up 75% year-over-year. Siemens, for example, is going all in on GitHub adopting the full platform to increase developer productivity after a successful Copilot rollout to 30,000-plus developers. GitHub Agent HQ is the organizing layer for all coding agents like Anthropic, OpenAI, Google, Cognition and xAI in the context of customers GitHub repos. With Copilot CLI and VS Code, we offer developers the full spectrum of form factors and models they need for AI-first coding workflows. And when you add Work IQ as a skill or an MCP to our developer workflow, it's a game changer, surfacing more context like e-mails, meetings, docs, projects, messages and more. You can simply ask the agent to plan and execute changes to your code base based on an update to a spec-in Sharepoint or using the transcript of your last engineering and design meeting in Teams. And we're going beyond that with GitHub Copilot STK. Developers can now embed the same run time behind Copilot CLI, multi-model, multistep planning tools, MCP integration, Ops streaming directly into their applications. In security, we added a dozen new and updated security Copilot agents across Defender, Entra, Intune, and Purview. For example, Icertis, the SOC team used Security Copilot agent to reduce manual triage time by 75%, which is a real game changer in an industry facing a severe talent shortage. To make it easier for security teams to onboard, we are rolling out security copilot to all our E5 customers and our security solutions are also becoming essential to manage organization's AI deployments. 24 billion Copilot interactions were audited by Purview this quarter, up 9x year-over- year. Finally, I want to talk about 2 additional high-impact agenetic experiences. First, in health care, Dragon Copilot is the leader in its category, helping over 100,000 medical providers automate their workflows. Mount Sinai Health is now moving to a system-wide Dragon Copilot deployment for providers after a successful trial with its primary care physicians. All up, we helped document 21 million patient encounters this quarter, up 3x year-over-year. And second, when it comes to science and engineering, companies like Unilever in consumer goods and Synopsys in EDA are using Microsoft Discovery to orchestrate specialized agents for R&D end-to-end. They're able to reason over scientific literature and internal knowledge, formulate hypotheses, spin up simulations and continuously iterate to drive new discoveries. Beyond AI, we continue to invest in all our core franchises and meet the needs of our customers and partners, and we are seeing strong progress. For example, when it comes to cloud migrations, our new SQL server has over 2x the IaaS adoption of the previous version. In Security, we now have 1.6 million security customers, including over 1 million who use 4 or more of our workloads. Windows reached a big milestone, 1 billion Windows 11 users up over 45% year-over-year. And we had share gains this quarter across Windows, Edge and Bing, double-digit member growth in LinkedIn with 30% growth in paid video ads. And in gaming, we are committed to delivering great games across Xbox, PC, Cloud and every other device, and we saw record PC players in paid streaming hours on Xbox. In closing, we feel very good about how we are delivering for customers today and building the full stack to capture the opportunity ahead. With that, let me turn it over to Amy to walk through our financial results and outlook, and I look forward to rejoining for your questions.",
      "role_category": "Executive"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO Thank you, Satya, and good afternoon, everyone. With growing demand for our offerings and focused execution by our sales teams, we again exceeded expectations across revenue, operating income and earnings per share, while investing to fuel long-term growth. This quarter, revenue was $81.3 billion, up 17% and 15% in constant currency. Gross margin dollars increased 16% and 14% in constant currency, while operating income increased 21% and 19% in constant currency. Earnings per share was $4.14, an increase of 24% and 21% in constant currency when adjusted for the impact from our investment in OpenAI. And FX increased reported results slightly less than expected, particularly in Intelligent Cloud revenue. Company gross margin percentage was 68%, down slightly year-over-year, primarily driven by continued investments in AI infrastructure and growing AI product usage that was partially offset by ongoing efficiency gains, particularly in Azure and M365 Commercial Cloud as well as sales mix shift to higher-margin businesses. Operating expenses increased 5% and 4% in constant currency, driven by R&D investments in compute capacity and AI talent as well as impairment charges in our gaming business. Operating margins increased year-over-year to 47%, ahead of expectations. As a reminder, we still account for investment in OpenAI under the equity method. And as a result of OpenAI's recapitalization, we now record gains or losses based on our share of the change in their net assets on their balance sheet as opposed to our share of their operating profit or losses from their income statement. Therefore, we recorded a gain which drove other income and expense to $10 billion in our GAAP results. When adjusted for the OpenAI impact, other income and expense was slightly negative and lower than expected driven by net losses on investments. Capital expenditures were $37.5 billion, and this quarter, roughly 2/3 of our CapEx was on short-lived assets, primarily GPUs and CPUs. Our customer demand continues to exceed our supply. Therefore, we must balance the need to have our incoming supply better meet growing Azure demand with expanding first-party AI usage across services like M365 Copilot and GitHub Copilot, increasing allocations to R&D teams to accelerate product innovation and continued replacement of end-of-life server and networking equipment. The remaining spend was for long-lived assets that will support monetization for the next 15 years and beyond. This quarter, total finance leases were $6.7 billion, and were primarily for large data center sites. And cash paid for PP&E was $29.9 billion. Cash flow from operations was $35.8 billion, up 60%, driven by strong Cloud billings and collections. And free cash flow was $5.9 billion and decreased sequentially, reflecting the higher cash capital expenditures from a lower mix of finance leases. And finally, we returned $12.7 billion to shareholders through dividend and share repurchases, an increase of 32% year-over-year. Now to our commercial results. Commercial bookings increased 230% and 228% in constant currency, driven by the previously announced large Azure commitment from OpenAI that reflects multiyear demand needs as well as the previously announced Anthropic commitment from November and healthy growth across our core annuity sales motions. Commercial remaining performance obligation, which continues to be reported net of reserves increased to $625 billion, and was up 110% year-over-year with a weighted average duration of approximately 2.5 years. Roughly 25% will be recognized in revenue in the next 12 months, up 39% year-over-year. The remaining portion recognized beyond the next 12 months increased 156%. Approximately 45% of our commercial RPO balance is from OpenAI. The significant remaining balance grew 28% and reflects ongoing broad customer demand across the portfolio. Microsoft Cloud revenue was $51.5 billion and grew 26% and 24% in constant currency. Microsoft Cloud gross margin percentage was slightly better than expected at 67%, and down year-over-year due to continued investments in AI that were partially offset by ongoing efficiency gains noted earlier. Now to our segment results. Revenue from Productivity and Business Processes was $34.1 billion and grew 16% and 14% in constant currency. M365 Commercial cloud revenue increased 17% and 14% in constant currency with consistent execution in the core business and increasing contribution from strong copilot results. ARPU growth was again led by E5 and M365 Copilot, and paid M365 commercial seats grew 6% year-over-year to over 450 million with installed base expansion across all customer segments, though primarily in our small and medium business and frontline worker offerings. M365 Commercial products revenue increased 13% and 10% in constant currency, ahead of expectations due to higher-than-expected Office 2024 transactional purchasing. M365 consumer cloud revenue increased 29% and 27% in constant currency, again driven by ARPU growth. M365 consumer subscriptions grew 6%. LinkedIn revenue increased 11% and 10% in constant currency driven by Marketing Solutions. Dynamics 365 revenue increased 19% and 17% in constant currency with continued growth across all workloads. Segment gross margin dollars increased 17% and 15% in constant currency, and gross margin percentage increased, again driven by efficiency gains at M365 Commercial Cloud that were partially offset by continued investments in AI, including the impact of growing copilot usage. Operating expenses increased 6% and 5% in constant currency, and operating income increased 22% and 19% in constant currency. Operating margins increased year-over-year to 60%, driven by improved operating leverage as well as the higher gross margins noted earlier. Next, the Intelligent Cloud segment. Revenue was $32.9 billion and grew 29% and 28% in constant currency. In Azure and Other Cloud services, revenue grew 39% and 38% in constant currency, slightly ahead of expectations with ongoing efficiency gains across our fungible fleet, enabling us to reallocate some capacity to Azure that was monetized in the quarter. As mentioned earlier, we continue to see strong demand across workloads, customer segments and geographic regions, and demand continues to exceed available supply. In our on-premises server business, revenue increased 2% and 1% in constant currency, ahead of expectations, driven by demand for our hybrid solutions, including a benefit from the launch of SQL Server 2025, as well as higher transactional purchasing ahead of memory price increases. Segment gross margin dollars increased 20% and 19% in constant currency. Gross margin percentage decreased year-over-year, driven by continued investments in AI and sales mix shift to Azure, partially offset by efficiency gains in Azure. Operating expenses increased 3% and 2% in constant currency, and operating income grew 28% and 27% in constant currency. Operating margins were 42%, down slightly year-over-year as increased investments in AI were mostly offset by improved operating leverage. Now to More Personal Computing. Revenue was $14.3 billion and declined 3%. Windows OEM and devices revenue increased 1%, and was relatively unchanged in constant currency. Windows OEM grew 5% with strong execution as well as a continued benefit from Windows 10 end of support. Results were ahead of expectations as inventory levels remained elevated with increased purchasing ahead of memory price increases. Search and news advertising revenue ex TAC increased 10% and 9% in constant currency, slightly below expectations, driven by some execution challenges. As expected, the sequential growth rate moderated as the benefit from third- party partnerships normalized. And in Gaming. Revenue decreased 9% and 10% in constant currency. Xbox content and services revenue decreased 5% and 6% in constant currency, and was below expectations driven by first-party content with impact across the platform. Segment gross margin dollars increased 2% and 1% in constant currency, and gross margin percentage increased year-over-year, driven by sales mix shift to higher-margin businesses. Operating expenses increased 6% and 5% in constant currency, driven by the impairment charges in our gaming business noted earlier, as well as R&D investments in compute capacity and AI talent. Operating income decreased 3% and 4% in constant currency, and operating margins were relatively unchanged year-over-year at 27% as higher operating expenses were mostly offset by higher gross margins. Now moving to our Q3 outlook, which unless specifically noted otherwise, is on a U.S. dollar basis. Based on current rates, we expect FX to increase total revenue growth by 3 points. Within the segments, we expect FX to increase revenue growth by 4 points in Productivity and Business Processes, and 2 points in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS and operating expense growth by 2 points. As a reminder, this impact is due to the exchange rates a year ago. Starting with the total company. We expect revenue of USD 80.65 billion to USD 81.75 billion or growth of 15% to 17%, with continued strong growth across our commercial businesses, partially offset by our consumer businesses. We expect COGS of USD 26.65 billion to USD 26.85 billion or growth of 22% to 23%, and operating expense of USD 17.8 billion to USD 17.9 billion or growth of 10% to 11%, driven by continued investment in R&D, AI compute capacity and talent against a low prior year comparable. Operating margins should be down slightly year-over-year. Excluding any impact from our investments in OpenAI, other income and expense is expected to be roughly $700 million, driven by a fair market gain in our equity portfolio and interest income, partially offset by interest expense, which includes the interest payments related to data center finance leases. And we expect our adjusted Q3 effective tax rate to be approximately 19%. Next, we expect capital expenditures to decrease on a sequential basis due to the normal variability from cloud infrastructure build-outs and the timing of delivery of finance leases. As we work to close the gap between demand and supply, we expect the mix of short-lived assets to remain similar to Q2. Now our commercial business. In commercial bookings, we expect healthy growth in the core business on a growing expiry base when adjusted for the OpenAI contracts in the prior year. As a reminder, the significant OpenAI contracts signed in Q2 represents multiyear demand needs from them, which will result in some quarterly volatility in both bookings and RPO growth rates going forward. Microsoft Cloud gross margin percentage to be roughly 65%, down year-over-year, driven by continued investments in AI. Now to segment guidance. In Productivity and Business Processes, we expect revenue of USD 34.25 billion to USD 34.55 billion or growth of 14% to 15%. In M365 Commercial Cloud, we expect revenue growth to be between 13% and 14% in constant currency with continued stability and year-over-year growth rates on a large and expanding base. Accelerating Copilot momentum and ongoing E5 adoption will again drive ARPU growth. M365 commercial products revenue should decline in the low single digits, down sequentially, assuming office 2024 transactional purchasing trends normalize. As a reminder, M365 commercial products include components that can be variable due to in-period revenue recognition dynamics. M365 consumer cloud revenue growth should be in the mid- to high 20% range, driven by growth in ARPU as well as continued subscription volume. For LinkedIn, we expect revenue growth to be in the low double digits. And in Dynamics 365, we expect revenue growth to be in the high teens with continued growth across all workloads. For Intelligent Cloud, we expect revenue of USD 34.1 billion to USD 34.4 billion or growth of 27% to 29%. In Azure, we expect Q3 revenue growth to be between 37% and 38% in constant currency against a prior year comparable that included significantly accelerating growth rates in both Q3 and Q4. As mentioned earlier, demand continues to exceed supply, and we will need to continue to balance the incoming supply we can allocate here against other priorities. As a reminder, there can be quarterly variability in year-on-year growth rates depending on the timing of capacity delivery and when it comes online as well as from in-period revenue recognition depending on the mix of contracts. In our on-premises server business, we expect revenue to decline in the low single digits as growth rates normalize following the launch of SQL Server 2025, though increased memory pricing could create additional volatility in transactional purchasing. In More Personal Computing, we expect revenue to be USD 12.3 billion to USD 12.8 billion. Windows OEM and devices revenue should decline in the low teens. Growth rates will be impacted as the benefit from Windows 10 end of support normalizes and as elevated inventory levels come down through the quarter. Therefore, Windows OEM revenue should decline roughly 10%. The range of potential outcomes remains wider than normal, in part due to the potential impact on the PC market from increased memory pricing. Search and News advertising ex TAC revenue growth should be in the high single digits. Even as we work to improve execution, we expect continued share gains across Bing and Edge with growth driven by volume, and we expect sequential growth moderation as the contribution from third-party partnerships continues to normalize. And in Xbox content and services, we expect revenue to decline in the mid- single digits against a prior year comparable that benefited from strong content performance, partially offset by growth in Xbox Game Pass. And hardware revenue should decline year-over-year. Now some additional thoughts on the rest of the fiscal year and beyond. First, FX. Based on current rates, we expect FX to increase Q4 total revenue and COGS growth by less than 1 point with no impact to operating expense growth. Within the segments, we expect FX to increase revenue growth by roughly 1 point in Productivity and Business Processes and More Personal Computing, and less than 1 point in Intelligent Cloud. With the strong work delivered in H1 to prioritize investment in key growth areas and the favorable impact from a higher mix of revenue in our Windows OEM and commercial on-prem businesses, we now expect FY '26 operating margins to be up slightly. We mentioned the potential impact on Windows OEM and on-premises server markets from increased memory pricing earlier. In addition, rising memory prices would impact capital expenditures, though the impact on Microsoft Cloud gross margins will build more gradually as these assets depreciate over 6 years. In closing, we delivered strong top line growth in H1, and are investing across every layer of the stack to continue to deliver high-value solutions and tools to our customers. With that, let's go to Q&A, Jonathan. Question and Answer",
      "role_category": "Executive"
    },
    {
      "speaker": "Jonathan  Neilson",
      "role": "Vice President of Investor Relations",
      "text": "Vice President of Investor Relations Thanks, Amy. We'll now move over to Q&A. Out of respects for others on the call, we request that participants please only ask 1 question. Operator, can you please repeat your instructions?",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "[Operator Instructions] And our first question comes from the line of Keith Weiss with Morgan Stanley.",
      "role_category": "Operator"
    },
    {
      "speaker": "Keith  Weiss",
      "role": "Morgan Stanley, Research Division",
      "text": "Morgan Stanley, Research Division I'm looking at Microsoft print where earnings is growing 24% year-on-year, which is a spectacular result. Great execution on your part, top line growing well, margins expanding. But I'm looking at after-hours trading and the stock is still down. And I think one of the core issues that is weighing on investors is CapEx is growing faster than we expected and maybe Azure is growing a little bit slower than we expected. And I think that fundamentally comes down to a concern on the ROI on this CapEx spend over time. So I was hoping you guys could help us fill in some of the blanks a little bit in terms of how should we think about capacity expansion and what that can yield in terms of Azure growth going forward. More to the point, how should we think about the ROI on this investment as it comes to fruition?",
      "role_category": "Analyst"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO Thanks, Keith. And let me start and Satya can add some broader comments, I'm sure. I think the first thing, I think you really asked a very direct correlation that I do think many investors are doing, which is between the CapEx spend and seeing an Azure revenue number. And we tried last quarter, and I think, again, this quarter to talk more specifically about all the places that the CapEx spend, especially the short-lived CapEx spend across CPU and GPU and where that will show up. Sometimes, I think it's probably better to think about the Azure guidance that we give as an allocated capacity guide about what we can deliver in Azure revenue. Because as we spend the capital and put GPUs specifically, it applies to CPUs, the GPUs more specifically, we're really making long- term decisions. And the first thing we're doing is solving for the increased usage in sales and the accelerating pace of M365 Copilot as well as GitHub Copilot, our first-party apps. Then we make sure we're investing in the long-term nature of R&D and product innovation. And much of the acceleration that I think you've seen from us and products over the past a bit is coming because we are allocating GPUs and capacity to many of the talented AI people we've been hiring over the past years. Then, when you end up, is that, you end up with the remainder going towards serving the Azure capacity that continues to grow in terms of demand. And a way to think about it, because I think, I get asked this question sometimes, is if I had taken the GPUs that just came online in Q1 and Q2 in terms of GPUs and allocated them all to Azure, the KPI would have been over 40. And I think the most important thing to realize is that this is about investing in all the layers of the stack that benefit customers. And I think that's hopefully helpful in terms of thinking about capital growth, it shows in every piece, it shows in revenue growth across the business and shows as OpEx growth as we invest in our people.",
      "role_category": "Executive"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Yes, I think you -- Amy covered it. But basically, as an investor, I think when you think about our capital and you think about the GM profile of our portfolio, you should obviously think about Azure. But you should think about M365 Copilot and you should think about GitHub pilot, you should think about Dragon Copilot, Security Copilot. All of those have a GM profile and lifetime value. I mean if you think about it, acquiring an Azure customer is super important to us, but so is acquiring an M365 or a GitHub or a Dragon Copilot, which are all by the way incremental businesses and TAMs for us. And so we don't want to maximize just 1 business of ours, we want to be able to allocate capacity while we're sort of supply constrained in a way that allow us to essentially build the best LTV portfolio. That's on one side. And the other one that Amy mentioned is also R&D. I mean you got to think about compute is also R&D, and that's sort of the second element of it. And so we are using all of that, obviously, to optimize for the long term.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Mark Moerdler with Bernstein Research.",
      "role_category": "Operator"
    },
    {
      "speaker": "Mark L. Moerdler",
      "role": "Bernstein Institutional Services LLC, Research Division",
      "text": "Bernstein Institutional Services LLC, Research Division Congrats on the quarter. One of the other questions we believe investors want to understand is how to think about your line of sight from hardware CapEx investment to revenue and margins. You capitalized servers over 6 years, but the average duration of your RPO is 2.5 years, up from 2 years last quarter. How do investors get comfortable that since this is a lot of this CapEx is AI-centric that you'll be able to capture sufficient revenue over the 6-year useful life of the hardware to deliver solid revenue and gross profit dollars growth, hopefully, one similar to the CPU revenue.",
      "role_category": "Analyst"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO Thanks, Mark. Let me start with at a high level and Satya can add as well. I think when you think about average duration, I think what you're getting to is -- and we need to remember, is it, average duration is a combination of a broad set of contract arrangements that we have. A lot of them around things like M365 or our BizApps portfolio, are shorter dated, right, 3-year contracts. And so they have, quite frankly, a short duration. The majority then that's remaining are Azure contracts are longer duration. And you saw that this quarter when we saw the extension of that duration from around 2 years to 2.5 years. And the way to think about that is the majority of the capital that we're spending today, and a lot of the GPUs that we're buying are already contracted for most of their useful life. And so a way to think about that is much of that risk that I think you're pointing to isn't there, because they're already sold for the entirety of their useful life. And so part of it exists because you have this shorter-dated RPO because of some of the M365 stuff. If you look at the Azure only, RPO is a little bit more extended. A lot of that is CPU basis. It's not just GPU. And on the GPU contracts that we've talked about, including for some of our largest customers, those are sold for the entire useful life of the GPU. And so there's not the risk to which I think you may be referring. Hopefully, that's helpful.",
      "role_category": "Executive"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Yes. And just to -- one other thing I would add to it is, in addition to sort of what Amy mentioned, which is it's already contracted for the useful life is we do use software to continuously around even the latest models on the fleet that is aging, if you will. So that's sort of what gives us that duration. And so at the end of the day, we want to have -- that's why we even think about aging the fleet constantly, right? So it's not about buying a whole lot of gear 1 year. It's about each year, you write the Moore's Law, you add, you use software, and then you optimize across all of it.",
      "role_category": "Executive"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO And Mark, maybe to state this in case it's not obvious, is that as you go through the useful life, actually, you get more and more and more efficient at delivery. So where you've sold the entirety of its life, the margins actually improved with time. And so I think that may be a good reminder to people as we see that, obviously, in the CPU fleet all the time.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Brent Thill with Jefferies.",
      "role_category": "Operator"
    },
    {
      "speaker": "Brent John Thill",
      "role": "Jefferies LLC, Research Division",
      "text": "Jefferies LLC, Research Division Amy, on 45% of the backlog being related to OpenAI. I'm just curious if you can comment, there's obviously concern about the durability. And I know maybe there's not much you can say on this, but I think everyone is concerned about the exposure. And if you could maybe talk through your perspective and what both you and Satya are seeing.",
      "role_category": "Analyst"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO I think maybe I would have thought about the question quite differently, Brent. The first thing to focus on is the reason we talked about that number is because 55% or roughly $350 billion is related to the breadth of our portfolio, a breadth of customers across solutions, across Azure, across industries, across geographies. That is a significant RPO balance, larger than most peers, more diversified than most peers. And frankly, I think we have super high confidence in it. And when you think about that portion alone growing 28%, it's really impressive work on the breadth as well as the adoption curve that we're seeing, which is I think what I get asked most frequently, it's grown by customer segment, by industry and by geo. And so it's very consistent. And so then if you're asking about how do I feel about OpenAI and the contract and the health, listen, it's a great partnership. We continue to be their provider of scale. We're excited to do that. We sit under one of the most successful businesses built, and we continue to feel quite good about that. It's allowed us to remain a leader in terms of what we're building and being on the cutting edge of app innovation.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Karl Keirstead with UBS.",
      "role_category": "Operator"
    },
    {
      "speaker": "Karl Emil Keirstead",
      "role": "UBS Investment Bank, Research Division",
      "text": "UBS Investment Bank, Research Division Amy, regardless of how you allocate the capacity between first party and third party, can you comment qualitatively on the amount of capacity that's coming on. I think the 1 gigawatt added in the December quarter was extraordinary and hence that the capacity adds are accelerating. But I think a lot of investors have their eyes on Fairwater Atlanta, Fairwater Wisconsin, and would love some comments about the magnitude of the capacity adds regardless of how they're allocated in the coming quarters.",
      "role_category": "Analyst"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO Yes, Karl, I think we've said a couple of things. We're working as hard as we can to add capacity as quickly as we can. You've mentioned specific sites like Atlanta or Wisconsin, those are multiyear deliveries. So I wouldn't focus necessarily on specific locations. The real thing we've got to do, and we're working incredibly hard doing it, is adding capacity globally. A lot of that will be added in the United States, the 2 locations you've mentioned, but it also needs to be added across the globe to meet the customer demand that we're seeing and the increased usage. We'll continue to add both long-lived infrastructure. The way to think about that is we need to make sure we've got power and land and facilities available and we'll continue to put GPUs and CPUs in them when they're done as quickly as we can. And then finally, we'll try to make sure we can get as efficient as we possibly can on the pace at which we do that and how we operate them so that they can have the highest possible utility. And so I think it's not really about 2 places, Karl, I would definitely abstract away from that. Those are multiyear delivery time lines. But really, we just need to get it done every location where we're currently in a build or starting to do that. We're working as quickly as we can.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Mark Murphy with JPMorgan.",
      "role_category": "Operator"
    },
    {
      "speaker": "Mark Ronald Murphy",
      "role": "JPMorgan Chase & Co, Research Division",
      "text": "JPMorgan Chase & Co, Research Division Satya, the performance achievements of the Maia 200 accelerator for inference, look quite remarkable, especially in comparison to TPUs and Trinium and Blackwell, which have just been around a lot longer. Could you put that accomplishment in perspective in terms of how much of a core competency you think silicon might become for Microsoft. And Amy, are there any ramifications worth mentioning there in terms of supporting your gross margin profile for inference costs going forward?",
      "role_category": "Analyst"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Yes, thanks for the question. So a couple of things. One is we've been at this in a variety of different forms for a long, long time in terms of building our own silicon. And so we're very, very thrilled about the progress with Maia 200, and -- especially when we think about running a GPT- 5.2 and the performance we were able to get in the GEMS at FB4, just proof point that when you have a new workload, a new shape of a workload, you can start innovating end-to-end between the model and the silicon and the entire system. It's just not even about just the silicon, the way the networking works at rack scale that's optimized with memory for this particular workload. And the other thing is we're obviously round-tripping and working very closely with own super intelligence team with all of our models, as you can imagine, whatever we build will be all optimized for Maia. So we feel great about it. And I think the way to think about all up is we're in such early innings. I mean, even just look at the amount of silicon innovation and systems innovation. Even since December, I think the new thing is everybody is talking about low latency inference, right? And so one of the things we want to make sure is we are not locked into any one thing. If anything, we have great partnership with NVIDIA, with AMD, they are innovating, we're innovating. We want a fleet at any given point in time to have access to the best TCO. And it's not a one-generation game. I think a lot of folks just talk about who's ahead. It's just remember, you have to be ahead for all time to come. And that means you really want to think about having a lot of innovation that happens out there to be in your fleet, so that your fleet is fundamentally advantaged at the TCO level. So that's kind of how I look at it, which is we are excited about Maia. We're excited about Cobalt. We're excited about our DPU, our NIC. So we have a lot of systems capability. That means we can vertically integrate. And because we can vertically integrate doesn't mean we just only vertically integrate. And so we want to be able to have the flexibility here, and that's what you see us do.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "The next question comes from the line of Brad Zelnick with Deutsche Bank.",
      "role_category": "Operator"
    },
    {
      "speaker": "Brad Alan Zelnick",
      "role": "Deutsche Bank AG, Research Division",
      "text": "Deutsche Bank AG, Research Division Satya, we heard a lot about Frontier transformations from Judson at Ignite, and we've seen customers realize breakthrough benefits when they adopt the Microsoft AI stack. Can you help frame for us the momentum in enterprises embarking on these journeys? And any expectation for how much their spend with Microsoft can expand in becoming frontier firms?",
      "role_category": "Analyst"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Yes. Thank you for that. So I think one of the things that we are seeing is the adoption across the 3 major suites of ours, right? So if you take M365, you take what's happening with security and you take GitHub. In fact, it's fascinating. I mean these 3 things had effectively compounding effects for our customers in the past, like something like Entra as an identity system, or Defender as the protection system, across all 3 was sort of super helpful. But so what now you're seeing is something like Work IQ, right? So I mean just to give you a favor for it, the most important database underneath for any company that uses Microsoft today is the data underneath Microsoft 365. And the reason is because it has all those tacit information, right, who are your people, what are their relationships, what are their projects they're working on, what are their artifacts, their communications. So that's a super important asset for any business process, business workflow context. In fact, the scenario I even had in my transcript around you can now take Work IQ as an MCP server and GitHub Repo and say, \"Hey, please look at my design meetings for the last month in Teams and tell me if my repo reflects it.\" I mean that's a pretty high-level way to think about how, what is happening previously perhaps with our tools business and our GitHub business are suddenly now being transformative, right? That agent black plane is really transforming companies in some sense, right? That's, I think, the most magical thing, which is you deploy these things. And suddenly, the agents are helping you coordinate, bring more leverage to your enterprise. Then on top of it, of course, there is the transformation, which is what businesses are doing. How should we think about customer service. How should we think about marketing. How should we think about finance. How should we think about that and build our own agents. That's where all the services in Fabric and Foundry. And of course, GitHub tooling is helping them or even the low-code/no-code tools. I had some stats on how much that's being used. But one of the more exciting things for me is the new agents systems, M365 Copilot, GitHub Copilot, Security Copilot, all coming together to compound the benefits of all the data and all the deployment, I think, is probably the most transformative effect right now.",
      "role_category": "Executive"
    },
    {
      "speaker": "Jonathan  Neilson",
      "role": "Vice President of Investor Relations",
      "text": "Vice President of Investor Relations Thanks, Brad. Operator, we have time for 1 last question.",
      "role_category": "Executive"
    },
    {
      "speaker": "Operator",
      "role": "Operator",
      "text": "And the last question will come from the line of Raimo Lenschow with Barclays.",
      "role_category": "Operator"
    },
    {
      "speaker": "Raimo  Lenschow",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division The last few quarters we talked -- besides the GPU side, you talked about CPU as well on the Azure side and you had some operational changes at the beginning of January last year. Can you speak what you saw there? And maybe put it more on a bigger picture in terms of clients realizing that their move to the cloud is important if you want to deliver proper AI. So what are we seeing in terms of cloud transition?",
      "role_category": "Analyst"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO I didn't quite...",
      "role_category": "Executive"
    },
    {
      "speaker": "Jonathan  Neilson",
      "role": "Vice President of Investor Relations",
      "text": "Vice President of Investor Relations Sorry, Raimo, you were asking about the SMC CPU side? Or can you just repeat the question, please?",
      "role_category": "Executive"
    },
    {
      "speaker": "Raimo  Lenschow",
      "role": "Barclays Bank PLC, Research Division",
      "text": "Barclays Bank PLC, Research Division Yes. Sorry. So I was wondering about the CPU side of Azure because we had some operational changes there. And we also hear from the [ field a lot ] that people are realizing they need to be in the Cloud if you want to do proper AI and if that's kind of driving momentum.",
      "role_category": "Analyst"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Yes. I think I get it. So first of all, I had mentioned in my remarks that when you think about AI workloads, you should think of AI workloads as just AI accelerator compute, right? Because in some sense, you take any agent, the agent will then spawn through tools used maybe a container, which runs obviously on compute. In fact, we have -- whenever we think about even building out of the fleet, we think of in ratios or even for a training job, by the way. An AI training job requires a bunch of compute and a bunch of storage very close to compute. So therefore -- and same thing in inferencing as well. So in inferencing with agent mode would require you to essentially provision a computer or computing resources to the agent. So not -- they don't need GPUs. They're running on GPUs, but they need computers, which are compute and storage. So that's what's happening even in the new world. The other thing you mentioned is the Cloud migrations are still going on. In fact, 1 of the stats I had was SQL -- latest SQL server growing as an IaaS service in Azure. And so -- that's one of the reasons why we have to think about our commercial cloud and keep it balanced with the rest of our AI Cloud because when clients bring their workloads and build new workloads, they need all of these infrastructure elements in the region in which they are deploying.",
      "role_category": "Executive"
    },
    {
      "speaker": "Jonathan  Neilson",
      "role": "Vice President of Investor Relations",
      "text": "Vice President of Investor Relations That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.",
      "role_category": "Executive"
    },
    {
      "speaker": "Satya  Nadella",
      "role": "Chairman & CEO",
      "text": "Chairman & CEO Thank you all.",
      "role_category": "Executive"
    },
    {
      "speaker": "Amy E. Hood",
      "role": "Executive VP & CFO",
      "text": "Executive VP & CFO Thank you. OperatorThank you. This concludes today's conference. You may disconnect your lines at this time, and we thank you for your participation. Have a great night. Copyright  2026 by S&P Global Market Intelligence, a division of S&P Global Inc. All rights reserved. These materials have been prepared solely for information purposes based upon information generally available to the public and from sources believed to be reliable. No content (including index data, ratings, credit- related analyses and data, research, model, software or other application or output therefrom) or any part thereof (Content) may be modified, reverse engineered, reproduced or distributed in any form by any means, or stored in a database or retrieval system, without the prior written permission of S&P Global Market Intelligence or its affiliates (collectively, S&P Global). The Content shall not be used for any unlawful or unauthorized purposes. S&P Global and any third-party providers, (collectively S&P Global Parties) do not guarantee the accuracy, completeness, timeliness or availability of the Content. S&P Global Parties are not responsible for any errors or omissions, regardless of the cause, for the results obtained from the use of the Content. THE CONTENT IS PROVIDED ON \"AS IS\" BASIS. S&P GLOBAL PARTIES DISCLAIM ANY AND ALL EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE OR USE, FREEDOM FROM BUGS, SOFTWARE ERRORS OR DEFECTS, THAT THE CONTENT'S FUNCTIONING WILL BE UNINTERRUPTED OR THAT THE CONTENT WILL OPERATE WITH ANY SOFTWARE OR HARDWARE CONFIGURATION. In no event shall S&P Global Parties be liable to any party for any direct, indirect, incidental, exemplary, compensatory, punitive, special or consequential damages, costs, expenses, legal fees, or losses (including, without limitation, lost income or lost profits and opportunity costs or losses caused by negligence) in connection with any use of the Content even if advised of the possibility of such damages. S&P Global Market Intelligence's opinions, quotes and credit-related and other analyses are statements of opinion as of the date they are expressed and not statements of fact or recommendations to purchase, hold, or sell any securities or to make any investment decisions, and do not address the suitability of any security. S&P Global Market Intelligence may provide index data. Direct investment in an index is not possible. Exposure to an asset class represented by an index is available through investable instruments based on that index. S&P Global Market Intelligence assumes no obligation to update the Content following publication in any form or format. The Content should not be relied on and is not a substitute for the skill, judgment and experience of the user, its management, employees, advisors and/or clients when making investment and other business decisions. S&P Global Market Intelligence does not act as a fiduciary or an investment advisor except where registered as such. S&P Global keeps certain activities of its divisions separate from each other in order to preserve the independence and objectivity of their respective activities. As a result, certain divisions of S&P Global may have information that is not available to other S&P Global divisions. S&P Global has established policies and procedures to maintain the confidentiality of certain nonpublic information received in connection with each analytical process. S&P Global may receive compensation for its ratings and certain analyses, normally from issuers or underwriters of securities or from obligors. S&P Global reserves the right to disseminate its opinions and analyses. S&P Global's public ratings and analyses are made available on its Web sites, www.standardandpoors.com (free of charge), and www.ratingsdirect.com and www.globalcreditportal.com (subscription), and may be distributed through other means, including via S&P Global publications and third-party redistributors. Additional information about our ratings fees is available at www.standardandpoors.com/usratingsfees.  2026 S&P Global Market Intelligence.",
      "role_category": "Executive"
    }
  ],
  "source_file": "Microsoft Corporation, Q2 2026 Earnings Call, Jan 28, 2026.rtf"
}